2025-03-24 19:20:40,020 - INFO - [Train] Using device: cuda
2025-03-24 19:20:45,723 - INFO - Loaded model checkpoint from /mnt/c/Users/didri/Desktop/Programmering/ArtificalintelligenceModels/UNet-Model_Vocal_Isolation/Unet_model_Audio_Seperation/Model_Weights/CheckPoints/Evaluation/checkpoint_epoch_3
2025-03-24 19:20:45,922 - INFO - [Train] Epoch 1/10 started.

2025-03-24 19:21:45,954 - INFO - #####INPUTS & TARGETS VALUE [2 BATCHES]####
Batch 1: Mixture shape=torch.Size([4, 1, 513, 946]), Target shape=torch.Size([4, 1, 513, 946])
2025-03-24 19:21:50,652 - INFO - [EPOCH 1]outputs from the model torch.Size([4, 64, 513, 946])
for batch 1
predicted mask shape torch.Size([4, 1, 513, 946])
2025-03-24 19:21:51,984 - INFO - Function: [log_first_2_batches_outputs_inputs_targets_predicted_mask]
2025-03-24 19:21:51,987 - INFO - ####OUTPUTS, INPUTS, TARGETS,PREDICTEDMASK [2 BATCHES]####
Batch 1: Mask range: min=0.0000, max=33.8125
Batch 1: Inputs shape=torch.Size([4, 1, 513, 946]), Targets shape=torch.Size([4, 1, 513, 946]), Predicted Mask shape=torch.Size([4, 1, 513, 946]), Outputs shape=torch.Size([4, 64, 513, 946])
Mask min=0.355712890625, max=1.0
[After Mask Application] Predicted vocals min: 0.0, max: 139.75

2025-03-24 19:21:51,987 - INFO - 
####LOSS VALUES####
[Combinedloss]:  Total treningsfeil, [BØR REDUSERES OVER TID]
[MaskLoss]: Sier hvor godt modellen lærer og predikere masken som isolerer vokaler[BØR REDUSERES OVER TID]
[l1_loss og stft_loss] gir ekstra indikasjoner på lydkvalitet.
[Hybridloss]: Kombinasjon av flere tapsfunksjoner[BØR REDUSERES OVER TID]

2025-03-24 19:21:52,096 - INFO - Appending Batch Losses: Mask: 0.3259923756122589, Hybrid: 0.7056859731674194, Combined: 1.2283642292022705
2025-03-24 19:22:15,258 - INFO - [EPOCH 1]outputs from the model torch.Size([4, 64, 513, 946])
for batch 2
predicted mask shape torch.Size([4, 1, 513, 946])
2025-03-24 19:22:19,295 - INFO - Appending Batch Losses: Mask: 0.4362500011920929, Hybrid: 1.107069492340088, Combined: 1.892249584197998
2025-03-24 19:22:21,220 - INFO - Appending Batch Losses: Mask: 0.3540101945400238, Hybrid: 0.7402722835540771, Combined: 1.0314743518829346
2025-03-24 19:22:22,841 - INFO - Appending Batch Losses: Mask: 0.3789069354534149, Hybrid: 0.7988483905792236, Combined: 0.6721869111061096
2025-03-24 19:22:23,950 - INFO - Appending Batch Losses: Mask: 0.2841535806655884, Hybrid: 0.6654698848724365, Combined: 0.9879850149154663
2025-03-24 19:22:25,764 - INFO - Appending Batch Losses: Mask: 0.37044328451156616, Hybrid: 0.6980918645858765, Combined: 1.5086255073547363
2025-03-24 19:22:41,428 - INFO - Appending Batch Losses: Mask: 0.3571000099182129, Hybrid: 1.0079107284545898, Combined: 2.302773952484131
2025-03-24 19:22:43,581 - INFO - Appending Batch Losses: Mask: 0.3534685969352722, Hybrid: 0.7263186573982239, Combined: 1.2889782190322876
2025-03-24 19:22:45,419 - INFO - Appending Batch Losses: Mask: 0.32173827290534973, Hybrid: 0.6955876350402832, Combined: 1.3038971424102783
2025-03-24 19:22:46,939 - INFO - Appending Batch Losses: Mask: 0.3282538950443268, Hybrid: 0.7007212042808533, Combined: 0.7357579469680786
2025-03-24 19:22:49,080 - INFO - Appending Batch Losses: Mask: 0.3949423134326935, Hybrid: 0.8571641445159912, Combined: 1.4471145868301392
2025-03-24 19:22:52,379 - INFO - Appending Batch Losses: Mask: 0.37114155292510986, Hybrid: 1.0235681533813477, Combined: 2.146909236907959
2025-03-24 19:23:45,495 - INFO - Appending Batch Losses: Mask: 0.393034428358078, Hybrid: 0.6865783929824829, Combined: 1.2834514379501343
2025-03-24 19:23:52,364 - INFO - Appending Batch Losses: Mask: 0.45544010400772095, Hybrid: 0.9876817464828491, Combined: 1.2899770736694336
2025-03-24 19:23:53,962 - INFO - Appending Batch Losses: Mask: 0.3435646891593933, Hybrid: 0.7256674766540527, Combined: 1.332839846611023
2025-03-24 19:23:55,540 - INFO - Appending Batch Losses: Mask: 0.3796934485435486, Hybrid: 0.8549087047576904, Combined: 1.628943681716919
2025-03-24 19:23:57,345 - INFO - Appending Batch Losses: Mask: 0.38209694623947144, Hybrid: 0.7589417695999146, Combined: 0.7881686687469482
2025-03-24 19:23:58,911 - INFO - Appending Batch Losses: Mask: 0.36706146597862244, Hybrid: 0.8953859806060791, Combined: 1.2715659141540527
2025-03-24 19:24:19,629 - INFO - Appending Batch Losses: Mask: 0.38022783398628235, Hybrid: 0.7822179794311523, Combined: 0.900490939617157
2025-03-24 19:24:20,679 - INFO - Appending Batch Losses: Mask: 0.47356554865837097, Hybrid: 1.1380555629730225, Combined: 1.0291365385055542
2025-03-24 19:24:22,558 - INFO - Appending Batch Losses: Mask: 0.4311879873275757, Hybrid: 0.9028924703598022, Combined: 1.6077499389648438
2025-03-24 19:24:30,133 - INFO - Appending Batch Losses: Mask: 0.3941890001296997, Hybrid: 0.7740569114685059, Combined: 1.0960514545440674
2025-03-24 19:24:32,813 - INFO - Appending Batch Losses: Mask: 0.38813525438308716, Hybrid: 0.7684502601623535, Combined: 1.5870039463043213
2025-03-24 19:24:33,827 - INFO - Appending Batch Losses: Mask: 0.44980770349502563, Hybrid: 0.9102469682693481, Combined: 1.3612487316131592
2025-03-24 19:24:56,986 - INFO - Appending Batch Losses: Mask: 0.3237738311290741, Hybrid: 0.6731379628181458, Combined: 0.5304743051528931
2025-03-24 19:24:59,840 - INFO - Current Learning Rate 0.0004959264651961047

2025-03-24 19:25:01,333 - INFO - Checkpoint saved: /mnt/c/Users/didri/Desktop/Programmering/ArtificalintelligenceModels/UNet-Model_Vocal_Isolation/Unet_model_Audio_Seperation/Model_Weights/CheckPoints/Training/checkpoint_epoch_0.pth
2025-03-24 19:25:01,333 - INFO - 
 [EPOCH 1]Model Checkpoint SAVED at epoch 1
 avg_epoch_loss: [1.290137]
 bestloss: [1.290137]
 Trigger times: 0/12

2025-03-24 19:26:26,206 - INFO - 
Trigger times: 0, patience: 20

2025-03-24 19:26:26,207 - INFO - 
Trigger times: 0, patience: 12

2025-03-24 19:26:26,207 - INFO - 
[Epoch Improvement] Epoch 1: Loss improved during training by nan% from previous epoch, 

2025-03-24 19:26:26,209 - INFO - ####LOGGING AVERAGE LOSS EPOCH###
[Epoch Summary] Epoch: 1/10, Avg Combined Loss: 1.290137, MaskLoss: 0.377527, Hybridloss: 0.823397Previous Epoch loss: inf
2025-03-24 19:26:26,210 - INFO - Epoch: 1 COMPLETED





2025-03-24 19:26:26,212 - INFO - [Train] Epoch 2/10 started.

2025-03-24 19:27:37,775 - INFO - #####INPUTS & TARGETS VALUE [2 BATCHES]####
Batch 1: Mixture shape=torch.Size([4, 1, 513, 946]), Target shape=torch.Size([4, 1, 513, 946])
2025-03-24 19:27:39,803 - INFO - [EPOCH 2]outputs from the model torch.Size([4, 64, 513, 946])
for batch 1
predicted mask shape torch.Size([4, 1, 513, 946])
2025-03-24 19:27:41,030 - INFO - Function: [log_first_2_batches_outputs_inputs_targets_predicted_mask]
2025-03-24 19:27:41,033 - INFO - ####OUTPUTS, INPUTS, TARGETS,PREDICTEDMASK [2 BATCHES]####
Batch 1: Mask range: min=0.0000, max=8.8047
Batch 1: Inputs shape=torch.Size([4, 1, 513, 946]), Targets shape=torch.Size([4, 1, 513, 946]), Predicted Mask shape=torch.Size([4, 1, 513, 946]), Outputs shape=torch.Size([4, 64, 513, 946])
Mask min=0.407958984375, max=0.9892578125
[After Mask Application] Predicted vocals min: 0.0, max: 93.0625

2025-03-24 19:27:41,033 - INFO - 
####LOSS VALUES####
[Combinedloss]:  Total treningsfeil, [BØR REDUSERES OVER TID]
[MaskLoss]: Sier hvor godt modellen lærer og predikere masken som isolerer vokaler[BØR REDUSERES OVER TID]
[l1_loss og stft_loss] gir ekstra indikasjoner på lydkvalitet.
[Hybridloss]: Kombinasjon av flere tapsfunksjoner[BØR REDUSERES OVER TID]

2025-03-24 19:27:41,053 - INFO - Appending Batch Losses: Mask: 0.3595389425754547, Hybrid: 0.8329286575317383, Combined: 0.8304221630096436
2025-03-24 19:28:20,596 - INFO - [EPOCH 2]outputs from the model torch.Size([4, 64, 513, 946])
for batch 2
predicted mask shape torch.Size([4, 1, 513, 946])
2025-03-24 19:28:22,733 - INFO - Appending Batch Losses: Mask: 0.3405318558216095, Hybrid: 0.6675098538398743, Combined: 1.509887933731079
2025-03-24 19:28:25,133 - INFO - Appending Batch Losses: Mask: 0.4500468969345093, Hybrid: 0.9436533451080322, Combined: 1.5686362981796265
2025-03-24 19:28:27,852 - INFO - Appending Batch Losses: Mask: 0.46699512004852295, Hybrid: 0.8999536037445068, Combined: 1.7764348983764648
2025-03-24 19:28:30,147 - INFO - Appending Batch Losses: Mask: 0.3718274235725403, Hybrid: 0.7804701924324036, Combined: 1.046118974685669
2025-03-24 19:28:32,003 - INFO - Appending Batch Losses: Mask: 0.41946840286254883, Hybrid: 0.8278309106826782, Combined: 1.3899568319320679
2025-03-24 19:28:38,679 - INFO - Appending Batch Losses: Mask: 0.26608288288116455, Hybrid: 0.6651617288589478, Combined: 0.9981987476348877
2025-03-24 19:28:44,118 - INFO - Appending Batch Losses: Mask: 0.27155205607414246, Hybrid: 0.6358591914176941, Combined: 1.1241166591644287
2025-03-24 19:28:47,147 - INFO - Appending Batch Losses: Mask: 0.3161301612854004, Hybrid: 0.6816670894622803, Combined: 1.2004773616790771
2025-03-24 19:28:48,180 - INFO - Appending Batch Losses: Mask: 0.5116651654243469, Hybrid: 0.9880973100662231, Combined: 1.6989428997039795
2025-03-24 19:28:51,247 - INFO - Appending Batch Losses: Mask: 0.4056708514690399, Hybrid: 0.8431804180145264, Combined: 0.5822228193283081
2025-03-24 19:29:06,454 - INFO - Appending Batch Losses: Mask: 0.38524067401885986, Hybrid: 0.9957154989242554, Combined: 1.8691562414169312
2025-03-24 19:29:08,407 - INFO - Appending Batch Losses: Mask: 0.3843236565589905, Hybrid: 0.7693994641304016, Combined: 1.5628688335418701
2025-03-24 19:29:09,506 - INFO - Appending Batch Losses: Mask: 0.32844820618629456, Hybrid: 0.8053016662597656, Combined: 0.7095558047294617
2025-03-24 19:29:15,958 - INFO - Appending Batch Losses: Mask: 0.3127315044403076, Hybrid: 0.6341094374656677, Combined: 0.8841673135757446
2025-03-24 19:29:18,856 - INFO - Appending Batch Losses: Mask: 0.26249822974205017, Hybrid: 0.6247789859771729, Combined: 1.5118727684020996
2025-03-24 19:29:20,681 - INFO - Appending Batch Losses: Mask: 0.3450655937194824, Hybrid: 0.683184802532196, Combined: 0.6679023504257202
2025-03-24 19:29:22,502 - INFO - Appending Batch Losses: Mask: 0.39810508489608765, Hybrid: 0.7816412448883057, Combined: 1.6466363668441772
2025-03-24 19:29:50,388 - INFO - Appending Batch Losses: Mask: 0.41500431299209595, Hybrid: 1.0303549766540527, Combined: 1.8749196529388428
2025-03-24 19:29:52,145 - INFO - Appending Batch Losses: Mask: 0.333213746547699, Hybrid: 0.7286314964294434, Combined: 0.5962616205215454
2025-03-24 19:29:54,476 - INFO - Appending Batch Losses: Mask: 0.34203654527664185, Hybrid: 0.9349275827407837, Combined: 1.4258009195327759
2025-03-24 19:29:56,449 - INFO - Appending Batch Losses: Mask: 0.37059396505355835, Hybrid: 0.7517032623291016, Combined: 0.8543272018432617
2025-03-24 19:29:59,668 - INFO - Appending Batch Losses: Mask: 0.37217557430267334, Hybrid: 0.7518031597137451, Combined: 1.3382396697998047
2025-03-24 19:30:00,920 - INFO - Appending Batch Losses: Mask: 0.3650566041469574, Hybrid: 0.8750723600387573, Combined: 1.204755187034607
2025-03-24 19:30:32,131 - INFO - Appending Batch Losses: Mask: 0.26858437061309814, Hybrid: 0.599589467048645, Combined: 0.6664242148399353
2025-03-24 19:30:33,855 - INFO - Current Learning Rate 0.0005404604490558215

2025-03-24 19:30:35,393 - INFO - Checkpoint saved: /mnt/c/Users/didri/Desktop/Programmering/ArtificalintelligenceModels/UNet-Model_Vocal_Isolation/Unet_model_Audio_Seperation/Model_Weights/CheckPoints/Training/checkpoint_epoch_1.pth
2025-03-24 19:30:35,393 - INFO - 
 [EPOCH 2]Model Checkpoint SAVED at epoch 2
 avg_epoch_loss: [1.221532]
 bestloss: [1.221532]
 Trigger times: 0/12

2025-03-24 19:32:03,610 - INFO - 
Trigger times: 1, patience: 20

2025-03-24 19:32:03,611 - INFO - 
Trigger times: 1, patience: 12

2025-03-24 19:32:03,611 - INFO - 
[Epoch Improvement] Epoch 2: Loss improved during training by 5.32% from previous epoch, 

2025-03-24 19:32:03,611 - INFO - ####LOGGING AVERAGE LOSS EPOCH###
[Epoch Summary] Epoch: 2/10, Avg Combined Loss: 1.221532, MaskLoss: 0.370015, Hybridloss: 0.806349Previous Epoch loss: 1.2901367664337158
2025-03-24 19:32:03,612 - INFO - Epoch: 2 COMPLETED





2025-03-24 19:32:03,613 - INFO - [Train] Epoch 3/10 started.

2025-03-24 19:32:52,151 - INFO - #####INPUTS & TARGETS VALUE [2 BATCHES]####
Batch 1: Mixture shape=torch.Size([4, 1, 513, 946]), Target shape=torch.Size([4, 1, 513, 946])
2025-03-24 19:32:54,192 - INFO - [EPOCH 3]outputs from the model torch.Size([4, 64, 513, 946])
for batch 1
predicted mask shape torch.Size([4, 1, 513, 946])
2025-03-24 19:32:55,450 - INFO - Function: [log_first_2_batches_outputs_inputs_targets_predicted_mask]
2025-03-24 19:32:55,453 - INFO - ####OUTPUTS, INPUTS, TARGETS,PREDICTEDMASK [2 BATCHES]####
Batch 1: Mask range: min=0.0000, max=3.8398
Batch 1: Inputs shape=torch.Size([4, 1, 513, 946]), Targets shape=torch.Size([4, 1, 513, 946]), Predicted Mask shape=torch.Size([4, 1, 513, 946]), Outputs shape=torch.Size([4, 64, 513, 946])
Mask min=0.395263671875, max=0.9013671875
[After Mask Application] Predicted vocals min: 0.0, max: 88.5

2025-03-24 19:32:55,453 - INFO - 
####LOSS VALUES####
[Combinedloss]:  Total treningsfeil, [BØR REDUSERES OVER TID]
[MaskLoss]: Sier hvor godt modellen lærer og predikere masken som isolerer vokaler[BØR REDUSERES OVER TID]
[l1_loss og stft_loss] gir ekstra indikasjoner på lydkvalitet.
[Hybridloss]: Kombinasjon av flere tapsfunksjoner[BØR REDUSERES OVER TID]

2025-03-24 19:32:55,474 - INFO - Appending Batch Losses: Mask: 0.29320457577705383, Hybrid: 0.7748668193817139, Combined: 1.1461890935897827
2025-03-24 19:33:03,613 - INFO - [EPOCH 3]outputs from the model torch.Size([4, 64, 513, 946])
for batch 2
predicted mask shape torch.Size([4, 1, 513, 946])
2025-03-24 19:33:04,680 - INFO - Appending Batch Losses: Mask: 0.3869583010673523, Hybrid: 0.7551963329315186, Combined: 0.8359675407409668
2025-03-24 19:33:05,976 - INFO - Appending Batch Losses: Mask: 0.3742833733558655, Hybrid: 0.70252525806427, Combined: 1.2418516874313354
2025-03-24 19:33:07,347 - INFO - Appending Batch Losses: Mask: 0.3450782895088196, Hybrid: 0.6698727607727051, Combined: 1.3688958883285522
2025-03-24 19:33:08,709 - INFO - Appending Batch Losses: Mask: 0.4265151023864746, Hybrid: 0.9426411390304565, Combined: 0.9692628383636475
2025-03-24 19:33:09,875 - INFO - Appending Batch Losses: Mask: 0.3849918246269226, Hybrid: 0.9093458652496338, Combined: 1.5746839046478271
2025-03-24 19:33:36,159 - INFO - Appending Batch Losses: Mask: 0.3908785879611969, Hybrid: 0.8035943508148193, Combined: 1.223814606666565
2025-03-24 19:33:39,346 - INFO - Appending Batch Losses: Mask: 0.3707848787307739, Hybrid: 0.9685938358306885, Combined: 1.6414618492126465
2025-03-24 19:33:40,251 - INFO - Appending Batch Losses: Mask: 0.42577648162841797, Hybrid: 0.9498839378356934, Combined: 1.1942226886749268
2025-03-24 19:33:41,585 - INFO - Appending Batch Losses: Mask: 0.30497992038726807, Hybrid: 0.7014740705490112, Combined: 1.0683817863464355
2025-03-24 19:33:49,866 - INFO - Appending Batch Losses: Mask: 0.24779769778251648, Hybrid: 0.7043145298957825, Combined: 0.8559190034866333
2025-03-24 19:33:52,222 - INFO - Appending Batch Losses: Mask: 0.33215680718421936, Hybrid: 0.6595890522003174, Combined: 1.419032335281372
2025-03-24 19:34:13,866 - INFO - Appending Batch Losses: Mask: 0.3593329191207886, Hybrid: 0.7853779792785645, Combined: 0.7407804727554321
2025-03-24 19:34:16,627 - INFO - Appending Batch Losses: Mask: 0.4372693598270416, Hybrid: 0.9687443375587463, Combined: 1.3465971946716309
2025-03-24 19:34:20,080 - INFO - Appending Batch Losses: Mask: 0.3100038468837738, Hybrid: 0.6989251375198364, Combined: 1.5537300109863281
2025-03-24 19:34:23,929 - INFO - Appending Batch Losses: Mask: 0.3641006350517273, Hybrid: 0.8416723608970642, Combined: 1.3996152877807617
2025-03-24 19:34:26,557 - INFO - Appending Batch Losses: Mask: 0.3191755414009094, Hybrid: 0.6157538890838623, Combined: 1.0429530143737793
2025-03-24 19:34:28,090 - INFO - Appending Batch Losses: Mask: 0.3134441077709198, Hybrid: 0.6324419975280762, Combined: 1.7801179885864258
2025-03-24 19:35:00,182 - INFO - Appending Batch Losses: Mask: 0.36434656381607056, Hybrid: 0.7551894187927246, Combined: 1.6141536235809326
2025-03-24 19:35:01,601 - INFO - Appending Batch Losses: Mask: 0.2962970435619354, Hybrid: 0.6081671714782715, Combined: 0.3525392413139343
2025-03-24 19:35:02,984 - INFO - Appending Batch Losses: Mask: 0.3618922233581543, Hybrid: 0.7601910829544067, Combined: 1.83579421043396
2025-03-24 19:35:04,447 - INFO - Appending Batch Losses: Mask: 0.30453383922576904, Hybrid: 0.6425979137420654, Combined: 1.4443495273590088
2025-03-24 19:35:06,375 - INFO - Appending Batch Losses: Mask: 0.34728556871414185, Hybrid: 0.703496515750885, Combined: 1.103318214416504
2025-03-24 19:35:07,843 - INFO - Appending Batch Losses: Mask: 0.3558286130428314, Hybrid: 0.7725822925567627, Combined: 1.5228607654571533
2025-03-24 19:35:26,558 - INFO - Appending Batch Losses: Mask: 0.45750945806503296, Hybrid: 1.1335065364837646, Combined: 1.527639627456665
2025-03-24 19:35:28,606 - INFO - Current Learning Rate 0.0005768473633077474

2025-03-24 19:35:28,607 - INFO - 
[EPOCH 3]No improvement, NO NEW MODEL CHECKPOINT SAVED at epoch 3
 avg_epoch_loss: [1.272165]
 bestloss: [1.221532]
 Trigger: 2/12

2025-03-24 19:36:48,491 - INFO - 
Trigger times: 0, patience: 20

2025-03-24 19:36:48,492 - INFO - 
Trigger times: 0, patience: 12

2025-03-24 19:36:48,492 - INFO - 
[Epoch Improvement] Epoch 3: Loss improved during training by -4.15% from previous epoch, 

2025-03-24 19:36:48,492 - INFO - ####LOGGING AVERAGE LOSS EPOCH###
[Epoch Summary] Epoch: 3/10, Avg Combined Loss: 1.272165, MaskLoss: 0.365003, Hybridloss: 0.797040Previous Epoch loss: 1.2215321493148803
2025-03-24 19:36:48,493 - INFO - Epoch: 3 COMPLETED





2025-03-24 19:36:48,498 - INFO - [Train] Epoch 4/10 started.

2025-03-24 19:37:31,511 - INFO - #####INPUTS & TARGETS VALUE [2 BATCHES]####
Batch 1: Mixture shape=torch.Size([4, 1, 513, 946]), Target shape=torch.Size([4, 1, 513, 946])
2025-03-24 19:37:32,528 - INFO - [EPOCH 4]outputs from the model torch.Size([4, 64, 513, 946])
for batch 1
predicted mask shape torch.Size([4, 1, 513, 946])
2025-03-24 19:37:33,620 - INFO - Function: [log_first_2_batches_outputs_inputs_targets_predicted_mask]
2025-03-24 19:37:33,624 - INFO - ####OUTPUTS, INPUTS, TARGETS,PREDICTEDMASK [2 BATCHES]####
Batch 1: Mask range: min=0.0000, max=2.8848
Batch 1: Inputs shape=torch.Size([4, 1, 513, 946]), Targets shape=torch.Size([4, 1, 513, 946]), Predicted Mask shape=torch.Size([4, 1, 513, 946]), Outputs shape=torch.Size([4, 64, 513, 946])
Mask min=0.404296875, max=0.85498046875
[After Mask Application] Predicted vocals min: 0.0, max: 81.4375

2025-03-24 19:37:33,624 - INFO - 
####LOSS VALUES####
[Combinedloss]:  Total treningsfeil, [BØR REDUSERES OVER TID]
[MaskLoss]: Sier hvor godt modellen lærer og predikere masken som isolerer vokaler[BØR REDUSERES OVER TID]
[l1_loss og stft_loss] gir ekstra indikasjoner på lydkvalitet.
[Hybridloss]: Kombinasjon av flere tapsfunksjoner[BØR REDUSERES OVER TID]

2025-03-24 19:37:33,663 - INFO - Appending Batch Losses: Mask: 0.3619629740715027, Hybrid: 0.7358499765396118, Combined: 0.753691554069519
2025-03-24 19:37:34,972 - INFO - [EPOCH 4]outputs from the model torch.Size([4, 64, 513, 946])
for batch 2
predicted mask shape torch.Size([4, 1, 513, 946])
2025-03-24 19:37:36,000 - INFO - Appending Batch Losses: Mask: 0.3553345799446106, Hybrid: 0.6571824550628662, Combined: 0.9289321899414062
2025-03-24 19:37:37,493 - INFO - Appending Batch Losses: Mask: 0.38615575432777405, Hybrid: 0.8839093446731567, Combined: 1.2276742458343506
2025-03-24 19:37:39,136 - INFO - Appending Batch Losses: Mask: 0.3693774938583374, Hybrid: 0.8086280822753906, Combined: 1.5329618453979492
2025-03-24 19:37:40,714 - INFO - Appending Batch Losses: Mask: 0.3440113067626953, Hybrid: 0.8116985559463501, Combined: 1.4085981845855713
2025-03-24 19:37:42,641 - INFO - Appending Batch Losses: Mask: 0.4519624710083008, Hybrid: 0.8562995195388794, Combined: 1.7361481189727783
2025-03-24 19:38:13,781 - INFO - Appending Batch Losses: Mask: 0.411926805973053, Hybrid: 0.8693913221359253, Combined: 1.859037160873413
2025-03-24 19:38:15,387 - INFO - Appending Batch Losses: Mask: 0.28440773487091064, Hybrid: 0.6054003834724426, Combined: 1.35150146484375
2025-03-24 19:38:17,042 - INFO - Appending Batch Losses: Mask: 0.3220425844192505, Hybrid: 0.8029853105545044, Combined: 1.2085812091827393
2025-03-24 19:38:19,980 - INFO - Appending Batch Losses: Mask: 0.38995927572250366, Hybrid: 0.9003287553787231, Combined: 1.115899682044983
2025-03-24 19:38:21,585 - INFO - Appending Batch Losses: Mask: 0.3411286473274231, Hybrid: 0.8410135507583618, Combined: 1.6503117084503174
2025-03-24 19:38:23,110 - INFO - Appending Batch Losses: Mask: 0.37307316064834595, Hybrid: 0.6935429573059082, Combined: 1.1444966793060303
2025-03-24 19:39:06,378 - INFO - Appending Batch Losses: Mask: 0.4115878641605377, Hybrid: 0.900885283946991, Combined: 0.965640127658844
2025-03-24 19:39:08,956 - INFO - Appending Batch Losses: Mask: 0.3658400774002075, Hybrid: 0.6871547698974609, Combined: 0.4261492192745209
2025-03-24 19:39:21,224 - INFO - Appending Batch Losses: Mask: 0.434739351272583, Hybrid: 0.8706287145614624, Combined: 1.7668347358703613
2025-03-24 19:39:23,748 - INFO - Appending Batch Losses: Mask: 0.42565521597862244, Hybrid: 0.8298666477203369, Combined: 1.2708473205566406
2025-03-24 19:39:26,193 - INFO - Appending Batch Losses: Mask: 0.3308449983596802, Hybrid: 0.7103737592697144, Combined: 1.5689191818237305
2025-03-24 19:39:31,532 - INFO - Appending Batch Losses: Mask: 0.40459609031677246, Hybrid: 0.8127791881561279, Combined: 1.371619462966919
2025-03-24 19:39:43,167 - INFO - Appending Batch Losses: Mask: 0.3913927674293518, Hybrid: 0.8762454986572266, Combined: 1.6338179111480713
2025-03-24 19:39:44,082 - INFO - Appending Batch Losses: Mask: 0.3573668897151947, Hybrid: 0.7530717849731445, Combined: 1.131096601486206
2025-03-24 19:39:45,142 - INFO - Appending Batch Losses: Mask: 0.2940611243247986, Hybrid: 0.6545827984809875, Combined: 0.8018271923065186
2025-03-24 19:39:46,624 - INFO - Appending Batch Losses: Mask: 0.32127535343170166, Hybrid: 0.7423312067985535, Combined: 0.7257968187332153
2025-03-24 19:39:48,218 - INFO - Appending Batch Losses: Mask: 0.29764431715011597, Hybrid: 0.6104427576065063, Combined: 1.6518205404281616
2025-03-24 19:39:49,303 - INFO - Appending Batch Losses: Mask: 0.38330233097076416, Hybrid: 0.770643413066864, Combined: 1.125134825706482
2025-03-24 19:40:03,203 - INFO - Appending Batch Losses: Mask: 0.3274485170841217, Hybrid: 0.708396852016449, Combined: 1.048441767692566
2025-03-24 19:40:04,992 - INFO - Current Learning Rate 0.000607612060951754

2025-03-24 19:40:04,992 - INFO - 
[EPOCH 4]No improvement, NO NEW MODEL CHECKPOINT SAVED at epoch 4
 avg_epoch_loss: [1.256231]
 bestloss: [1.221532]
 Trigger: 1/12

2025-03-24 19:41:26,157 - INFO - 
Trigger times: 1, patience: 20

2025-03-24 19:41:26,158 - INFO - 
Trigger times: 1, patience: 12

2025-03-24 19:41:26,158 - INFO - 
[Epoch Improvement] Epoch 4: Loss improved during training by 1.25% from previous epoch, 

2025-03-24 19:41:26,158 - INFO - ####LOGGING AVERAGE LOSS EPOCH###
[Epoch Summary] Epoch: 4/10, Avg Combined Loss: 1.256231, MaskLoss: 0.365123, Hybridloss: 0.791716Previous Epoch loss: 1.2721652960777283
2025-03-24 19:41:26,159 - INFO - Epoch: 4 COMPLETED





2025-03-24 19:41:26,159 - INFO - [Train] Epoch 5/10 started.

2025-03-24 19:42:10,265 - INFO - #####INPUTS & TARGETS VALUE [2 BATCHES]####
Batch 1: Mixture shape=torch.Size([4, 1, 513, 946]), Target shape=torch.Size([4, 1, 513, 946])
2025-03-24 19:42:12,272 - INFO - [EPOCH 5]outputs from the model torch.Size([4, 64, 513, 946])
for batch 1
predicted mask shape torch.Size([4, 1, 513, 946])
2025-03-24 19:42:13,808 - INFO - Function: [log_first_2_batches_outputs_inputs_targets_predicted_mask]
2025-03-24 19:42:13,811 - INFO - ####OUTPUTS, INPUTS, TARGETS,PREDICTEDMASK [2 BATCHES]####
Batch 1: Mask range: min=0.0000, max=3.1445
Batch 1: Inputs shape=torch.Size([4, 1, 513, 946]), Targets shape=torch.Size([4, 1, 513, 946]), Predicted Mask shape=torch.Size([4, 1, 513, 946]), Outputs shape=torch.Size([4, 64, 513, 946])
Mask min=0.3876953125, max=0.8330078125
[After Mask Application] Predicted vocals min: 0.0, max: 77.9375

2025-03-24 19:42:13,811 - INFO - 
####LOSS VALUES####
[Combinedloss]:  Total treningsfeil, [BØR REDUSERES OVER TID]
[MaskLoss]: Sier hvor godt modellen lærer og predikere masken som isolerer vokaler[BØR REDUSERES OVER TID]
[l1_loss og stft_loss] gir ekstra indikasjoner på lydkvalitet.
[Hybridloss]: Kombinasjon av flere tapsfunksjoner[BØR REDUSERES OVER TID]

2025-03-24 19:42:13,823 - INFO - Appending Batch Losses: Mask: 0.38432344794273376, Hybrid: 0.9038206934928894, Combined: 1.0232231616973877
2025-03-24 19:42:35,831 - INFO - [EPOCH 5]outputs from the model torch.Size([4, 64, 513, 946])
for batch 2
predicted mask shape torch.Size([4, 1, 513, 946])
2025-03-24 19:42:36,791 - INFO - Appending Batch Losses: Mask: 0.3862513303756714, Hybrid: 0.8327655792236328, Combined: 1.4660625457763672
2025-03-24 19:42:38,825 - INFO - Appending Batch Losses: Mask: 0.4085290729999542, Hybrid: 0.9210494756698608, Combined: 1.5340099334716797
2025-03-24 19:42:39,986 - INFO - Appending Batch Losses: Mask: 0.45351168513298035, Hybrid: 0.8345056772232056, Combined: 1.6655657291412354
2025-03-24 19:42:43,791 - INFO - Appending Batch Losses: Mask: 0.3821616470813751, Hybrid: 0.8363116979598999, Combined: 1.256820797920227
2025-03-24 19:42:47,860 - INFO - Appending Batch Losses: Mask: 0.4342191815376282, Hybrid: 0.9077585935592651, Combined: 1.420078992843628
2025-03-24 19:42:49,073 - INFO - Appending Batch Losses: Mask: 0.3650723695755005, Hybrid: 0.8029539585113525, Combined: 0.7634395956993103
2025-03-24 19:43:20,976 - INFO - Appending Batch Losses: Mask: 0.3120630979537964, Hybrid: 0.7451796531677246, Combined: 0.835918664932251
2025-03-24 19:43:23,502 - INFO - Appending Batch Losses: Mask: 0.33440086245536804, Hybrid: 0.7356159687042236, Combined: 1.086103081703186
2025-03-24 19:43:27,887 - INFO - Appending Batch Losses: Mask: 0.4276182949542999, Hybrid: 0.9557536840438843, Combined: 1.2976075410842896
2025-03-24 19:43:29,122 - INFO - Appending Batch Losses: Mask: 0.4342784583568573, Hybrid: 1.0686768293380737, Combined: 1.611656904220581
2025-03-24 19:43:32,870 - INFO - Appending Batch Losses: Mask: 0.2850855886936188, Hybrid: 0.6486877202987671, Combined: 1.0676190853118896
2025-03-24 19:43:35,757 - INFO - Appending Batch Losses: Mask: 0.4007081389427185, Hybrid: 0.8191268444061279, Combined: 1.3761191368103027
2025-03-24 19:44:04,655 - INFO - Appending Batch Losses: Mask: 0.3979730010032654, Hybrid: 0.8440894484519958, Combined: 0.4483241140842438
2025-03-24 19:44:07,412 - INFO - Appending Batch Losses: Mask: 0.42763200402259827, Hybrid: 0.9284166097640991, Combined: 1.1025272607803345
2025-03-24 19:44:08,429 - INFO - Appending Batch Losses: Mask: 0.47246605157852173, Hybrid: 0.8540422916412354, Combined: 1.584601640701294
2025-03-24 19:44:10,269 - INFO - Appending Batch Losses: Mask: 0.3525489270687103, Hybrid: 0.7212016582489014, Combined: 0.9460315704345703
2025-03-24 19:44:13,011 - INFO - Appending Batch Losses: Mask: 0.4568910300731659, Hybrid: 1.0308204889297485, Combined: 1.7095386981964111
2025-03-24 19:44:14,284 - INFO - Appending Batch Losses: Mask: 0.25624895095825195, Hybrid: 0.5740379095077515, Combined: 1.6051691770553589
2025-03-24 19:44:47,103 - INFO - Appending Batch Losses: Mask: 0.4071963429450989, Hybrid: 1.0184366703033447, Combined: 0.8506308794021606
2025-03-24 19:44:48,689 - INFO - Appending Batch Losses: Mask: 0.35724201798439026, Hybrid: 0.6965672969818115, Combined: 1.5432147979736328
2025-03-24 19:44:51,750 - INFO - Appending Batch Losses: Mask: 0.33437708020210266, Hybrid: 0.7144845724105835, Combined: 0.9105907082557678
2025-03-24 19:44:53,713 - INFO - Appending Batch Losses: Mask: 0.28005698323249817, Hybrid: 0.605992317199707, Combined: 1.127417802810669
2025-03-24 19:44:55,839 - INFO - Appending Batch Losses: Mask: 0.37315842509269714, Hybrid: 0.7232788801193237, Combined: 1.2331459522247314
2025-03-24 19:45:09,676 - INFO - Appending Batch Losses: Mask: 0.38154497742652893, Hybrid: 0.8352077007293701, Combined: 1.1758131980895996
2025-03-24 19:45:11,782 - INFO - Current Learning Rate 0.0006342616542242586

2025-03-24 19:45:11,783 - INFO - 
[EPOCH 5]No improvement, NO NEW MODEL CHECKPOINT SAVED at epoch 5
 avg_epoch_loss: [1.225649]
 bestloss: [1.221532]
 Trigger: 2/12

2025-03-24 19:46:30,198 - INFO - 
Trigger times: 0, patience: 20

2025-03-24 19:46:30,199 - INFO - 
Trigger times: 0, patience: 12

2025-03-24 19:46:30,199 - INFO - 
[Epoch Improvement] Epoch 5: Loss improved during training by 2.43% from previous epoch, 

2025-03-24 19:46:30,200 - INFO - ####LOGGING AVERAGE LOSS EPOCH###
[Epoch Summary] Epoch: 5/10, Avg Combined Loss: 1.225649, MaskLoss: 0.368143, Hybridloss: 0.797843Previous Epoch loss: 1.2562311899662018
2025-03-24 19:46:30,200 - INFO - Epoch: 5 COMPLETED





2025-03-24 19:46:30,201 - INFO - [Train] Epoch 6/10 started.

2025-03-24 19:47:18,383 - INFO - #####INPUTS & TARGETS VALUE [2 BATCHES]####
Batch 1: Mixture shape=torch.Size([4, 1, 513, 946]), Target shape=torch.Size([4, 1, 513, 946])
2025-03-24 19:47:20,202 - INFO - [EPOCH 6]outputs from the model torch.Size([4, 64, 513, 946])
for batch 1
predicted mask shape torch.Size([4, 1, 513, 946])
2025-03-24 19:47:21,127 - INFO - Function: [log_first_2_batches_outputs_inputs_targets_predicted_mask]
2025-03-24 19:47:21,130 - INFO - ####OUTPUTS, INPUTS, TARGETS,PREDICTEDMASK [2 BATCHES]####
Batch 1: Mask range: min=0.0000, max=2.3965
Batch 1: Inputs shape=torch.Size([4, 1, 513, 946]), Targets shape=torch.Size([4, 1, 513, 946]), Predicted Mask shape=torch.Size([4, 1, 513, 946]), Outputs shape=torch.Size([4, 64, 513, 946])
Mask min=0.40625, max=0.83642578125
[After Mask Application] Predicted vocals min: 0.0, max: 66.875

2025-03-24 19:47:21,130 - INFO - 
####LOSS VALUES####
[Combinedloss]:  Total treningsfeil, [BØR REDUSERES OVER TID]
[MaskLoss]: Sier hvor godt modellen lærer og predikere masken som isolerer vokaler[BØR REDUSERES OVER TID]
[l1_loss og stft_loss] gir ekstra indikasjoner på lydkvalitet.
[Hybridloss]: Kombinasjon av flere tapsfunksjoner[BØR REDUSERES OVER TID]

2025-03-24 19:47:21,146 - INFO - Appending Batch Losses: Mask: 0.398305743932724, Hybrid: 0.9799388647079468, Combined: 1.6846816539764404
2025-03-24 19:47:22,187 - INFO - [EPOCH 6]outputs from the model torch.Size([4, 64, 513, 946])
for batch 2
predicted mask shape torch.Size([4, 1, 513, 946])
2025-03-24 19:47:23,362 - INFO - Appending Batch Losses: Mask: 0.42059412598609924, Hybrid: 0.8245589733123779, Combined: 1.2352665662765503
2025-03-24 19:47:24,397 - INFO - Appending Batch Losses: Mask: 0.3635302186012268, Hybrid: 0.7713104486465454, Combined: 1.1449127197265625
2025-03-24 19:47:26,486 - INFO - Appending Batch Losses: Mask: 0.29230546951293945, Hybrid: 0.7105562686920166, Combined: 1.8079884052276611
2025-03-24 19:47:28,338 - INFO - Appending Batch Losses: Mask: 0.36853331327438354, Hybrid: 0.8741558790206909, Combined: 1.9351797103881836
2025-03-24 19:47:30,191 - INFO - Appending Batch Losses: Mask: 0.3115113377571106, Hybrid: 0.6727416515350342, Combined: 0.5131462216377258
2025-03-24 19:47:57,100 - INFO - Appending Batch Losses: Mask: 0.5083034038543701, Hybrid: 1.024884819984436, Combined: 0.7809661626815796
2025-03-24 19:47:58,945 - INFO - Appending Batch Losses: Mask: 0.26088064908981323, Hybrid: 0.7820956707000732, Combined: 1.5507009029388428
2025-03-24 19:48:00,764 - INFO - Appending Batch Losses: Mask: 0.29859745502471924, Hybrid: 0.6989800333976746, Combined: 0.34594544768333435
2025-03-24 19:48:02,605 - INFO - Appending Batch Losses: Mask: 0.3091350197792053, Hybrid: 0.7108745574951172, Combined: 0.3484936058521271
2025-03-24 19:48:07,216 - INFO - Appending Batch Losses: Mask: 0.35907885432243347, Hybrid: 0.7549412250518799, Combined: 0.7767484188079834
2025-03-24 19:48:09,266 - INFO - Appending Batch Losses: Mask: 0.3158371150493622, Hybrid: 0.7139467000961304, Combined: 0.9826700687408447
2025-03-24 19:48:26,544 - INFO - Appending Batch Losses: Mask: 0.31207844614982605, Hybrid: 0.7209726572036743, Combined: 1.4492019414901733
2025-03-24 19:48:29,944 - INFO - Appending Batch Losses: Mask: 0.4279172420501709, Hybrid: 0.8973785042762756, Combined: 1.8602256774902344
2025-03-24 19:48:31,826 - INFO - Appending Batch Losses: Mask: 0.4032578766345978, Hybrid: 0.8207151889801025, Combined: 1.270774483680725
2025-03-24 19:48:33,667 - INFO - Appending Batch Losses: Mask: 0.3557378649711609, Hybrid: 0.6589081883430481, Combined: 0.8727389574050903
2025-03-24 19:48:43,775 - INFO - Appending Batch Losses: Mask: 0.4179740846157074, Hybrid: 0.963726282119751, Combined: 1.5237948894500732
2025-03-24 19:48:45,616 - INFO - Appending Batch Losses: Mask: 0.411126971244812, Hybrid: 0.8040358424186707, Combined: 1.4488158226013184
2025-03-24 19:48:53,868 - INFO - Appending Batch Losses: Mask: 0.3618592321872711, Hybrid: 0.8243697881698608, Combined: 0.9943869709968567
2025-03-24 19:49:01,491 - INFO - Appending Batch Losses: Mask: 0.46769338846206665, Hybrid: 0.917705774307251, Combined: 1.2671597003936768
2025-03-24 19:49:02,402 - INFO - Appending Batch Losses: Mask: 0.32097727060317993, Hybrid: 0.7023332118988037, Combined: 0.8629812598228455
2025-03-24 19:49:11,047 - INFO - Appending Batch Losses: Mask: 0.3479745388031006, Hybrid: 0.7125792503356934, Combined: 0.6751701235771179
2025-03-24 19:49:20,284 - INFO - Appending Batch Losses: Mask: 0.3614773154258728, Hybrid: 1.0294404029846191, Combined: 1.7904107570648193
2025-03-24 19:49:21,197 - INFO - Appending Batch Losses: Mask: 0.3147639036178589, Hybrid: 0.8136904835700989, Combined: 1.807943344116211
2025-03-24 19:49:22,098 - INFO - Appending Batch Losses: Mask: 0.445085734128952, Hybrid: 0.8841196298599243, Combined: 1.2185577154159546
2025-03-24 19:49:23,801 - INFO - Current Learning Rate 0.0006577682614193902

2025-03-24 19:49:25,257 - INFO - Checkpoint saved: /mnt/c/Users/didri/Desktop/Programmering/ArtificalintelligenceModels/UNet-Model_Vocal_Isolation/Unet_model_Audio_Seperation/Model_Weights/CheckPoints/Training/checkpoint_epoch_5.pth
2025-03-24 19:49:25,257 - INFO - 
 [EPOCH 6]Model Checkpoint SAVED at epoch 6
 avg_epoch_loss: [1.205954]
 bestloss: [1.205954]
 Trigger times: 0/12

2025-03-24 19:50:36,501 - INFO - 
Trigger times: 1, patience: 20

2025-03-24 19:50:36,502 - INFO - 
Trigger times: 1, patience: 12

2025-03-24 19:50:36,502 - INFO - 
[Epoch Improvement] Epoch 6: Loss improved during training by 1.61% from previous epoch, 

2025-03-24 19:50:36,502 - INFO - ####LOGGING AVERAGE LOSS EPOCH###
[Epoch Summary] Epoch: 6/10, Avg Combined Loss: 1.205954, MaskLoss: 0.367816, Hybridloss: 0.799996Previous Epoch loss: 1.2256492388248443
2025-03-24 19:50:36,503 - INFO - Epoch: 6 COMPLETED





2025-03-24 19:50:36,504 - INFO - [Train] Epoch 7/10 started.

2025-03-24 19:51:18,669 - INFO - #####INPUTS & TARGETS VALUE [2 BATCHES]####
Batch 1: Mixture shape=torch.Size([4, 1, 513, 946]), Target shape=torch.Size([4, 1, 513, 946])
2025-03-24 19:51:19,918 - INFO - [EPOCH 7]outputs from the model torch.Size([4, 64, 513, 946])
for batch 1
predicted mask shape torch.Size([4, 1, 513, 946])
2025-03-24 19:51:21,192 - INFO - Function: [log_first_2_batches_outputs_inputs_targets_predicted_mask]
2025-03-24 19:51:21,195 - INFO - ####OUTPUTS, INPUTS, TARGETS,PREDICTEDMASK [2 BATCHES]####
Batch 1: Mask range: min=0.0000, max=2.9941
Batch 1: Inputs shape=torch.Size([4, 1, 513, 946]), Targets shape=torch.Size([4, 1, 513, 946]), Predicted Mask shape=torch.Size([4, 1, 513, 946]), Outputs shape=torch.Size([4, 64, 513, 946])
Mask min=0.369873046875, max=0.87353515625
[After Mask Application] Predicted vocals min: 0.0, max: 80.1875

2025-03-24 19:51:21,195 - INFO - 
####LOSS VALUES####
[Combinedloss]:  Total treningsfeil, [BØR REDUSERES OVER TID]
[MaskLoss]: Sier hvor godt modellen lærer og predikere masken som isolerer vokaler[BØR REDUSERES OVER TID]
[l1_loss og stft_loss] gir ekstra indikasjoner på lydkvalitet.
[Hybridloss]: Kombinasjon av flere tapsfunksjoner[BØR REDUSERES OVER TID]

2025-03-24 19:51:21,210 - INFO - Appending Batch Losses: Mask: 0.3155710697174072, Hybrid: 0.6615266799926758, Combined: 1.4216547012329102
2025-03-24 19:51:25,661 - INFO - [EPOCH 7]outputs from the model torch.Size([3, 64, 513, 946])
for batch 2
predicted mask shape torch.Size([3, 1, 513, 946])
2025-03-24 19:51:27,102 - INFO - Appending Batch Losses: Mask: 0.3092082738876343, Hybrid: 0.6856991052627563, Combined: 0.7845653295516968
2025-03-24 19:51:28,924 - INFO - Appending Batch Losses: Mask: 0.3052991032600403, Hybrid: 0.6640169024467468, Combined: 0.21813258528709412
2025-03-24 19:51:29,874 - INFO - Appending Batch Losses: Mask: 0.43018338084220886, Hybrid: 0.8603098392486572, Combined: 1.0206798315048218
2025-03-24 19:51:30,871 - INFO - Appending Batch Losses: Mask: 0.4461714029312134, Hybrid: 0.9026532769203186, Combined: 1.6444482803344727
2025-03-24 19:51:31,833 - INFO - Appending Batch Losses: Mask: 0.3272329270839691, Hybrid: 0.7110841870307922, Combined: 0.7469523549079895
2025-03-24 19:51:54,772 - INFO - Appending Batch Losses: Mask: 0.38179799914360046, Hybrid: 0.7503910064697266, Combined: 1.5580253601074219
2025-03-24 19:51:58,865 - INFO - Appending Batch Losses: Mask: 0.40548503398895264, Hybrid: 0.9478408098220825, Combined: 1.2140694856643677
2025-03-24 19:51:59,943 - INFO - Appending Batch Losses: Mask: 0.28606489300727844, Hybrid: 0.618430495262146, Combined: 0.8837087154388428
2025-03-24 19:52:00,962 - INFO - Appending Batch Losses: Mask: 0.3499357998371124, Hybrid: 0.8572791814804077, Combined: 1.715168833732605
2025-03-24 19:52:04,085 - INFO - Appending Batch Losses: Mask: 0.30001482367515564, Hybrid: 0.6990415453910828, Combined: 1.5305651426315308
2025-03-24 19:52:06,409 - INFO - Appending Batch Losses: Mask: 0.45789846777915955, Hybrid: 1.004364252090454, Combined: 1.2025668621063232
2025-03-24 19:52:26,635 - INFO - Appending Batch Losses: Mask: 0.5224102139472961, Hybrid: 1.1744532585144043, Combined: 0.6650689840316772
2025-03-24 19:52:38,112 - INFO - Appending Batch Losses: Mask: 0.40728288888931274, Hybrid: 0.8843610882759094, Combined: 1.4099900722503662
2025-03-24 19:52:41,225 - INFO - Appending Batch Losses: Mask: 0.35729560256004333, Hybrid: 0.7979694604873657, Combined: 1.2353243827819824
2025-03-24 19:52:43,924 - INFO - Appending Batch Losses: Mask: 0.3138704299926758, Hybrid: 0.7743085622787476, Combined: 1.9469735622406006
2025-03-24 19:52:55,695 - INFO - Appending Batch Losses: Mask: 0.34908586740493774, Hybrid: 0.849949836730957, Combined: 2.1820545196533203
2025-03-24 19:52:58,523 - INFO - Appending Batch Losses: Mask: 0.4330832362174988, Hybrid: 0.9772303104400635, Combined: 2.6662633419036865
2025-03-24 19:53:03,862 - INFO - Appending Batch Losses: Mask: 0.3133465051651001, Hybrid: 0.6912044286727905, Combined: 1.2931737899780273
2025-03-24 19:53:23,651 - INFO - Appending Batch Losses: Mask: 0.41125842928886414, Hybrid: 1.1347291469573975, Combined: 1.6487314701080322
2025-03-24 19:53:26,079 - INFO - Appending Batch Losses: Mask: 0.3376605212688446, Hybrid: 0.7761386632919312, Combined: 1.317469835281372
2025-03-24 19:53:28,354 - INFO - Appending Batch Losses: Mask: 0.3555499017238617, Hybrid: 0.7276293039321899, Combined: 0.9642641544342041
2025-03-24 19:53:30,662 - INFO - Appending Batch Losses: Mask: 0.3711508810520172, Hybrid: 0.7809497714042664, Combined: 1.6983155012130737
2025-03-24 19:53:32,823 - INFO - Appending Batch Losses: Mask: 0.2861331105232239, Hybrid: 0.5845658779144287, Combined: 0.6367562413215637
2025-03-24 19:53:35,076 - INFO - Appending Batch Losses: Mask: 0.3233892321586609, Hybrid: 0.7692713737487793, Combined: 1.668691873550415
2025-03-24 19:53:37,017 - INFO - Current Learning Rate 0.0006787956380839754

2025-03-24 19:53:37,017 - INFO - 
[EPOCH 7]No improvement, NO NEW MODEL CHECKPOINT SAVED at epoch 7
 avg_epoch_loss: [1.330945]
 bestloss: [1.205954]
 Trigger: 2/12

2025-03-24 19:55:13,916 - INFO - 
Trigger times: 2, patience: 20

2025-03-24 19:55:13,917 - INFO - 
Trigger times: 2, patience: 12

2025-03-24 19:55:13,917 - INFO - 
[Epoch Improvement] Epoch 7: Loss improved during training by -10.36% from previous epoch, 

2025-03-24 19:55:13,917 - INFO - ####LOGGING AVERAGE LOSS EPOCH###
[Epoch Summary] Epoch: 7/10, Avg Combined Loss: 1.330945, MaskLoss: 0.367250, Hybridloss: 0.801627Previous Epoch loss: 1.2059544610977173
2025-03-24 19:55:13,918 - INFO - Epoch: 7 COMPLETED





2025-03-24 19:55:13,918 - INFO - [Train] Epoch 8/10 started.

2025-03-24 19:55:59,615 - INFO - #####INPUTS & TARGETS VALUE [2 BATCHES]####
Batch 1: Mixture shape=torch.Size([4, 1, 513, 946]), Target shape=torch.Size([4, 1, 513, 946])
2025-03-24 19:56:01,003 - INFO - [EPOCH 8]outputs from the model torch.Size([4, 64, 513, 946])
for batch 1
predicted mask shape torch.Size([4, 1, 513, 946])
2025-03-24 19:56:01,997 - INFO - Function: [log_first_2_batches_outputs_inputs_targets_predicted_mask]
2025-03-24 19:56:02,000 - INFO - ####OUTPUTS, INPUTS, TARGETS,PREDICTEDMASK [2 BATCHES]####
Batch 1: Mask range: min=0.0000, max=3.7168
Batch 1: Inputs shape=torch.Size([4, 1, 513, 946]), Targets shape=torch.Size([4, 1, 513, 946]), Predicted Mask shape=torch.Size([4, 1, 513, 946]), Outputs shape=torch.Size([4, 64, 513, 946])
Mask min=0.373779296875, max=0.9228515625
[After Mask Application] Predicted vocals min: 0.0, max: 68.0625

2025-03-24 19:56:02,000 - INFO - 
####LOSS VALUES####
[Combinedloss]:  Total treningsfeil, [BØR REDUSERES OVER TID]
[MaskLoss]: Sier hvor godt modellen lærer og predikere masken som isolerer vokaler[BØR REDUSERES OVER TID]
[l1_loss og stft_loss] gir ekstra indikasjoner på lydkvalitet.
[Hybridloss]: Kombinasjon av flere tapsfunksjoner[BØR REDUSERES OVER TID]

2025-03-24 19:56:02,025 - INFO - Appending Batch Losses: Mask: 0.3422078490257263, Hybrid: 0.720201849937439, Combined: 1.0345996618270874
2025-03-24 19:56:03,262 - INFO - [EPOCH 8]outputs from the model torch.Size([4, 64, 513, 946])
for batch 2
predicted mask shape torch.Size([4, 1, 513, 946])
2025-03-24 19:56:04,276 - INFO - Appending Batch Losses: Mask: 0.3704177737236023, Hybrid: 0.6969966292381287, Combined: 0.7362343668937683
2025-03-24 19:56:05,213 - INFO - Appending Batch Losses: Mask: 0.3608055114746094, Hybrid: 0.7596075534820557, Combined: 0.7909577488899231
2025-03-24 19:56:14,940 - INFO - Appending Batch Losses: Mask: 0.33927613496780396, Hybrid: 0.7399212718009949, Combined: 0.6292532682418823
2025-03-24 19:56:16,202 - INFO - Appending Batch Losses: Mask: 0.3973119258880615, Hybrid: 0.7270197868347168, Combined: 1.8788011074066162
2025-03-24 19:56:17,260 - INFO - Appending Batch Losses: Mask: 0.25864678621292114, Hybrid: 0.6653657555580139, Combined: 1.044688105583191
2025-03-24 19:56:40,059 - INFO - Appending Batch Losses: Mask: 0.36113932728767395, Hybrid: 0.7459194660186768, Combined: 0.5614277720451355
2025-03-24 19:56:41,001 - INFO - Appending Batch Losses: Mask: 0.421073317527771, Hybrid: 0.8793230652809143, Combined: 1.4028514623641968
2025-03-24 19:56:41,952 - INFO - Appending Batch Losses: Mask: 0.4794279634952545, Hybrid: 1.026858925819397, Combined: 1.4557163715362549
2025-03-24 19:56:54,009 - INFO - Appending Batch Losses: Mask: 0.3471336364746094, Hybrid: 0.7818917036056519, Combined: 1.5772099494934082
2025-03-24 19:56:54,941 - INFO - Appending Batch Losses: Mask: 0.35070735216140747, Hybrid: 0.8439419269561768, Combined: 0.8297615051269531
2025-03-24 19:56:55,883 - INFO - Appending Batch Losses: Mask: 0.417841374874115, Hybrid: 0.8163822889328003, Combined: 1.4112815856933594
2025-03-24 19:57:25,092 - INFO - Appending Batch Losses: Mask: 0.33005431294441223, Hybrid: 0.7232149839401245, Combined: 1.0613634586334229
2025-03-24 19:57:26,371 - INFO - Appending Batch Losses: Mask: 0.40854793787002563, Hybrid: 0.7982437014579773, Combined: 1.5819061994552612
2025-03-24 19:57:27,801 - INFO - Appending Batch Losses: Mask: 0.3504635989665985, Hybrid: 0.8365410566329956, Combined: 1.220481276512146
2025-03-24 19:57:53,300 - INFO - Appending Batch Losses: Mask: 0.448245108127594, Hybrid: 0.9731490612030029, Combined: 2.121702194213867
2025-03-24 19:57:54,319 - INFO - Appending Batch Losses: Mask: 0.2651214897632599, Hybrid: 0.5235645771026611, Combined: 0.9248055219650269
2025-03-24 19:57:56,187 - INFO - Appending Batch Losses: Mask: 0.34737786650657654, Hybrid: 0.7643179893493652, Combined: 1.2851722240447998
2025-03-24 19:58:10,664 - INFO - Appending Batch Losses: Mask: 0.3661191165447235, Hybrid: 0.681480884552002, Combined: 0.5568933486938477
2025-03-24 19:58:11,598 - INFO - Appending Batch Losses: Mask: 0.3657188415527344, Hybrid: 0.789728045463562, Combined: 0.7357352375984192
2025-03-24 19:58:12,531 - INFO - Appending Batch Losses: Mask: 0.38897430896759033, Hybrid: 0.9845371246337891, Combined: 2.073310613632202
2025-03-24 19:58:29,506 - INFO - Appending Batch Losses: Mask: 0.44483232498168945, Hybrid: 1.209354043006897, Combined: 1.4069011211395264
2025-03-24 19:58:30,628 - INFO - Appending Batch Losses: Mask: 0.3875054121017456, Hybrid: 0.7792144417762756, Combined: 1.4682352542877197
2025-03-24 19:58:31,693 - INFO - Appending Batch Losses: Mask: 0.41430801153182983, Hybrid: 0.8278038501739502, Combined: 1.3292863368988037
2025-03-24 19:58:51,195 - INFO - Appending Batch Losses: Mask: 0.3196362555027008, Hybrid: 0.818056583404541, Combined: 0.8378824591636658
2025-03-24 19:58:53,023 - INFO - Current Learning Rate 0.0006978172140339599

2025-03-24 19:58:54,565 - INFO - Checkpoint saved: /mnt/c/Users/didri/Desktop/Programmering/ArtificalintelligenceModels/UNet-Model_Vocal_Isolation/Unet_model_Audio_Seperation/Model_Weights/CheckPoints/Training/checkpoint_epoch_7.pth
2025-03-24 19:58:54,565 - INFO - 
 [EPOCH 8]Model Checkpoint SAVED at epoch 8
 avg_epoch_loss: [1.198258]
 bestloss: [1.198258]
 Trigger times: 0/12

2025-03-24 20:00:18,505 - INFO - 
Trigger times: 3, patience: 20

2025-03-24 20:00:18,505 - INFO - 
Trigger times: 3, patience: 12

2025-03-24 20:00:18,505 - INFO - 
[Epoch Improvement] Epoch 8: Loss improved during training by 9.97% from previous epoch, 

2025-03-24 20:00:18,506 - INFO - ####LOGGING AVERAGE LOSS EPOCH###
[Epoch Summary] Epoch: 8/10, Avg Combined Loss: 1.198258, MaskLoss: 0.367758, Hybridloss: 0.801987Previous Epoch loss: 1.330944608449936
2025-03-24 20:00:18,506 - INFO - Epoch: 8 COMPLETED





2025-03-24 20:00:18,507 - INFO - [Train] Epoch 9/10 started.

2025-03-24 20:01:18,201 - INFO - #####INPUTS & TARGETS VALUE [2 BATCHES]####
Batch 1: Mixture shape=torch.Size([4, 1, 513, 946]), Target shape=torch.Size([4, 1, 513, 946])
2025-03-24 20:01:19,788 - INFO - [EPOCH 9]outputs from the model torch.Size([4, 64, 513, 946])
for batch 1
predicted mask shape torch.Size([4, 1, 513, 946])
2025-03-24 20:01:20,995 - INFO - Function: [log_first_2_batches_outputs_inputs_targets_predicted_mask]
2025-03-24 20:01:20,998 - INFO - ####OUTPUTS, INPUTS, TARGETS,PREDICTEDMASK [2 BATCHES]####
Batch 1: Mask range: min=0.0000, max=2.7285
Batch 1: Inputs shape=torch.Size([4, 1, 513, 946]), Targets shape=torch.Size([4, 1, 513, 946]), Predicted Mask shape=torch.Size([4, 1, 513, 946]), Outputs shape=torch.Size([4, 64, 513, 946])
Mask min=0.37255859375, max=0.90625
[After Mask Application] Predicted vocals min: 0.0, max: 69.0625

2025-03-24 20:01:20,998 - INFO - 
####LOSS VALUES####
[Combinedloss]:  Total treningsfeil, [BØR REDUSERES OVER TID]
[MaskLoss]: Sier hvor godt modellen lærer og predikere masken som isolerer vokaler[BØR REDUSERES OVER TID]
[l1_loss og stft_loss] gir ekstra indikasjoner på lydkvalitet.
[Hybridloss]: Kombinasjon av flere tapsfunksjoner[BØR REDUSERES OVER TID]

2025-03-24 20:01:21,013 - INFO - Appending Batch Losses: Mask: 0.4600890278816223, Hybrid: 0.964641809463501, Combined: 1.4599804878234863
2025-03-24 20:01:21,950 - INFO - [EPOCH 9]outputs from the model torch.Size([4, 64, 513, 946])
for batch 2
predicted mask shape torch.Size([4, 1, 513, 946])
2025-03-24 20:01:23,093 - INFO - Appending Batch Losses: Mask: 0.30369624495506287, Hybrid: 0.606482207775116, Combined: 0.34746479988098145
2025-03-24 20:01:27,807 - INFO - Appending Batch Losses: Mask: 0.3731312155723572, Hybrid: 0.8006592988967896, Combined: 1.3657901287078857
2025-03-24 20:01:28,749 - INFO - Appending Batch Losses: Mask: 0.47155678272247314, Hybrid: 0.9131457209587097, Combined: 1.2920634746551514
2025-03-24 20:01:29,681 - INFO - Appending Batch Losses: Mask: 0.28000861406326294, Hybrid: 0.5888897180557251, Combined: 2.067315101623535
2025-03-24 20:01:30,604 - INFO - Appending Batch Losses: Mask: 0.4265764355659485, Hybrid: 1.0023056268692017, Combined: 1.8364949226379395
2025-03-24 20:01:55,995 - INFO - Appending Batch Losses: Mask: 0.34652280807495117, Hybrid: 0.689129650592804, Combined: 0.8399045467376709
2025-03-24 20:01:56,963 - INFO - Appending Batch Losses: Mask: 0.33041805028915405, Hybrid: 0.6854444742202759, Combined: 0.9336015582084656
2025-03-24 20:02:21,766 - INFO - Appending Batch Losses: Mask: 0.31109797954559326, Hybrid: 0.698493242263794, Combined: 0.7605863809585571
2025-03-24 20:02:22,689 - INFO - Appending Batch Losses: Mask: 0.39637795090675354, Hybrid: 0.7337859272956848, Combined: 1.341797113418579
2025-03-24 20:02:23,637 - INFO - Appending Batch Losses: Mask: 0.33010566234588623, Hybrid: 0.8494520783424377, Combined: 2.0849757194519043
2025-03-24 20:02:24,556 - INFO - Appending Batch Losses: Mask: 0.37513837218284607, Hybrid: 0.8815730810165405, Combined: 1.5918488502502441
2025-03-24 20:02:51,883 - INFO - Appending Batch Losses: Mask: 0.35545891523361206, Hybrid: 0.7817813754081726, Combined: 1.9126304388046265
2025-03-24 20:02:52,809 - INFO - Appending Batch Losses: Mask: 0.320553719997406, Hybrid: 0.6254018545150757, Combined: 0.786227285861969
2025-03-24 20:03:01,944 - INFO - Appending Batch Losses: Mask: 0.3761817216873169, Hybrid: 0.7566864490509033, Combined: 1.2204251289367676
2025-03-24 20:03:02,901 - INFO - Appending Batch Losses: Mask: 0.3579385280609131, Hybrid: 0.8669222593307495, Combined: 1.6558446884155273
2025-03-24 20:03:04,062 - INFO - Appending Batch Losses: Mask: 0.42398780584335327, Hybrid: 0.909636378288269, Combined: 1.4967191219329834
2025-03-24 20:03:05,035 - INFO - Appending Batch Losses: Mask: 0.44217491149902344, Hybrid: 0.8865816593170166, Combined: 1.0487964153289795
2025-03-24 20:03:34,029 - INFO - Appending Batch Losses: Mask: 0.31164389848709106, Hybrid: 0.6577770709991455, Combined: 0.8072843551635742
2025-03-24 20:03:35,019 - INFO - Appending Batch Losses: Mask: 0.3773181736469269, Hybrid: 0.8257677555084229, Combined: 1.2011680603027344
2025-03-24 20:03:41,506 - INFO - Appending Batch Losses: Mask: 0.40494483709335327, Hybrid: 0.96021968126297, Combined: 1.354803204536438
2025-03-24 20:03:45,368 - INFO - Appending Batch Losses: Mask: 0.2999536097049713, Hybrid: 0.7091218829154968, Combined: 1.6604955196380615
2025-03-24 20:03:50,169 - INFO - Appending Batch Losses: Mask: 0.30927014350891113, Hybrid: 0.6844749450683594, Combined: 1.3043766021728516
2025-03-24 20:03:51,096 - INFO - Appending Batch Losses: Mask: 0.378488689661026, Hybrid: 0.6385486721992493, Combined: 1.0155147314071655
2025-03-24 20:04:02,191 - INFO - Appending Batch Losses: Mask: 0.3196747303009033, Hybrid: 0.8542633652687073, Combined: 0.927451491355896
2025-03-24 20:04:04,050 - INFO - Current Learning Rate 0.0007151825523359015

2025-03-24 20:04:04,050 - INFO - 
[EPOCH 9]No improvement, NO NEW MODEL CHECKPOINT SAVED at epoch 9
 avg_epoch_loss: [1.292542]
 bestloss: [1.198258]
 Trigger: 4/12

2025-03-24 20:05:51,629 - INFO - 
Trigger times: 4, patience: 20

2025-03-24 20:05:51,629 - INFO - 
Trigger times: 4, patience: 12

2025-03-24 20:05:51,629 - INFO - 
[Epoch Improvement] Epoch 9: Loss improved during training by -7.87% from previous epoch, 

2025-03-24 20:05:51,630 - INFO - ####LOGGING AVERAGE LOSS EPOCH###
[Epoch Summary] Epoch: 9/10, Avg Combined Loss: 1.292542, MaskLoss: 0.367262, Hybridloss: 0.799860Previous Epoch loss: 1.1982583260536195
2025-03-24 20:05:51,630 - INFO - Epoch: 9 COMPLETED





2025-03-24 20:05:51,631 - INFO - [Train] Epoch 10/10 started.

2025-03-24 20:06:36,414 - INFO - #####INPUTS & TARGETS VALUE [2 BATCHES]####
Batch 1: Mixture shape=torch.Size([4, 1, 513, 946]), Target shape=torch.Size([4, 1, 513, 946])
2025-03-24 20:06:37,426 - INFO - [EPOCH 10]outputs from the model torch.Size([4, 64, 513, 946])
for batch 1
predicted mask shape torch.Size([4, 1, 513, 946])
2025-03-24 20:06:38,417 - INFO - Function: [log_first_2_batches_outputs_inputs_targets_predicted_mask]
2025-03-24 20:06:38,420 - INFO - ####OUTPUTS, INPUTS, TARGETS,PREDICTEDMASK [2 BATCHES]####
Batch 1: Mask range: min=0.0000, max=3.6738
Batch 1: Inputs shape=torch.Size([4, 1, 513, 946]), Targets shape=torch.Size([4, 1, 513, 946]), Predicted Mask shape=torch.Size([4, 1, 513, 946]), Outputs shape=torch.Size([4, 64, 513, 946])
Mask min=0.347900390625, max=0.955078125
[After Mask Application] Predicted vocals min: 0.0, max: 65.0625

2025-03-24 20:06:38,420 - INFO - 
####LOSS VALUES####
[Combinedloss]:  Total treningsfeil, [BØR REDUSERES OVER TID]
[MaskLoss]: Sier hvor godt modellen lærer og predikere masken som isolerer vokaler[BØR REDUSERES OVER TID]
[l1_loss og stft_loss] gir ekstra indikasjoner på lydkvalitet.
[Hybridloss]: Kombinasjon av flere tapsfunksjoner[BØR REDUSERES OVER TID]

2025-03-24 20:06:38,432 - INFO - Appending Batch Losses: Mask: 0.5059658288955688, Hybrid: 1.195751428604126, Combined: 2.2276201248168945
2025-03-24 20:06:39,643 - INFO - [EPOCH 10]outputs from the model torch.Size([4, 64, 513, 946])
for batch 2
predicted mask shape torch.Size([4, 1, 513, 946])
2025-03-24 20:06:40,640 - INFO - Appending Batch Losses: Mask: 0.22386054694652557, Hybrid: 0.5188860893249512, Combined: 1.1309502124786377
2025-03-24 20:06:41,876 - INFO - Appending Batch Losses: Mask: 0.4356963336467743, Hybrid: 0.9006646871566772, Combined: 1.3948166370391846
2025-03-24 20:06:46,841 - INFO - Appending Batch Losses: Mask: 0.29946082830429077, Hybrid: 0.5742844939231873, Combined: 0.5062705278396606
2025-03-24 20:06:53,041 - INFO - Appending Batch Losses: Mask: 0.3369704484939575, Hybrid: 0.6649869084358215, Combined: 0.6568611860275269
2025-03-24 20:06:54,368 - INFO - Appending Batch Losses: Mask: 0.2997221350669861, Hybrid: 0.6732714176177979, Combined: 0.845046877861023
2025-03-24 20:12:38,545 - INFO - Appending Batch Losses: Mask: 0.3745078146457672, Hybrid: 0.7437554597854614, Combined: 1.3360964059829712
2025-03-24 20:12:39,758 - INFO - Appending Batch Losses: Mask: 0.38552507758140564, Hybrid: 0.8520559072494507, Combined: 1.707760214805603
2025-03-24 20:12:40,732 - INFO - Appending Batch Losses: Mask: 0.3413091003894806, Hybrid: 0.6437027454376221, Combined: 1.2814669609069824
2025-03-24 20:12:41,644 - INFO - Appending Batch Losses: Mask: 0.3576686978340149, Hybrid: 0.8565429449081421, Combined: 1.2052407264709473
2025-03-24 20:12:42,385 - INFO - Appending Batch Losses: Mask: 0.3836112320423126, Hybrid: 0.8058974742889404, Combined: 1.1270228624343872
2025-03-24 20:12:43,433 - INFO - Appending Batch Losses: Mask: 0.28380832076072693, Hybrid: 0.6472908854484558, Combined: 0.4801962375640869
2025-03-24 20:12:45,518 - INFO - Appending Batch Losses: Mask: 0.39348170161247253, Hybrid: 0.8428201675415039, Combined: 0.946319580078125
2025-03-24 20:12:46,519 - INFO - Appending Batch Losses: Mask: 0.4539719820022583, Hybrid: 0.9479993581771851, Combined: 0.9214648604393005
2025-03-24 20:12:47,849 - INFO - Appending Batch Losses: Mask: 0.4759393036365509, Hybrid: 0.9774467945098877, Combined: 1.6740660667419434
2025-03-24 20:12:50,699 - INFO - Appending Batch Losses: Mask: 0.4407597780227661, Hybrid: 1.0327410697937012, Combined: 1.7755485773086548
2025-03-24 20:12:51,758 - INFO - Appending Batch Losses: Mask: 0.4114808440208435, Hybrid: 0.909575343132019, Combined: 1.7106807231903076
2025-03-24 20:12:52,837 - INFO - Appending Batch Losses: Mask: 0.2611042857170105, Hybrid: 0.6208683848381042, Combined: 0.5092621445655823
2025-03-24 20:12:53,886 - INFO - Appending Batch Losses: Mask: 0.44844090938568115, Hybrid: 1.063180685043335, Combined: 1.0825622081756592
2025-03-24 20:13:18,403 - INFO - Appending Batch Losses: Mask: 0.3646056056022644, Hybrid: 0.777301549911499, Combined: 1.4158709049224854
2025-03-24 20:13:19,362 - INFO - Appending Batch Losses: Mask: 0.3470594584941864, Hybrid: 0.6926436424255371, Combined: 1.0941569805145264
2025-03-24 20:13:20,337 - INFO - Appending Batch Losses: Mask: 0.3566535711288452, Hybrid: 0.7225659489631653, Combined: 0.5025363564491272
2025-03-24 20:13:21,331 - INFO - Appending Batch Losses: Mask: 0.33865678310394287, Hybrid: 0.6717590093612671, Combined: 0.7535154819488525
2025-03-24 20:13:22,519 - INFO - Appending Batch Losses: Mask: 0.30103063583374023, Hybrid: 0.5910803079605103, Combined: 0.5011506080627441
2025-03-24 20:13:24,796 - INFO - Appending Batch Losses: Mask: 0.415759801864624, Hybrid: 0.9408524632453918, Combined: 1.873183250427246
2025-03-24 20:13:26,753 - INFO - Current Learning Rate 0.0007311571150361335

2025-03-24 20:13:27,907 - INFO - Checkpoint saved: /mnt/c/Users/didri/Desktop/Programmering/ArtificalintelligenceModels/UNet-Model_Vocal_Isolation/Unet_model_Audio_Seperation/Model_Weights/CheckPoints/Training/checkpoint_epoch_9.pth
2025-03-24 20:13:27,907 - INFO - 
 [EPOCH 10]Model Checkpoint SAVED at epoch 10
 avg_epoch_loss: [1.146387]
 bestloss: [1.146387]
 Trigger times: 0/12

2025-03-24 20:14:50,088 - INFO - 
Trigger times: 0, patience: 20

2025-03-24 20:14:50,088 - INFO - 
Trigger times: 0, patience: 12

2025-03-24 20:14:50,089 - INFO - 
[Epoch Improvement] Epoch 10: Loss improved during training by 11.31% from previous epoch, 

2025-03-24 20:14:50,092 - INFO - ####LOGGING AVERAGE LOSS EPOCH###
[Epoch Summary] Epoch: 10/10, Avg Combined Loss: 1.146387, MaskLoss: 0.367484, Hybridloss: 0.799346Previous Epoch loss: 1.292542405128479
2025-03-24 20:14:50,093 - INFO - Epoch: 10 COMPLETED





2025-03-24 20:14:52,008 - INFO - [Train] Training completed. Clearing memory cache now...
2025-03-24 20:14:53,865 - INFO - Saved DeepSpeed checkpoint to /mnt/c/Users/didri/Desktop/Programmering/ArtificalintelligenceModels/UNet-Model_Vocal_Isolation/Unet_model_Audio_Seperation/Model_Weights/Pre_trained/deepspeed_checkpoint
2025-03-24 20:14:53,865 - INFO - Starting Evaluation now. 
