2025-02-22 01:01:12,207 - INFO - [Train] Using device: cuda
2025-02-22 01:01:17,960 - INFO - Loaded model checkpoint from Unet_model_Audio_Seperation/Model_Weights/Pre_trained/deepspeed_checkpoint
2025-02-22 01:01:18,159 - INFO - [Train] Epoch 1/50 started.

2025-02-22 01:01:56,643 - INFO - #####INPUTS & TARGETS VALUE [2 BATCHES]####
Batch 1: Mixture shape=torch.Size([4, 1, 513, 946]), Target shape=torch.Size([4, 1, 513, 946])
2025-02-22 01:02:03,665 - INFO - [EPOCH 1]outputs from the model torch.Size([4, 64, 513, 946])
for batch 1
predicted mask shape torch.Size([4, 1, 513, 946])
2025-02-22 01:02:05,086 - INFO - Function: [log_first_2_batches_outputs_inputs_targets_predicted_mask]
2025-02-22 01:02:05,089 - INFO - ####OUTPUTS, INPUTS, TARGETS,PREDICTEDMASK [2 BATCHES]####
Batch 1: Mask range: min=0.0000, max=60.7812
Batch 1: Inputs shape=torch.Size([4, 1, 513, 946]), Targets shape=torch.Size([4, 1, 513, 946]), Predicted Mask shape=torch.Size([4, 1, 513, 946]), Outputs shape=torch.Size([4, 64, 513, 946])
Mask min=0.0, max=1.0
[After Mask Application] Predicted vocals min: 0.0, max: 113.8125

2025-02-22 01:02:05,090 - INFO - 
####LOSS VALUES####
[Combinedloss]:  Total treningsfeil, [BØR REDUSERES OVER TID]
[MaskLoss]: Sier hvor godt modellen lærer og predikere masken som isolerer vokaler[BØR REDUSERES OVER TID]
[l1_loss og stft_loss] gir ekstra indikasjoner på lydkvalitet.
[Hybridloss]: Kombinasjon av flere tapsfunksjoner[BØR REDUSERES OVER TID]

2025-02-22 01:02:05,188 - INFO - Appending Batch Losses: Mask: 0.37754198908805847, Hybrid: 0.5783579349517822, Combined: 0.59975665807724
2025-02-22 01:02:22,795 - INFO - [EPOCH 1]outputs from the model torch.Size([4, 64, 513, 946])
for batch 2
predicted mask shape torch.Size([4, 1, 513, 946])
2025-02-22 01:02:23,838 - INFO - Appending Batch Losses: Mask: 0.38180428743362427, Hybrid: 0.7908272743225098, Combined: 0.6385245323181152
2025-02-22 01:02:25,716 - INFO - Appending Batch Losses: Mask: 0.49806851148605347, Hybrid: 0.7906777858734131, Combined: 0.6712810397148132
2025-02-22 01:02:26,942 - INFO - Appending Batch Losses: Mask: 0.34027716517448425, Hybrid: 0.5670877695083618, Combined: 0.6649913787841797
2025-02-22 01:02:30,432 - INFO - Appending Batch Losses: Mask: 0.35513681173324585, Hybrid: 0.5862569808959961, Combined: 0.32690849900245667
2025-02-22 01:02:33,810 - INFO - Appending Batch Losses: Mask: 0.47638726234436035, Hybrid: 0.8459857702255249, Combined: 0.8562074303627014
2025-02-22 01:02:40,187 - INFO - Appending Batch Losses: Mask: 0.3877606987953186, Hybrid: 0.724837064743042, Combined: 0.5703365206718445
2025-02-22 01:02:54,586 - INFO - Appending Batch Losses: Mask: 0.3354736566543579, Hybrid: 0.6256347894668579, Combined: 0.604030430316925
2025-02-22 01:03:04,920 - INFO - Appending Batch Losses: Mask: 0.423615962266922, Hybrid: 0.7695013284683228, Combined: 0.6721451878547668
2025-02-22 01:03:10,950 - INFO - Appending Batch Losses: Mask: 0.49564453959465027, Hybrid: 0.9515292644500732, Combined: 0.9283789992332458
2025-02-22 01:03:12,650 - INFO - Appending Batch Losses: Mask: 0.5388329029083252, Hybrid: 0.8595738410949707, Combined: 0.7832568287849426
2025-02-22 01:03:15,047 - INFO - Appending Batch Losses: Mask: 0.26374056935310364, Hybrid: 0.48583537340164185, Combined: 0.3036746382713318
2025-02-22 01:03:29,525 - INFO - Appending Batch Losses: Mask: 0.39046627283096313, Hybrid: 0.8157968521118164, Combined: 0.5369971990585327
2025-02-22 01:03:34,641 - INFO - Appending Batch Losses: Mask: 0.3965702950954437, Hybrid: 0.7381044626235962, Combined: 0.6034716963768005
2025-02-22 01:03:36,913 - INFO - Appending Batch Losses: Mask: 0.44142770767211914, Hybrid: 0.7663463354110718, Combined: 0.718245267868042
2025-02-22 01:03:39,167 - INFO - Appending Batch Losses: Mask: 0.44270867109298706, Hybrid: 0.7461315393447876, Combined: 0.5687567591667175
2025-02-22 01:03:42,375 - INFO - Appending Batch Losses: Mask: 0.4125112295150757, Hybrid: 0.7540202140808105, Combined: 0.40213391184806824
2025-02-22 01:03:44,826 - INFO - Appending Batch Losses: Mask: 0.38755354285240173, Hybrid: 0.7045438289642334, Combined: 0.7142760753631592
2025-02-22 01:04:15,520 - INFO - Appending Batch Losses: Mask: 0.34970012307167053, Hybrid: 0.6102060079574585, Combined: 0.7064764499664307
2025-02-22 01:04:17,546 - INFO - Appending Batch Losses: Mask: 0.37195703387260437, Hybrid: 0.6998705267906189, Combined: 0.5055992603302002
2025-02-22 01:04:19,544 - INFO - Appending Batch Losses: Mask: 0.4794970154762268, Hybrid: 0.7415814399719238, Combined: 0.7884993553161621
2025-02-22 01:04:21,576 - INFO - Appending Batch Losses: Mask: 0.4224959909915924, Hybrid: 0.6637058258056641, Combined: 0.8991645574569702
2025-02-22 01:04:23,623 - INFO - Appending Batch Losses: Mask: 0.3453979790210724, Hybrid: 0.5699728727340698, Combined: 0.6214855909347534
2025-02-22 01:04:24,724 - INFO - Appending Batch Losses: Mask: 0.35420477390289307, Hybrid: 0.6590144634246826, Combined: 0.6266719102859497
2025-02-22 01:04:51,251 - INFO - Appending Batch Losses: Mask: 0.35021400451660156, Hybrid: 0.6062805652618408, Combined: 0.5207219123840332
2025-02-22 01:04:53,862 - INFO - Appending Batch Losses: Mask: 0.4253031611442566, Hybrid: 0.7725825309753418, Combined: 0.7565602660179138
2025-02-22 01:04:56,556 - INFO - Appending Batch Losses: Mask: 0.43401142954826355, Hybrid: 0.7209315299987793, Combined: 0.6902318596839905
2025-02-22 01:05:00,426 - INFO - Appending Batch Losses: Mask: 0.49602386355400085, Hybrid: 0.9449411034584045, Combined: 0.8592958450317383
2025-02-22 01:05:02,600 - INFO - Appending Batch Losses: Mask: 0.47122499346733093, Hybrid: 0.855852484703064, Combined: 0.631049394607544
2025-02-22 01:05:04,650 - INFO - Appending Batch Losses: Mask: 0.44083860516548157, Hybrid: 0.7573111653327942, Combined: 0.6721124053001404
2025-02-22 01:05:25,574 - INFO - Appending Batch Losses: Mask: 0.43254953622817993, Hybrid: 0.6998457908630371, Combined: 0.7607216835021973
2025-02-22 01:05:27,963 - INFO - Appending Batch Losses: Mask: 0.4499495327472687, Hybrid: 0.7930108308792114, Combined: 0.7247967720031738
2025-02-22 01:05:30,257 - INFO - Appending Batch Losses: Mask: 0.539345920085907, Hybrid: 0.8356369137763977, Combined: 0.6678522825241089
2025-02-22 01:05:31,694 - INFO - Appending Batch Losses: Mask: 0.3169560432434082, Hybrid: 0.5199065208435059, Combined: 0.41661176085472107
2025-02-22 01:05:32,879 - INFO - Appending Batch Losses: Mask: 0.5326845645904541, Hybrid: 0.8949495553970337, Combined: 0.6748815178871155
2025-02-22 01:05:35,618 - INFO - Appending Batch Losses: Mask: 0.33741456270217896, Hybrid: 0.5674080848693848, Combined: 0.49103274941444397
2025-02-22 01:05:54,691 - INFO - Appending Batch Losses: Mask: 0.4245872497558594, Hybrid: 0.6835540533065796, Combined: 0.7362979650497437
2025-02-22 01:05:57,062 - INFO - Current Learning Rate 0.0007961034504475443

2025-02-22 01:05:58,640 - INFO - Checkpoint saved: /mnt/c/Users/didri/Desktop/Programmering/ArtificalintelligenceModels/UNet-Model_Vocal_Isolation/Unet_model_Audio_Seperation/Model_Weights/CheckPoints/Training/checkpoint_epoch_0.pth
2025-02-22 01:05:58,640 - INFO - 
 [EPOCH 1]Model Checkpoint SAVED at epoch 1
 avg_epoch_loss: [0.646309]
 bestloss: [0.646309]
 Trigger times: 0/12

2025-02-22 01:07:44,044 - INFO - 
Trigger times: 0, patience: 15

2025-02-22 01:07:44,044 - INFO - 
Trigger times: 0, patience: 12

2025-02-22 01:07:44,044 - INFO - 
[Epoch Improvement] Epoch 1: Loss improved during training by nan% from previous epoch, 

2025-02-22 01:07:44,046 - INFO - ####LOGGING AVERAGE LOSS EPOCH###
[Epoch Summary] Epoch: 1/50, Avg Combined Loss: 0.646309, MaskLoss: 0.414051, Hybridloss: 0.721557Previous Epoch loss: inf
2025-02-22 01:07:44,047 - INFO - Epoch: 1 COMPLETED





2025-02-22 01:07:44,047 - INFO - [Train] Epoch 2/50 started.

2025-02-22 01:08:14,299 - INFO - #####INPUTS & TARGETS VALUE [2 BATCHES]####
Batch 1: Mixture shape=torch.Size([4, 1, 513, 946]), Target shape=torch.Size([4, 1, 513, 946])
2025-02-22 01:08:15,187 - INFO - [EPOCH 2]outputs from the model torch.Size([4, 64, 513, 946])
for batch 1
predicted mask shape torch.Size([4, 1, 513, 946])
2025-02-22 01:08:16,426 - INFO - Function: [log_first_2_batches_outputs_inputs_targets_predicted_mask]
2025-02-22 01:08:16,429 - INFO - ####OUTPUTS, INPUTS, TARGETS,PREDICTEDMASK [2 BATCHES]####
Batch 1: Mask range: min=0.0000, max=94.3750
Batch 1: Inputs shape=torch.Size([4, 1, 513, 946]), Targets shape=torch.Size([4, 1, 513, 946]), Predicted Mask shape=torch.Size([4, 1, 513, 946]), Outputs shape=torch.Size([4, 64, 513, 946])
Mask min=0.0, max=1.0
[After Mask Application] Predicted vocals min: 0.0, max: 150.25

2025-02-22 01:08:16,429 - INFO - 
####LOSS VALUES####
[Combinedloss]:  Total treningsfeil, [BØR REDUSERES OVER TID]
[MaskLoss]: Sier hvor godt modellen lærer og predikere masken som isolerer vokaler[BØR REDUSERES OVER TID]
[l1_loss og stft_loss] gir ekstra indikasjoner på lydkvalitet.
[Hybridloss]: Kombinasjon av flere tapsfunksjoner[BØR REDUSERES OVER TID]

2025-02-22 01:08:16,443 - INFO - Appending Batch Losses: Mask: 0.40985310077667236, Hybrid: 0.8098500967025757, Combined: 0.8147593140602112
2025-02-22 01:08:23,226 - INFO - [EPOCH 2]outputs from the model torch.Size([4, 64, 513, 946])
for batch 2
predicted mask shape torch.Size([4, 1, 513, 946])
2025-02-22 01:08:24,358 - INFO - Appending Batch Losses: Mask: 0.4528358578681946, Hybrid: 0.8175826668739319, Combined: 0.8265499472618103
2025-02-22 01:08:26,402 - INFO - Appending Batch Losses: Mask: 0.47322824597358704, Hybrid: 0.7789371013641357, Combined: 0.6798025369644165
2025-02-22 01:08:28,635 - INFO - Appending Batch Losses: Mask: 0.4237176775932312, Hybrid: 0.6763938665390015, Combined: 0.5952606797218323
2025-02-22 01:08:30,614 - INFO - Appending Batch Losses: Mask: 0.43133848905563354, Hybrid: 0.7337729930877686, Combined: 0.7042209506034851
2025-02-22 01:08:32,883 - INFO - Appending Batch Losses: Mask: 0.5114519000053406, Hybrid: 0.8270403146743774, Combined: 0.6819181442260742
2025-02-22 01:08:58,961 - INFO - Appending Batch Losses: Mask: 0.35299158096313477, Hybrid: 0.7356107234954834, Combined: 0.5652755498886108
2025-02-22 01:09:01,425 - INFO - Appending Batch Losses: Mask: 0.39283287525177, Hybrid: 0.6676958799362183, Combined: 0.3438630998134613
2025-02-22 01:09:02,432 - INFO - Appending Batch Losses: Mask: 0.4137047827243805, Hybrid: 0.9522154331207275, Combined: 0.6639544367790222
2025-02-22 01:09:03,331 - INFO - Appending Batch Losses: Mask: 0.41212746500968933, Hybrid: 0.7200337052345276, Combined: 0.7892552614212036
2025-02-22 01:09:04,218 - INFO - Appending Batch Losses: Mask: 0.35020211338996887, Hybrid: 0.6894616484642029, Combined: 0.4181056022644043
2025-02-22 01:09:06,043 - INFO - Appending Batch Losses: Mask: 0.3690963089466095, Hybrid: 0.7043863534927368, Combined: 0.6754812598228455
2025-02-22 01:09:41,790 - INFO - Appending Batch Losses: Mask: 0.5138366222381592, Hybrid: 0.7494871020317078, Combined: 0.9266961812973022
2025-02-22 01:09:42,798 - INFO - Appending Batch Losses: Mask: 0.3493693768978119, Hybrid: 0.5529899001121521, Combined: 0.5659199357032776
2025-02-22 01:09:43,814 - INFO - Appending Batch Losses: Mask: 0.48267003893852234, Hybrid: 0.7237678170204163, Combined: 0.7267341613769531
2025-02-22 01:09:44,699 - INFO - Appending Batch Losses: Mask: 0.46992233395576477, Hybrid: 0.7419676780700684, Combined: 0.6938652992248535
2025-02-22 01:09:45,577 - INFO - Appending Batch Losses: Mask: 0.38286203145980835, Hybrid: 0.7449896931648254, Combined: 0.29515567421913147
2025-02-22 01:09:46,595 - INFO - Appending Batch Losses: Mask: 0.47106167674064636, Hybrid: 0.9017521142959595, Combined: 0.6145114898681641
2025-02-22 01:10:12,599 - INFO - Appending Batch Losses: Mask: 0.5028204917907715, Hybrid: 0.787345826625824, Combined: 0.6552963852882385
2025-02-22 01:10:13,880 - INFO - Appending Batch Losses: Mask: 0.4434666037559509, Hybrid: 0.7295714616775513, Combined: 0.7682787775993347
2025-02-22 01:10:14,890 - INFO - Appending Batch Losses: Mask: 0.4405699074268341, Hybrid: 0.9813549518585205, Combined: 0.6442760825157166
2025-02-22 01:10:15,955 - INFO - Appending Batch Losses: Mask: 0.42699629068374634, Hybrid: 0.7344662547111511, Combined: 0.6928625106811523
2025-02-22 01:10:16,974 - INFO - Appending Batch Losses: Mask: 0.40787872672080994, Hybrid: 0.6627597808837891, Combined: 0.6391950845718384
2025-02-22 01:10:17,991 - INFO - Appending Batch Losses: Mask: 0.43706271052360535, Hybrid: 0.7069481611251831, Combined: 0.7223262786865234
2025-02-22 01:10:51,437 - INFO - Appending Batch Losses: Mask: 0.40691134333610535, Hybrid: 0.7590094804763794, Combined: 0.47922414541244507
2025-02-22 01:10:53,315 - INFO - Appending Batch Losses: Mask: 0.4375174045562744, Hybrid: 0.7074716091156006, Combined: 0.5571683049201965
2025-02-22 01:10:54,436 - INFO - Appending Batch Losses: Mask: 0.37774160504341125, Hybrid: 0.6252967119216919, Combined: 0.659296989440918
2025-02-22 01:10:55,815 - INFO - Appending Batch Losses: Mask: 0.32729455828666687, Hybrid: 0.6635423898696899, Combined: 0.4328303933143616
2025-02-22 01:10:56,824 - INFO - Appending Batch Losses: Mask: 0.2832014560699463, Hybrid: 0.737226665019989, Combined: 0.4978565573692322
2025-02-22 01:10:58,123 - INFO - Appending Batch Losses: Mask: 0.4077633321285248, Hybrid: 0.5971695780754089, Combined: 0.5499987602233887
2025-02-22 01:11:13,023 - INFO - Appending Batch Losses: Mask: 0.36806732416152954, Hybrid: 0.6400759220123291, Combined: 0.7528019547462463
2025-02-22 01:11:13,879 - INFO - Appending Batch Losses: Mask: 0.44785261154174805, Hybrid: 0.7320789098739624, Combined: 0.6067554950714111
2025-02-22 01:11:14,729 - INFO - Appending Batch Losses: Mask: 0.4975880980491638, Hybrid: 0.7693829536437988, Combined: 0.7285096645355225
2025-02-22 01:11:15,710 - INFO - Appending Batch Losses: Mask: 0.33701297640800476, Hybrid: 0.6085312366485596, Combined: 0.3567047715187073
2025-02-22 01:11:16,704 - INFO - Appending Batch Losses: Mask: 0.41233760118484497, Hybrid: 0.89849853515625, Combined: 0.6420251131057739
2025-02-22 01:11:17,979 - INFO - Appending Batch Losses: Mask: 0.36700695753097534, Hybrid: 0.5803722143173218, Combined: 0.5706400275230408
2025-02-22 01:11:28,669 - INFO - Appending Batch Losses: Mask: 0.4584204852581024, Hybrid: 0.7255492210388184, Combined: 0.6693916916847229
2025-02-22 01:11:30,849 - INFO - Current Learning Rate 0.0008137765382186265

2025-02-22 01:11:32,279 - INFO - Checkpoint saved: /mnt/c/Users/didri/Desktop/Programmering/ArtificalintelligenceModels/UNet-Model_Vocal_Isolation/Unet_model_Audio_Seperation/Model_Weights/CheckPoints/Training/checkpoint_epoch_1.pth
2025-02-22 01:11:32,279 - INFO - 
 [EPOCH 2]Model Checkpoint SAVED at epoch 2
 avg_epoch_loss: [0.627210]
 bestloss: [0.627210]
 Trigger times: 0/12

2025-02-22 01:13:03,097 - INFO - 
Trigger times: 1, patience: 15

2025-02-22 01:13:03,097 - INFO - 
Trigger times: 1, patience: 12

2025-02-22 01:13:03,097 - INFO - 
[Epoch Improvement] Epoch 2: Loss improved during training by 2.96% from previous epoch, 

2025-02-22 01:13:03,097 - INFO - ####LOGGING AVERAGE LOSS EPOCH###
[Epoch Summary] Epoch: 2/50, Avg Combined Loss: 0.627210, MaskLoss: 0.415817, Hybridloss: 0.728003Previous Epoch loss: 0.6463090970709517
2025-02-22 01:13:03,098 - INFO - Epoch: 2 COMPLETED





2025-02-22 01:13:03,099 - INFO - [Train] Epoch 3/50 started.

2025-02-22 01:13:46,511 - INFO - #####INPUTS & TARGETS VALUE [2 BATCHES]####
Batch 1: Mixture shape=torch.Size([4, 1, 513, 946]), Target shape=torch.Size([4, 1, 513, 946])
2025-02-22 01:13:47,481 - INFO - [EPOCH 3]outputs from the model torch.Size([4, 64, 513, 946])
for batch 1
predicted mask shape torch.Size([4, 1, 513, 946])
2025-02-22 01:13:48,723 - INFO - Function: [log_first_2_batches_outputs_inputs_targets_predicted_mask]
2025-02-22 01:13:48,726 - INFO - ####OUTPUTS, INPUTS, TARGETS,PREDICTEDMASK [2 BATCHES]####
Batch 1: Mask range: min=0.0000, max=61.0625
Batch 1: Inputs shape=torch.Size([4, 1, 513, 946]), Targets shape=torch.Size([4, 1, 513, 946]), Predicted Mask shape=torch.Size([4, 1, 513, 946]), Outputs shape=torch.Size([4, 64, 513, 946])
Mask min=0.0, max=1.0
[After Mask Application] Predicted vocals min: 0.0, max: 148.125

2025-02-22 01:13:48,726 - INFO - 
####LOSS VALUES####
[Combinedloss]:  Total treningsfeil, [BØR REDUSERES OVER TID]
[MaskLoss]: Sier hvor godt modellen lærer og predikere masken som isolerer vokaler[BØR REDUSERES OVER TID]
[l1_loss og stft_loss] gir ekstra indikasjoner på lydkvalitet.
[Hybridloss]: Kombinasjon av flere tapsfunksjoner[BØR REDUSERES OVER TID]

2025-02-22 01:13:48,738 - INFO - Appending Batch Losses: Mask: 0.4815692603588104, Hybrid: 0.8415944576263428, Combined: 0.7078979015350342
2025-02-22 01:13:49,761 - INFO - [EPOCH 3]outputs from the model torch.Size([4, 64, 513, 946])
for batch 2
predicted mask shape torch.Size([4, 1, 513, 946])
2025-02-22 01:13:51,068 - INFO - Appending Batch Losses: Mask: 0.41216397285461426, Hybrid: 0.7503386735916138, Combined: 0.5166561603546143
2025-02-22 01:13:52,069 - INFO - Appending Batch Losses: Mask: 0.3418748676776886, Hybrid: 0.5438131093978882, Combined: 0.5241634845733643
2025-02-22 01:13:52,928 - INFO - Appending Batch Losses: Mask: 0.5931500196456909, Hybrid: 0.9853200912475586, Combined: 1.031131625175476
2025-02-22 01:13:53,799 - INFO - Appending Batch Losses: Mask: 0.4972527325153351, Hybrid: 0.8257492184638977, Combined: 0.8324596881866455
2025-02-22 01:13:54,830 - INFO - Appending Batch Losses: Mask: 0.3797857165336609, Hybrid: 0.706281304359436, Combined: 0.5104363560676575
2025-02-22 01:14:22,728 - INFO - Appending Batch Losses: Mask: 0.23290665447711945, Hybrid: 0.46291255950927734, Combined: 0.07342877984046936
2025-02-22 01:14:23,605 - INFO - Appending Batch Losses: Mask: 0.38461074233055115, Hybrid: 0.7222459316253662, Combined: 0.28879299759864807
2025-02-22 01:14:24,597 - INFO - Appending Batch Losses: Mask: 0.4004863500595093, Hybrid: 0.7094249725341797, Combined: 0.4717569947242737
2025-02-22 01:14:25,602 - INFO - Appending Batch Losses: Mask: 0.508554220199585, Hybrid: 0.8545838594436646, Combined: 0.849449872970581
2025-02-22 01:14:26,593 - INFO - Appending Batch Losses: Mask: 0.4536365568637848, Hybrid: 0.9066459536552429, Combined: 0.7721699476242065
2025-02-22 01:14:27,602 - INFO - Appending Batch Losses: Mask: 0.4150882363319397, Hybrid: 0.7235580682754517, Combined: 0.7083791494369507
2025-02-22 01:15:02,577 - INFO - Appending Batch Losses: Mask: 0.47622281312942505, Hybrid: 0.7170287370681763, Combined: 0.9220641851425171
2025-02-22 01:15:03,571 - INFO - Appending Batch Losses: Mask: 0.4024697542190552, Hybrid: 0.6437629461288452, Combined: 0.6220901608467102
2025-02-22 01:15:04,910 - INFO - Appending Batch Losses: Mask: 0.3508596420288086, Hybrid: 0.7236645221710205, Combined: -0.0656900405883789
2025-02-22 01:15:05,882 - INFO - Appending Batch Losses: Mask: 0.3611990213394165, Hybrid: 0.7799156904220581, Combined: 0.5292838215827942
2025-02-22 01:15:06,877 - INFO - Appending Batch Losses: Mask: 0.3993229866027832, Hybrid: 0.8100982904434204, Combined: 0.6630026698112488
2025-02-22 01:15:07,864 - INFO - Appending Batch Losses: Mask: 0.3774182200431824, Hybrid: 0.7209120988845825, Combined: 0.6818471550941467
2025-02-22 01:15:31,020 - INFO - Appending Batch Losses: Mask: 0.4752820134162903, Hybrid: 0.8141354322433472, Combined: 0.5643442273139954
2025-02-22 01:15:32,014 - INFO - Appending Batch Losses: Mask: 0.493617445230484, Hybrid: 0.6971756219863892, Combined: 0.8724914789199829
2025-02-22 01:15:33,009 - INFO - Appending Batch Losses: Mask: 0.4513116776943207, Hybrid: 0.7871208190917969, Combined: 0.5345478653907776
2025-02-22 01:15:34,037 - INFO - Appending Batch Losses: Mask: 0.4013630449771881, Hybrid: 0.6167190074920654, Combined: 0.5534327030181885
2025-02-22 01:15:35,323 - INFO - Appending Batch Losses: Mask: 0.43602389097213745, Hybrid: 0.8897320032119751, Combined: 0.9085553884506226
2025-02-22 01:15:36,329 - INFO - Appending Batch Losses: Mask: 0.4883415997028351, Hybrid: 0.8963921070098877, Combined: 0.7247622013092041
2025-02-22 01:15:58,224 - INFO - Appending Batch Losses: Mask: 0.32823437452316284, Hybrid: 0.6097603440284729, Combined: 0.35550546646118164
2025-02-22 01:15:59,214 - INFO - Appending Batch Losses: Mask: 0.5876805186271667, Hybrid: 0.9125726222991943, Combined: 0.8469893336296082
2025-02-22 01:16:00,218 - INFO - Appending Batch Losses: Mask: 0.4982333481311798, Hybrid: 0.793458104133606, Combined: 0.7626762986183167
2025-02-22 01:16:01,197 - INFO - Appending Batch Losses: Mask: 0.46034935116767883, Hybrid: 0.7376209497451782, Combined: 0.6681416630744934
2025-02-22 01:16:02,179 - INFO - Appending Batch Losses: Mask: 0.42823657393455505, Hybrid: 0.7283596992492676, Combined: 0.6070401668548584
2025-02-22 01:16:03,170 - INFO - Appending Batch Losses: Mask: 0.45529279112815857, Hybrid: 0.6514654755592346, Combined: 0.6160203218460083
2025-02-22 01:16:19,910 - INFO - Appending Batch Losses: Mask: 0.4782088100910187, Hybrid: 0.7423567771911621, Combined: 0.7292733788490295
2025-02-22 01:16:20,880 - INFO - Appending Batch Losses: Mask: 0.41197749972343445, Hybrid: 0.8019260168075562, Combined: 0.5672965049743652
2025-02-22 01:16:21,859 - INFO - Appending Batch Losses: Mask: 0.3749304413795471, Hybrid: 0.6795074343681335, Combined: 0.5496417880058289
2025-02-22 01:16:22,835 - INFO - Appending Batch Losses: Mask: 0.39561474323272705, Hybrid: 0.6246499419212341, Combined: 0.5543547868728638
2025-02-22 01:16:25,869 - INFO - Appending Batch Losses: Mask: 0.4388319253921509, Hybrid: 1.099773645401001, Combined: 0.7791035175323486
2025-02-22 01:16:26,859 - INFO - Appending Batch Losses: Mask: 0.4504179060459137, Hybrid: 0.8322169184684753, Combined: 0.6287809014320374
2025-02-22 01:16:40,511 - INFO - Appending Batch Losses: Mask: 0.424050509929657, Hybrid: 0.6720439195632935, Combined: 0.6665585041046143
2025-02-22 01:16:42,708 - INFO - Current Learning Rate 0.0008268681480915507

2025-02-22 01:16:44,231 - INFO - Checkpoint saved: /mnt/c/Users/didri/Desktop/Programmering/ArtificalintelligenceModels/UNet-Model_Vocal_Isolation/Unet_model_Audio_Seperation/Model_Weights/CheckPoints/Training/checkpoint_epoch_2.pth
2025-02-22 01:16:44,232 - INFO - 
 [EPOCH 3]Model Checkpoint SAVED at epoch 3
 avg_epoch_loss: [0.625104]
 bestloss: [0.625104]
 Trigger times: 0/12

2025-02-22 01:18:10,254 - INFO - 
Trigger times: 0, patience: 15

2025-02-22 01:18:10,255 - INFO - 
Trigger times: 0, patience: 12

2025-02-22 01:18:10,255 - INFO - 
[Epoch Improvement] Epoch 3: Loss improved during training by 0.34% from previous epoch, 

2025-02-22 01:18:10,256 - INFO - ####LOGGING AVERAGE LOSS EPOCH###
[Epoch Summary] Epoch: 3/50, Avg Combined Loss: 0.625104, MaskLoss: 0.420874, Hybridloss: 0.737721Previous Epoch loss: 0.6272099598034008
2025-02-22 01:18:10,257 - INFO - Epoch: 3 COMPLETED





2025-02-22 01:18:10,259 - INFO - [Train] Epoch 4/50 started.

2025-02-22 01:18:51,859 - INFO - #####INPUTS & TARGETS VALUE [2 BATCHES]####
Batch 1: Mixture shape=torch.Size([4, 1, 513, 946]), Target shape=torch.Size([4, 1, 513, 946])
2025-02-22 01:18:52,749 - INFO - [EPOCH 4]outputs from the model torch.Size([4, 64, 513, 946])
for batch 1
predicted mask shape torch.Size([4, 1, 513, 946])
2025-02-22 01:18:53,979 - INFO - Function: [log_first_2_batches_outputs_inputs_targets_predicted_mask]
2025-02-22 01:18:53,982 - INFO - ####OUTPUTS, INPUTS, TARGETS,PREDICTEDMASK [2 BATCHES]####
Batch 1: Mask range: min=0.0000, max=105.5000
Batch 1: Inputs shape=torch.Size([4, 1, 513, 946]), Targets shape=torch.Size([4, 1, 513, 946]), Predicted Mask shape=torch.Size([4, 1, 513, 946]), Outputs shape=torch.Size([4, 64, 513, 946])
Mask min=0.0, max=1.0
[After Mask Application] Predicted vocals min: 0.0, max: 205.0

2025-02-22 01:18:53,982 - INFO - 
####LOSS VALUES####
[Combinedloss]:  Total treningsfeil, [BØR REDUSERES OVER TID]
[MaskLoss]: Sier hvor godt modellen lærer og predikere masken som isolerer vokaler[BØR REDUSERES OVER TID]
[l1_loss og stft_loss] gir ekstra indikasjoner på lydkvalitet.
[Hybridloss]: Kombinasjon av flere tapsfunksjoner[BØR REDUSERES OVER TID]

2025-02-22 01:18:53,995 - INFO - Appending Batch Losses: Mask: 0.33790475130081177, Hybrid: 0.8141193985939026, Combined: 0.5309543609619141
2025-02-22 01:18:55,295 - INFO - [EPOCH 4]outputs from the model torch.Size([4, 64, 513, 946])
for batch 2
predicted mask shape torch.Size([4, 1, 513, 946])
2025-02-22 01:18:56,530 - INFO - Appending Batch Losses: Mask: 0.3928694427013397, Hybrid: 0.7461320757865906, Combined: 0.3825552761554718
2025-02-22 01:18:57,543 - INFO - Appending Batch Losses: Mask: 0.4378070533275604, Hybrid: 0.8807953596115112, Combined: 0.7390210032463074
2025-02-22 01:18:58,541 - INFO - Appending Batch Losses: Mask: 0.30160650610923767, Hybrid: 0.5974063873291016, Combined: -0.02556896209716797
2025-02-22 01:18:59,541 - INFO - Appending Batch Losses: Mask: 0.44167065620422363, Hybrid: 0.7323586940765381, Combined: 0.6104052066802979
2025-02-22 01:19:00,557 - INFO - Appending Batch Losses: Mask: 0.40644899010658264, Hybrid: 0.7945924997329712, Combined: 0.6764026284217834
2025-02-22 01:19:30,012 - INFO - Appending Batch Losses: Mask: 0.39256027340888977, Hybrid: 0.7129501700401306, Combined: 0.5384876728057861
2025-02-22 01:19:31,035 - INFO - Appending Batch Losses: Mask: 0.33542895317077637, Hybrid: 0.5965566635131836, Combined: 0.5501881241798401
2025-02-22 01:19:32,658 - INFO - Appending Batch Losses: Mask: 0.41063934564590454, Hybrid: 0.6351058483123779, Combined: 0.6842113137245178
2025-02-22 01:19:33,973 - INFO - Appending Batch Losses: Mask: 0.3647550940513611, Hybrid: 0.5781347751617432, Combined: 0.49200400710105896
2025-02-22 01:19:34,971 - INFO - Appending Batch Losses: Mask: 0.4343913197517395, Hybrid: 0.7288094758987427, Combined: 0.46101200580596924
2025-02-22 01:19:35,992 - INFO - Appending Batch Losses: Mask: 0.5008178949356079, Hybrid: 0.8532471656799316, Combined: 0.8945069909095764
2025-02-22 01:19:58,383 - INFO - Appending Batch Losses: Mask: 0.3624219298362732, Hybrid: 0.5401418209075928, Combined: 0.6301523447036743
2025-02-22 01:19:59,357 - INFO - Appending Batch Losses: Mask: 0.5200914144515991, Hybrid: 0.8095544576644897, Combined: 0.8000420331954956
2025-02-22 01:20:00,344 - INFO - Appending Batch Losses: Mask: 0.40221187472343445, Hybrid: 0.7133363485336304, Combined: 0.7278642058372498
2025-02-22 01:20:01,335 - INFO - Appending Batch Losses: Mask: 0.42270898818969727, Hybrid: 0.6774002909660339, Combined: 0.5740005373954773
2025-02-22 01:20:02,322 - INFO - Appending Batch Losses: Mask: 0.3828744888305664, Hybrid: 0.6956934332847595, Combined: 0.5940364003181458
2025-02-22 01:20:03,593 - INFO - Appending Batch Losses: Mask: 0.45791327953338623, Hybrid: 0.7745891213417053, Combined: 0.7411068677902222
2025-02-22 01:20:36,389 - INFO - Appending Batch Losses: Mask: 0.3540365695953369, Hybrid: 0.6301888823509216, Combined: 0.49760985374450684
2025-02-22 01:20:37,360 - INFO - Appending Batch Losses: Mask: 0.5268469452857971, Hybrid: 0.7811700105667114, Combined: 0.7870115637779236
2025-02-22 01:20:38,342 - INFO - Appending Batch Losses: Mask: 0.4802303910255432, Hybrid: 0.7848860025405884, Combined: 0.34285596013069153
2025-02-22 01:20:39,331 - INFO - Appending Batch Losses: Mask: 0.4191954731941223, Hybrid: 0.7858187556266785, Combined: 0.7007529735565186
2025-02-22 01:20:40,322 - INFO - Appending Batch Losses: Mask: 0.40279361605644226, Hybrid: 0.8418248295783997, Combined: 0.5622212290763855
2025-02-22 01:20:41,324 - INFO - Appending Batch Losses: Mask: 0.5159014463424683, Hybrid: 0.7741971015930176, Combined: 0.627886176109314
2025-02-22 01:21:06,956 - INFO - Appending Batch Losses: Mask: 0.5503236055374146, Hybrid: 0.8976651430130005, Combined: 1.0810295343399048
2025-02-22 01:21:08,280 - INFO - Appending Batch Losses: Mask: 0.4415499269962311, Hybrid: 0.7056170701980591, Combined: 0.4891968369483948
2025-02-22 01:21:09,259 - INFO - Appending Batch Losses: Mask: 0.4774649739265442, Hybrid: 0.7842439413070679, Combined: 0.3772292137145996
2025-02-22 01:21:10,254 - INFO - Appending Batch Losses: Mask: 0.3331433832645416, Hybrid: 0.6731345653533936, Combined: 0.26018986105918884
2025-02-22 01:21:11,100 - INFO - Appending Batch Losses: Mask: 0.48972904682159424, Hybrid: 0.6950764656066895, Combined: 0.8785251975059509
2025-02-22 01:21:11,958 - INFO - Appending Batch Losses: Mask: 0.32097476720809937, Hybrid: 0.6049748659133911, Combined: 0.5070133805274963
2025-02-22 01:21:32,186 - INFO - Appending Batch Losses: Mask: 0.4137641489505768, Hybrid: 0.7244548797607422, Combined: 0.3704301714897156
2025-02-22 01:21:33,167 - INFO - Appending Batch Losses: Mask: 0.43457597494125366, Hybrid: 0.7174959182739258, Combined: 0.5803611874580383
2025-02-22 01:21:35,252 - INFO - Appending Batch Losses: Mask: 0.4541013538837433, Hybrid: 0.8272655606269836, Combined: 0.7951375246047974
2025-02-22 01:21:36,481 - INFO - Appending Batch Losses: Mask: 0.3900032937526703, Hybrid: 0.6221584677696228, Combined: 0.517284631729126
2025-02-22 01:21:37,455 - INFO - Appending Batch Losses: Mask: 0.514068603515625, Hybrid: 0.7346557378768921, Combined: 0.8162211179733276
2025-02-22 01:21:38,447 - INFO - Appending Batch Losses: Mask: 0.5089061260223389, Hybrid: 0.8200960159301758, Combined: 0.7011997103691101
2025-02-22 01:21:55,877 - INFO - Appending Batch Losses: Mask: 0.4590538442134857, Hybrid: 0.7484797239303589, Combined: 0.6635854840278625
2025-02-22 01:21:58,077 - INFO - Current Learning Rate 0.000842110322846229

2025-02-22 01:21:59,323 - INFO - Checkpoint saved: /mnt/c/Users/didri/Desktop/Programmering/ArtificalintelligenceModels/UNet-Model_Vocal_Isolation/Unet_model_Audio_Seperation/Model_Weights/CheckPoints/Training/checkpoint_epoch_3.pth
2025-02-22 01:21:59,323 - INFO - 
 [EPOCH 4]Model Checkpoint SAVED at epoch 4
 avg_epoch_loss: [0.598841]
 bestloss: [0.598841]
 Trigger times: 0/12

2025-02-22 01:23:32,635 - INFO - 
Trigger times: 0, patience: 15

2025-02-22 01:23:32,636 - INFO - 
Trigger times: 0, patience: 12

2025-02-22 01:23:32,636 - INFO - 
[Epoch Improvement] Epoch 4: Loss improved during training by 4.20% from previous epoch, 

2025-02-22 01:23:32,636 - INFO - ####LOGGING AVERAGE LOSS EPOCH###
[Epoch Summary] Epoch: 4/50, Avg Combined Loss: 0.598841, MaskLoss: 0.422357, Hybridloss: 0.735955Previous Epoch loss: 0.6251037136928456
2025-02-22 01:23:32,637 - INFO - Epoch: 4 COMPLETED





2025-02-22 01:23:32,642 - INFO - [Train] Epoch 5/50 started.

2025-02-22 01:24:06,529 - INFO - #####INPUTS & TARGETS VALUE [2 BATCHES]####
Batch 1: Mixture shape=torch.Size([4, 1, 513, 946]), Target shape=torch.Size([4, 1, 513, 946])
2025-02-22 01:24:07,377 - INFO - [EPOCH 5]outputs from the model torch.Size([4, 64, 513, 946])
for batch 1
predicted mask shape torch.Size([4, 1, 513, 946])
2025-02-22 01:24:08,721 - INFO - Function: [log_first_2_batches_outputs_inputs_targets_predicted_mask]
2025-02-22 01:24:08,724 - INFO - ####OUTPUTS, INPUTS, TARGETS,PREDICTEDMASK [2 BATCHES]####
Batch 1: Mask range: min=0.0000, max=106.9375
Batch 1: Inputs shape=torch.Size([4, 1, 513, 946]), Targets shape=torch.Size([4, 1, 513, 946]), Predicted Mask shape=torch.Size([4, 1, 513, 946]), Outputs shape=torch.Size([4, 64, 513, 946])
Mask min=0.0, max=1.0
[After Mask Application] Predicted vocals min: 0.0, max: 142.75

2025-02-22 01:24:08,724 - INFO - 
####LOSS VALUES####
[Combinedloss]:  Total treningsfeil, [BØR REDUSERES OVER TID]
[MaskLoss]: Sier hvor godt modellen lærer og predikere masken som isolerer vokaler[BØR REDUSERES OVER TID]
[l1_loss og stft_loss] gir ekstra indikasjoner på lydkvalitet.
[Hybridloss]: Kombinasjon av flere tapsfunksjoner[BØR REDUSERES OVER TID]

2025-02-22 01:24:08,740 - INFO - Appending Batch Losses: Mask: 0.4355688989162445, Hybrid: 0.8583487868309021, Combined: 0.9740283489227295
2025-02-22 01:24:09,587 - INFO - [EPOCH 5]outputs from the model torch.Size([3, 64, 513, 946])
for batch 2
predicted mask shape torch.Size([3, 1, 513, 946])
2025-02-22 01:24:10,881 - INFO - Appending Batch Losses: Mask: 0.4958387017250061, Hybrid: 0.7790712714195251, Combined: 0.4607853591442108
2025-02-22 01:24:11,754 - INFO - Appending Batch Losses: Mask: 0.5252938866615295, Hybrid: 0.8316107988357544, Combined: 0.8788251280784607
2025-02-22 01:24:13,567 - INFO - Appending Batch Losses: Mask: 0.3459551930427551, Hybrid: 0.6061110496520996, Combined: 0.46450889110565186
2025-02-22 01:24:21,608 - INFO - Appending Batch Losses: Mask: 0.46653133630752563, Hybrid: 0.7041316032409668, Combined: 0.5319551825523376
2025-02-22 01:24:22,609 - INFO - Appending Batch Losses: Mask: 0.4332073926925659, Hybrid: 0.6971315145492554, Combined: 0.7253295183181763
2025-02-22 01:24:34,660 - INFO - Appending Batch Losses: Mask: 0.3609960675239563, Hybrid: 0.6033062934875488, Combined: 0.4709017276763916
2025-02-22 01:24:35,679 - INFO - Appending Batch Losses: Mask: 0.33000171184539795, Hybrid: 0.553413450717926, Combined: 0.37048012018203735
2025-02-22 01:24:36,671 - INFO - Appending Batch Losses: Mask: 0.5415216088294983, Hybrid: 0.8603352308273315, Combined: 0.8058187961578369
2025-02-22 01:24:37,877 - INFO - Appending Batch Losses: Mask: 0.35413628816604614, Hybrid: 0.629096269607544, Combined: 0.12546753883361816
2025-02-22 01:24:48,971 - INFO - Appending Batch Losses: Mask: 0.686337947845459, Hybrid: 1.069851040840149, Combined: 1.099066972732544
2025-02-22 01:24:49,842 - INFO - Appending Batch Losses: Mask: 0.3917531371116638, Hybrid: 0.750861644744873, Combined: 0.34493306279182434
2025-02-22 01:25:07,055 - INFO - Appending Batch Losses: Mask: 0.4671931266784668, Hybrid: 0.9266060590744019, Combined: 0.4167836606502533
2025-02-22 01:25:08,055 - INFO - Appending Batch Losses: Mask: 0.44587355852127075, Hybrid: 0.7197504043579102, Combined: 0.6599660515785217
2025-02-22 01:25:09,889 - INFO - Appending Batch Losses: Mask: 0.3954731822013855, Hybrid: 0.7243458032608032, Combined: 0.42825087904930115
2025-02-22 01:25:10,876 - INFO - Appending Batch Losses: Mask: 0.428094744682312, Hybrid: 0.9232057332992554, Combined: 0.5283176898956299
2025-02-22 01:25:15,212 - INFO - Appending Batch Losses: Mask: 0.3155766427516937, Hybrid: 0.6958345174789429, Combined: 0.10371196269989014
2025-02-22 01:25:16,206 - INFO - Appending Batch Losses: Mask: 0.5397143363952637, Hybrid: 0.8480210900306702, Combined: 1.0290021896362305
2025-02-22 01:25:41,328 - INFO - Appending Batch Losses: Mask: 0.3675280213356018, Hybrid: 0.5889934301376343, Combined: 0.3529480993747711
2025-02-22 01:25:42,319 - INFO - Appending Batch Losses: Mask: 0.32737699151039124, Hybrid: 0.5935235023498535, Combined: 0.4630553722381592
2025-02-22 01:25:47,922 - INFO - Appending Batch Losses: Mask: 0.40056174993515015, Hybrid: 0.6518474221229553, Combined: 0.4629344940185547
2025-02-22 01:25:48,912 - INFO - Appending Batch Losses: Mask: 0.43101584911346436, Hybrid: 0.8109368681907654, Combined: 0.5182859301567078
2025-02-22 01:25:49,916 - INFO - Appending Batch Losses: Mask: 0.41439950466156006, Hybrid: 0.6512289643287659, Combined: 0.5298702120780945
2025-02-22 01:25:50,933 - INFO - Appending Batch Losses: Mask: 0.36355072259902954, Hybrid: 0.6176510453224182, Combined: 0.37547069787979126
2025-02-22 01:26:23,714 - INFO - Appending Batch Losses: Mask: 0.40444082021713257, Hybrid: 0.7710648775100708, Combined: 0.5088449716567993
2025-02-22 01:26:24,699 - INFO - Appending Batch Losses: Mask: 0.4814549684524536, Hybrid: 0.8005786538124084, Combined: 0.7019765973091125
2025-02-22 01:26:27,445 - INFO - Appending Batch Losses: Mask: 0.41061946749687195, Hybrid: 0.6848516464233398, Combined: 0.7741273045539856
2025-02-22 01:26:28,449 - INFO - Appending Batch Losses: Mask: 0.293705016374588, Hybrid: 0.45924732089042664, Combined: 0.5399872660636902
2025-02-22 01:26:29,688 - INFO - Appending Batch Losses: Mask: 0.4108840227127075, Hybrid: 0.7890335917472839, Combined: 0.7369083762168884
2025-02-22 01:26:30,686 - INFO - Appending Batch Losses: Mask: 0.4811003506183624, Hybrid: 0.7590442895889282, Combined: 0.730002760887146
2025-02-22 01:26:50,428 - INFO - Appending Batch Losses: Mask: 0.3988662660121918, Hybrid: 0.6622482538223267, Combined: 0.7967996597290039
2025-02-22 01:26:51,406 - INFO - Appending Batch Losses: Mask: 0.5714027881622314, Hybrid: 0.8807872533798218, Combined: 0.9169639945030212
2025-02-22 01:26:52,392 - INFO - Appending Batch Losses: Mask: 0.23029880225658417, Hybrid: 0.42238688468933105, Combined: 0.5308645963668823
2025-02-22 01:26:53,365 - INFO - Appending Batch Losses: Mask: 0.3252273499965668, Hybrid: 0.5765392780303955, Combined: 0.5432714223861694
2025-02-22 01:26:54,344 - INFO - Appending Batch Losses: Mask: 0.5036566853523254, Hybrid: 0.7571582794189453, Combined: 0.6359373331069946
2025-02-22 01:26:55,334 - INFO - Appending Batch Losses: Mask: 0.48468950390815735, Hybrid: 0.9557157754898071, Combined: 0.5597939491271973
2025-02-22 01:27:10,482 - INFO - Appending Batch Losses: Mask: 0.475990355014801, Hybrid: 0.7077960968017578, Combined: 0.713871419429779
2025-02-22 01:27:12,901 - INFO - Current Learning Rate 0.0008562705504037769

2025-02-22 01:27:14,314 - INFO - Checkpoint saved: /mnt/c/Users/didri/Desktop/Programmering/ArtificalintelligenceModels/UNet-Model_Vocal_Isolation/Unet_model_Audio_Seperation/Model_Weights/CheckPoints/Training/checkpoint_epoch_4.pth
2025-02-22 01:27:14,314 - INFO - 
 [EPOCH 5]Model Checkpoint SAVED at epoch 5
 avg_epoch_loss: [0.589461]
 bestloss: [0.589461]
 Trigger times: 0/12

2025-02-22 01:28:40,831 - INFO - 
Trigger times: 1, patience: 15

2025-02-22 01:28:40,831 - INFO - 
Trigger times: 1, patience: 12

2025-02-22 01:28:40,831 - INFO - 
[Epoch Improvement] Epoch 5: Loss improved during training by 1.57% from previous epoch, 

2025-02-22 01:28:40,833 - INFO - ####LOGGING AVERAGE LOSS EPOCH###
[Epoch Summary] Epoch: 5/50, Avg Combined Loss: 0.589461, MaskLoss: 0.422944, Hybridloss: 0.734287Previous Epoch loss: 0.5988411790615803
2025-02-22 01:28:40,834 - INFO - Epoch: 5 COMPLETED





2025-02-22 01:28:40,835 - INFO - [Train] Epoch 6/50 started.

2025-02-22 01:29:06,768 - INFO - #####INPUTS & TARGETS VALUE [2 BATCHES]####
Batch 1: Mixture shape=torch.Size([4, 1, 513, 946]), Target shape=torch.Size([4, 1, 513, 946])
2025-02-22 01:29:07,782 - INFO - [EPOCH 6]outputs from the model torch.Size([4, 64, 513, 946])
for batch 1
predicted mask shape torch.Size([4, 1, 513, 946])
2025-02-22 01:29:08,975 - INFO - Function: [log_first_2_batches_outputs_inputs_targets_predicted_mask]
2025-02-22 01:29:08,978 - INFO - ####OUTPUTS, INPUTS, TARGETS,PREDICTEDMASK [2 BATCHES]####
Batch 1: Mask range: min=0.0000, max=108.4375
Batch 1: Inputs shape=torch.Size([4, 1, 513, 946]), Targets shape=torch.Size([4, 1, 513, 946]), Predicted Mask shape=torch.Size([4, 1, 513, 946]), Outputs shape=torch.Size([4, 64, 513, 946])
Mask min=0.0, max=1.0
[After Mask Application] Predicted vocals min: 0.0, max: 137.25

2025-02-22 01:29:08,978 - INFO - 
####LOSS VALUES####
[Combinedloss]:  Total treningsfeil, [BØR REDUSERES OVER TID]
[MaskLoss]: Sier hvor godt modellen lærer og predikere masken som isolerer vokaler[BØR REDUSERES OVER TID]
[l1_loss og stft_loss] gir ekstra indikasjoner på lydkvalitet.
[Hybridloss]: Kombinasjon av flere tapsfunksjoner[BØR REDUSERES OVER TID]

2025-02-22 01:29:08,990 - INFO - Appending Batch Losses: Mask: 0.31939631700515747, Hybrid: 0.6436327695846558, Combined: 0.6160898208618164
2025-02-22 01:29:09,963 - INFO - [EPOCH 6]outputs from the model torch.Size([4, 64, 513, 946])
for batch 2
predicted mask shape torch.Size([4, 1, 513, 946])
2025-02-22 01:29:11,052 - INFO - Appending Batch Losses: Mask: 0.31820544600486755, Hybrid: 0.570859432220459, Combined: 0.6358784437179565
2025-02-22 01:29:16,656 - INFO - Appending Batch Losses: Mask: 0.5576797723770142, Hybrid: 0.8859696984291077, Combined: 0.8910748958587646
2025-02-22 01:29:17,690 - INFO - Appending Batch Losses: Mask: 0.4109194278717041, Hybrid: 0.6452271938323975, Combined: 0.5782171487808228
2025-02-22 01:29:20,038 - INFO - Appending Batch Losses: Mask: 0.36015695333480835, Hybrid: 0.613654375076294, Combined: 0.5700908899307251
2025-02-22 01:29:21,049 - INFO - Appending Batch Losses: Mask: 0.41892728209495544, Hybrid: 0.6727616786956787, Combined: 0.47573453187942505
2025-02-22 01:29:48,763 - INFO - Appending Batch Losses: Mask: 0.4752136468887329, Hybrid: 0.8199818730354309, Combined: 0.5292342901229858
2025-02-22 01:29:50,068 - INFO - Appending Batch Losses: Mask: 0.46041661500930786, Hybrid: 0.7426125407218933, Combined: 0.6477059125900269
2025-02-22 01:29:51,052 - INFO - Appending Batch Losses: Mask: 0.5927938222885132, Hybrid: 1.2254389524459839, Combined: 0.9368869662284851
2025-02-22 01:29:52,060 - INFO - Appending Batch Losses: Mask: 0.38842809200286865, Hybrid: 0.6404932737350464, Combined: 0.6591182351112366
2025-02-22 01:29:53,080 - INFO - Appending Batch Losses: Mask: 0.30306461453437805, Hybrid: 0.5977342128753662, Combined: 0.66838139295578
2025-02-22 01:29:54,086 - INFO - Appending Batch Losses: Mask: 0.39740389585494995, Hybrid: 0.6752510070800781, Combined: 0.4353243112564087
2025-02-22 01:30:29,254 - INFO - Appending Batch Losses: Mask: 0.3728083670139313, Hybrid: 0.890270471572876, Combined: 0.3526669442653656
2025-02-22 01:30:30,129 - INFO - Appending Batch Losses: Mask: 0.44200971722602844, Hybrid: 0.7032679319381714, Combined: 0.6644907593727112
2025-02-22 01:30:31,125 - INFO - Appending Batch Losses: Mask: 0.5484840869903564, Hybrid: 0.8182370662689209, Combined: 0.8721791505813599
2025-02-22 01:30:32,380 - INFO - Appending Batch Losses: Mask: 0.3856361508369446, Hybrid: 0.6924569606781006, Combined: 0.4044874310493469
2025-02-22 01:30:33,373 - INFO - Appending Batch Losses: Mask: 0.5329403281211853, Hybrid: 0.8365751504898071, Combined: 0.7271000742912292
2025-02-22 01:30:34,354 - INFO - Appending Batch Losses: Mask: 0.5325980186462402, Hybrid: 0.789635956287384, Combined: 0.9111043810844421
2025-02-22 01:31:05,932 - INFO - Appending Batch Losses: Mask: 0.4537854492664337, Hybrid: 0.776776909828186, Combined: 0.7279461622238159
2025-02-22 01:31:06,907 - INFO - Appending Batch Losses: Mask: 0.32649677991867065, Hybrid: 0.5485981702804565, Combined: 0.27586203813552856
2025-02-22 01:31:07,902 - INFO - Appending Batch Losses: Mask: 0.3321736454963684, Hybrid: 0.5224639773368835, Combined: 0.4958381652832031
2025-02-22 01:31:08,741 - INFO - Appending Batch Losses: Mask: 0.4794062674045563, Hybrid: 0.7165969610214233, Combined: 0.6932948231697083
2025-02-22 01:31:09,597 - INFO - Appending Batch Losses: Mask: 0.4682251811027527, Hybrid: 0.7442628145217896, Combined: 0.5679932832717896
2025-02-22 01:31:10,849 - INFO - Appending Batch Losses: Mask: 0.5581539869308472, Hybrid: 0.8382365703582764, Combined: 0.779586136341095
2025-02-22 01:31:31,936 - INFO - Appending Batch Losses: Mask: 0.2896357476711273, Hybrid: 0.6416183710098267, Combined: 0.16066649556159973
2025-02-22 01:31:32,922 - INFO - Appending Batch Losses: Mask: 0.46837982535362244, Hybrid: 0.726138710975647, Combined: 0.5124348402023315
2025-02-22 01:31:33,936 - INFO - Appending Batch Losses: Mask: 0.39692890644073486, Hybrid: 0.7220569849014282, Combined: 0.47737210988998413
2025-02-22 01:31:34,932 - INFO - Appending Batch Losses: Mask: 0.5390315651893616, Hybrid: 0.812485933303833, Combined: 0.8086777329444885
2025-02-22 01:31:35,766 - INFO - Appending Batch Losses: Mask: 0.3934662342071533, Hybrid: 0.7708590626716614, Combined: 0.4148319363594055
2025-02-22 01:31:36,491 - INFO - Appending Batch Losses: Mask: 0.36653661727905273, Hybrid: 0.6042335033416748, Combined: 0.2504473030567169
2025-02-22 01:31:52,965 - INFO - Appending Batch Losses: Mask: 0.4499157965183258, Hybrid: 0.7414249181747437, Combined: 0.7012580037117004
2025-02-22 01:31:54,159 - INFO - Appending Batch Losses: Mask: 0.4022960364818573, Hybrid: 0.6560684442520142, Combined: 0.5860028862953186
2025-02-22 01:32:05,049 - INFO - Appending Batch Losses: Mask: 0.34986501932144165, Hybrid: 0.624704122543335, Combined: 0.4441918730735779
2025-02-22 01:32:06,028 - INFO - Appending Batch Losses: Mask: 0.5647612810134888, Hybrid: 1.0570213794708252, Combined: 0.7237895131111145
2025-02-22 01:32:07,004 - INFO - Appending Batch Losses: Mask: 0.49854809045791626, Hybrid: 0.8841507434844971, Combined: 0.6489455699920654
2025-02-22 01:32:07,986 - INFO - Appending Batch Losses: Mask: 0.44254136085510254, Hybrid: 0.7619854211807251, Combined: 0.5026041865348816
2025-02-22 01:32:17,008 - INFO - Appending Batch Losses: Mask: 0.4361294209957123, Hybrid: 0.7261518239974976, Combined: 0.8963128328323364
2025-02-22 01:32:19,252 - INFO - Current Learning Rate 0.0008669171007061202

2025-02-22 01:32:19,252 - INFO - 
[EPOCH 6]No improvement, NO NEW MODEL CHECKPOINT SAVED at epoch 6
 avg_epoch_loss: [0.601184]
 bestloss: [0.589461]
 Trigger: 2/12

2025-02-22 01:33:47,583 - INFO - 
Trigger times: 2, patience: 15

2025-02-22 01:33:47,584 - INFO - 
Trigger times: 2, patience: 12

2025-02-22 01:33:47,584 - INFO - 
[Epoch Improvement] Epoch 6: Loss improved during training by -1.99% from previous epoch, 

2025-02-22 01:33:47,584 - INFO - ####LOGGING AVERAGE LOSS EPOCH###
[Epoch Summary] Epoch: 6/50, Avg Combined Loss: 0.601184, MaskLoss: 0.424676, Hybridloss: 0.735058Previous Epoch loss: 0.5894607442456323
2025-02-22 01:33:47,585 - INFO - Epoch: 6 COMPLETED





2025-02-22 01:33:47,586 - INFO - [Train] Epoch 7/50 started.

2025-02-22 01:34:25,691 - INFO - #####INPUTS & TARGETS VALUE [2 BATCHES]####
Batch 1: Mixture shape=torch.Size([3, 1, 513, 946]), Target shape=torch.Size([3, 1, 513, 946])
2025-02-22 01:34:26,475 - INFO - [EPOCH 7]outputs from the model torch.Size([3, 64, 513, 946])
for batch 1
predicted mask shape torch.Size([3, 1, 513, 946])
2025-02-22 01:34:27,816 - INFO - Function: [log_first_2_batches_outputs_inputs_targets_predicted_mask]
2025-02-22 01:34:27,819 - INFO - ####OUTPUTS, INPUTS, TARGETS,PREDICTEDMASK [2 BATCHES]####
Batch 1: Mask range: min=0.0000, max=81.4375
Batch 1: Inputs shape=torch.Size([3, 1, 513, 946]), Targets shape=torch.Size([3, 1, 513, 946]), Predicted Mask shape=torch.Size([3, 1, 513, 946]), Outputs shape=torch.Size([3, 64, 513, 946])
Mask min=0.0, max=1.0
[After Mask Application] Predicted vocals min: 0.0, max: 161.375

2025-02-22 01:34:27,819 - INFO - 
####LOSS VALUES####
[Combinedloss]:  Total treningsfeil, [BØR REDUSERES OVER TID]
[MaskLoss]: Sier hvor godt modellen lærer og predikere masken som isolerer vokaler[BØR REDUSERES OVER TID]
[l1_loss og stft_loss] gir ekstra indikasjoner på lydkvalitet.
[Hybridloss]: Kombinasjon av flere tapsfunksjoner[BØR REDUSERES OVER TID]

2025-02-22 01:34:27,833 - INFO - Appending Batch Losses: Mask: 0.2644674479961395, Hybrid: 0.5163291096687317, Combined: 0.10702934861183167
2025-02-22 01:34:28,679 - INFO - [EPOCH 7]outputs from the model torch.Size([4, 64, 513, 946])
for batch 2
predicted mask shape torch.Size([4, 1, 513, 946])
2025-02-22 01:34:29,988 - INFO - Appending Batch Losses: Mask: 0.42838719487190247, Hybrid: 0.8836656808853149, Combined: 0.6755178570747375
2025-02-22 01:34:31,262 - INFO - Appending Batch Losses: Mask: 0.4244459867477417, Hybrid: 0.7383586168289185, Combined: 0.6125433444976807
2025-02-22 01:34:32,251 - INFO - Appending Batch Losses: Mask: 0.35130733251571655, Hybrid: 0.6376967430114746, Combined: 0.4484269320964813
2025-02-22 01:34:33,260 - INFO - Appending Batch Losses: Mask: 0.5107017755508423, Hybrid: 0.9173920154571533, Combined: 0.6420446038246155
2025-02-22 01:34:34,253 - INFO - Appending Batch Losses: Mask: 0.46494805812835693, Hybrid: 0.7919593453407288, Combined: 0.5992612838745117
2025-02-22 01:35:00,813 - INFO - Appending Batch Losses: Mask: 0.3713929057121277, Hybrid: 0.5912787914276123, Combined: 0.44876405596733093
2025-02-22 01:35:01,521 - INFO - Appending Batch Losses: Mask: 0.5522462725639343, Hybrid: 0.8025708198547363, Combined: 0.7608915567398071
2025-02-22 01:35:16,316 - INFO - Appending Batch Losses: Mask: 0.37350988388061523, Hybrid: 0.5890666842460632, Combined: 0.39722269773483276
2025-02-22 01:35:17,307 - INFO - Appending Batch Losses: Mask: 0.4294232726097107, Hybrid: 0.724338173866272, Combined: 0.5879572629928589
2025-02-22 01:35:18,540 - INFO - Appending Batch Losses: Mask: 0.477857381105423, Hybrid: 0.8304167985916138, Combined: 0.5551571846008301
2025-02-22 01:35:19,511 - INFO - Appending Batch Losses: Mask: 0.4739149510860443, Hybrid: 0.7605783939361572, Combined: 0.7455511093139648
2025-02-22 01:35:20,493 - INFO - Appending Batch Losses: Mask: 0.42062342166900635, Hybrid: 0.7107974290847778, Combined: 0.5114237666130066
2025-02-22 01:35:21,481 - INFO - Appending Batch Losses: Mask: 0.4391655921936035, Hybrid: 0.7626043558120728, Combined: 0.5664696097373962
2025-02-22 01:35:52,002 - INFO - Appending Batch Losses: Mask: 0.3958365321159363, Hybrid: 0.758660614490509, Combined: 0.5621826648712158
2025-02-22 01:35:52,993 - INFO - Appending Batch Losses: Mask: 0.52288818359375, Hybrid: 0.9200775623321533, Combined: 0.8489569425582886
2025-02-22 01:35:53,985 - INFO - Appending Batch Losses: Mask: 0.4348471164703369, Hybrid: 0.7231026887893677, Combined: 0.6944653391838074
2025-02-22 01:35:54,985 - INFO - Appending Batch Losses: Mask: 0.46376916766166687, Hybrid: 0.7509792447090149, Combined: 0.5938294529914856
2025-02-22 01:35:56,224 - INFO - Appending Batch Losses: Mask: 0.3985762894153595, Hybrid: 0.5939996242523193, Combined: 0.702954888343811
2025-02-22 01:35:57,215 - INFO - Appending Batch Losses: Mask: 0.4859057664871216, Hybrid: 0.8027081489562988, Combined: 0.9587433338165283
2025-02-22 01:36:13,951 - INFO - Appending Batch Losses: Mask: 0.47135812044143677, Hybrid: 0.7198116779327393, Combined: 0.6754177212715149
2025-02-22 01:36:14,931 - INFO - Appending Batch Losses: Mask: 0.4225403964519501, Hybrid: 0.8431302309036255, Combined: 0.603300929069519
2025-02-22 01:36:15,913 - INFO - Appending Batch Losses: Mask: 0.4488370418548584, Hybrid: 0.8124757409095764, Combined: 0.6607480645179749
2025-02-22 01:36:16,893 - INFO - Appending Batch Losses: Mask: 0.40695327520370483, Hybrid: 0.6951642036437988, Combined: 0.6110531687736511
2025-02-22 01:36:17,869 - INFO - Appending Batch Losses: Mask: 0.3468405604362488, Hybrid: 0.5583968162536621, Combined: 0.4625324010848999
2025-02-22 01:36:18,846 - INFO - Appending Batch Losses: Mask: 0.4038310647010803, Hybrid: 0.6148916482925415, Combined: 0.6993148922920227
2025-02-22 01:36:33,822 - INFO - Appending Batch Losses: Mask: 0.42098212242126465, Hybrid: 0.6685769557952881, Combined: 0.6234962940216064
2025-02-22 01:36:34,803 - INFO - Appending Batch Losses: Mask: 0.43432608246803284, Hybrid: 0.7094433903694153, Combined: 0.9646943807601929
2025-02-22 01:36:35,789 - INFO - Appending Batch Losses: Mask: 0.39188748598098755, Hybrid: 0.7406201362609863, Combined: 0.4370708465576172
2025-02-22 01:36:36,783 - INFO - Appending Batch Losses: Mask: 0.38130778074264526, Hybrid: 0.6614137887954712, Combined: 0.6270776391029358
2025-02-22 01:36:47,235 - INFO - Appending Batch Losses: Mask: 0.3662828803062439, Hybrid: 0.687394380569458, Combined: 0.15677058696746826
2025-02-22 01:36:48,212 - INFO - Appending Batch Losses: Mask: 0.35349032282829285, Hybrid: 0.8142601251602173, Combined: 0.16660022735595703
2025-02-22 01:36:59,216 - INFO - Appending Batch Losses: Mask: 0.3949507772922516, Hybrid: 0.6227735280990601, Combined: 0.6520751714706421
2025-02-22 01:37:00,190 - INFO - Appending Batch Losses: Mask: 0.48770394921302795, Hybrid: 0.7207499742507935, Combined: 0.5284110307693481
2025-02-22 01:37:03,313 - INFO - Appending Batch Losses: Mask: 0.40005171298980713, Hybrid: 0.6896693110466003, Combined: 0.627960741519928
2025-02-22 01:37:04,289 - INFO - Appending Batch Losses: Mask: 0.3120528757572174, Hybrid: 0.5640134811401367, Combined: -0.05620700120925903
2025-02-22 01:37:20,921 - INFO - Appending Batch Losses: Mask: 0.5427667498588562, Hybrid: 0.8835954666137695, Combined: 0.6979572772979736
2025-02-22 01:37:23,159 - INFO - Current Learning Rate 0.0008794731583151618

2025-02-22 01:37:24,593 - INFO - Checkpoint saved: /mnt/c/Users/didri/Desktop/Programmering/ArtificalintelligenceModels/UNet-Model_Vocal_Isolation/Unet_model_Audio_Seperation/Model_Weights/CheckPoints/Training/checkpoint_epoch_6.pth
2025-02-22 01:37:24,593 - INFO - 
 [EPOCH 7]Model Checkpoint SAVED at epoch 7
 avg_epoch_loss: [0.571829]
 bestloss: [0.571829]
 Trigger times: 0/12

2025-02-22 01:38:49,389 - INFO - 
Trigger times: 3, patience: 15

2025-02-22 01:38:49,389 - INFO - 
Trigger times: 3, patience: 12

2025-02-22 01:38:49,389 - INFO - 
[Epoch Improvement] Epoch 7: Loss improved during training by 4.88% from previous epoch, 

2025-02-22 01:38:49,390 - INFO - ####LOGGING AVERAGE LOSS EPOCH###
[Epoch Summary] Epoch: 7/50, Avg Combined Loss: 0.571829, MaskLoss: 0.424511, Hybridloss: 0.733575Previous Epoch loss: 0.601184364106204
2025-02-22 01:38:49,390 - INFO - Epoch: 7 COMPLETED





2025-02-22 01:38:49,391 - INFO - [Train] Epoch 8/50 started.

2025-02-22 01:39:27,338 - INFO - #####INPUTS & TARGETS VALUE [2 BATCHES]####
Batch 1: Mixture shape=torch.Size([4, 1, 513, 946]), Target shape=torch.Size([4, 1, 513, 946])
2025-02-22 01:39:28,274 - INFO - [EPOCH 8]outputs from the model torch.Size([4, 64, 513, 946])
for batch 1
predicted mask shape torch.Size([4, 1, 513, 946])
2025-02-22 01:39:29,431 - INFO - Function: [log_first_2_batches_outputs_inputs_targets_predicted_mask]
2025-02-22 01:39:29,434 - INFO - ####OUTPUTS, INPUTS, TARGETS,PREDICTEDMASK [2 BATCHES]####
Batch 1: Mask range: min=0.0000, max=73.5000
Batch 1: Inputs shape=torch.Size([4, 1, 513, 946]), Targets shape=torch.Size([4, 1, 513, 946]), Predicted Mask shape=torch.Size([4, 1, 513, 946]), Outputs shape=torch.Size([4, 64, 513, 946])
Mask min=0.0, max=1.0
[After Mask Application] Predicted vocals min: 0.0, max: 143.125

2025-02-22 01:39:29,434 - INFO - 
####LOSS VALUES####
[Combinedloss]:  Total treningsfeil, [BØR REDUSERES OVER TID]
[MaskLoss]: Sier hvor godt modellen lærer og predikere masken som isolerer vokaler[BØR REDUSERES OVER TID]
[l1_loss og stft_loss] gir ekstra indikasjoner på lydkvalitet.
[Hybridloss]: Kombinasjon av flere tapsfunksjoner[BØR REDUSERES OVER TID]

2025-02-22 01:39:29,446 - INFO - Appending Batch Losses: Mask: 0.42981499433517456, Hybrid: 0.8212949633598328, Combined: 0.628476619720459
2025-02-22 01:39:33,833 - INFO - [EPOCH 8]outputs from the model torch.Size([4, 64, 513, 946])
for batch 2
predicted mask shape torch.Size([4, 1, 513, 946])
2025-02-22 01:39:35,097 - INFO - Appending Batch Losses: Mask: 0.3608372211456299, Hybrid: 0.6076569557189941, Combined: 0.5363397598266602
2025-02-22 01:39:36,103 - INFO - Appending Batch Losses: Mask: 0.37278053164482117, Hybrid: 0.6506596803665161, Combined: 0.42611509561538696
2025-02-22 01:39:37,099 - INFO - Appending Batch Losses: Mask: 0.4400170147418976, Hybrid: 0.9487087726593018, Combined: 0.6656424403190613
2025-02-22 01:39:38,106 - INFO - Appending Batch Losses: Mask: 0.4188585877418518, Hybrid: 0.7560515403747559, Combined: 0.401619017124176
2025-02-22 01:39:39,395 - INFO - Appending Batch Losses: Mask: 0.42371228337287903, Hybrid: 0.8382279276847839, Combined: 0.5224612951278687
2025-02-22 01:39:51,956 - INFO - Appending Batch Losses: Mask: 0.4050114154815674, Hybrid: 0.6543149352073669, Combined: 0.526741623878479
2025-02-22 01:40:08,072 - INFO - Appending Batch Losses: Mask: 0.47042176127433777, Hybrid: 0.7241171002388, Combined: 0.40633833408355713
2025-02-22 01:40:09,050 - INFO - Appending Batch Losses: Mask: 0.4892919659614563, Hybrid: 0.7854073643684387, Combined: 0.6237590312957764
2025-02-22 01:40:10,030 - INFO - Appending Batch Losses: Mask: 0.4015296995639801, Hybrid: 0.647743821144104, Combined: 0.48654356598854065
2025-02-22 01:40:11,037 - INFO - Appending Batch Losses: Mask: 0.4512300491333008, Hybrid: 0.7689254283905029, Combined: 0.42875051498413086
2025-02-22 01:40:12,027 - INFO - Appending Batch Losses: Mask: 0.4998776316642761, Hybrid: 0.8328797817230225, Combined: 0.6618301868438721
2025-02-22 01:40:13,075 - INFO - Appending Batch Losses: Mask: 0.2745603919029236, Hybrid: 0.4696926176548004, Combined: 0.8034777641296387
2025-02-22 01:40:33,312 - INFO - Appending Batch Losses: Mask: 0.47753649950027466, Hybrid: 0.7916653752326965, Combined: 0.8011395931243896
2025-02-22 01:40:34,291 - INFO - Appending Batch Losses: Mask: 0.38621821999549866, Hybrid: 0.7785776257514954, Combined: 0.7215035557746887
2025-02-22 01:40:35,306 - INFO - Appending Batch Losses: Mask: 0.4019104540348053, Hybrid: 0.7666833400726318, Combined: 0.4604244530200958
2025-02-22 01:40:49,304 - INFO - Appending Batch Losses: Mask: 0.37828874588012695, Hybrid: 0.6517636775970459, Combined: 0.3482873737812042
2025-02-22 01:40:50,286 - INFO - Appending Batch Losses: Mask: 0.3690086007118225, Hybrid: 0.6415623426437378, Combined: 0.14351209998130798
2025-02-22 01:40:51,260 - INFO - Appending Batch Losses: Mask: 0.41067638993263245, Hybrid: 0.7243181467056274, Combined: 0.5529429912567139
2025-02-22 01:41:03,354 - INFO - Appending Batch Losses: Mask: 0.39244720339775085, Hybrid: 0.6695016026496887, Combined: 0.4344736933708191
2025-02-22 01:41:04,346 - INFO - Appending Batch Losses: Mask: 0.3121032118797302, Hybrid: 0.5629510283470154, Combined: 0.5029548406600952
2025-02-22 01:41:05,591 - INFO - Appending Batch Losses: Mask: 0.4501070976257324, Hybrid: 0.8546230792999268, Combined: 0.7149943113327026
2025-02-22 01:41:27,254 - INFO - Appending Batch Losses: Mask: 0.44035768508911133, Hybrid: 0.9814029932022095, Combined: 0.5932786464691162
2025-02-22 01:41:28,243 - INFO - Appending Batch Losses: Mask: 0.34393978118896484, Hybrid: 0.6096289753913879, Combined: 0.5693396329879761
2025-02-22 01:41:29,211 - INFO - Appending Batch Losses: Mask: 0.45196476578712463, Hybrid: 0.6535720825195312, Combined: 0.7569487690925598
2025-02-22 01:41:38,391 - INFO - Appending Batch Losses: Mask: 0.35752129554748535, Hybrid: 0.6917502880096436, Combined: 0.2863801121711731
2025-02-22 01:41:39,367 - INFO - Appending Batch Losses: Mask: 0.42455005645751953, Hybrid: 0.6171692609786987, Combined: 0.820765495300293
2025-02-22 01:41:40,329 - INFO - Appending Batch Losses: Mask: 0.4776816964149475, Hybrid: 0.700343668460846, Combined: 0.6537976264953613
2025-02-22 01:41:52,404 - INFO - Appending Batch Losses: Mask: 0.33259302377700806, Hybrid: 0.7046756148338318, Combined: 0.38693201541900635
2025-02-22 01:41:53,647 - INFO - Appending Batch Losses: Mask: 0.4267292618751526, Hybrid: 0.6657825708389282, Combined: 0.6255453824996948
2025-02-22 01:41:54,612 - INFO - Appending Batch Losses: Mask: 0.4965166747570038, Hybrid: 0.7575229406356812, Combined: 0.5201509594917297
2025-02-22 01:41:57,809 - INFO - Appending Batch Losses: Mask: 0.43675658106803894, Hybrid: 0.7518457174301147, Combined: 0.7084207534790039
2025-02-22 01:41:58,782 - INFO - Appending Batch Losses: Mask: 0.35196003317832947, Hybrid: 0.7779257893562317, Combined: 0.4990605115890503
2025-02-22 01:41:59,751 - INFO - Appending Batch Losses: Mask: 0.49362993240356445, Hybrid: 0.9019675254821777, Combined: 0.8697152137756348
2025-02-22 01:42:09,170 - INFO - Appending Batch Losses: Mask: 0.604047954082489, Hybrid: 0.9649016857147217, Combined: 0.9492772817611694
2025-02-22 01:42:10,014 - INFO - Appending Batch Losses: Mask: 0.3946983814239502, Hybrid: 0.7092254161834717, Combined: 0.646209716796875
2025-02-22 01:42:10,984 - INFO - Appending Batch Losses: Mask: 0.39246347546577454, Hybrid: 0.6864727735519409, Combined: 0.50467848777771
2025-02-22 01:42:13,396 - INFO - Current Learning Rate 0.000891285806395949

2025-02-22 01:42:13,397 - INFO - 
[EPOCH 8]No improvement, NO NEW MODEL CHECKPOINT SAVED at epoch 8
 avg_epoch_loss: [0.572671]
 bestloss: [0.571829]
 Trigger: 4/12

2025-02-22 01:43:42,014 - INFO - 
Trigger times: 4, patience: 15

2025-02-22 01:43:42,015 - INFO - 
Trigger times: 4, patience: 12

2025-02-22 01:43:42,015 - INFO - 
[Epoch Improvement] Epoch 8: Loss improved during training by -0.15% from previous epoch, 

2025-02-22 01:43:42,015 - INFO - ####LOGGING AVERAGE LOSS EPOCH###
[Epoch Summary] Epoch: 8/50, Avg Combined Loss: 0.572671, MaskLoss: 0.423615, Hybridloss: 0.733505Previous Epoch loss: 0.5718288542451085
2025-02-22 01:43:42,016 - INFO - Epoch: 8 COMPLETED





2025-02-22 01:43:42,017 - INFO - [Train] Epoch 9/50 started.

2025-02-22 01:44:05,537 - INFO - #####INPUTS & TARGETS VALUE [2 BATCHES]####
Batch 1: Mixture shape=torch.Size([4, 1, 513, 946]), Target shape=torch.Size([4, 1, 513, 946])
2025-02-22 01:44:06,259 - INFO - [EPOCH 9]outputs from the model torch.Size([4, 64, 513, 946])
for batch 1
predicted mask shape torch.Size([4, 1, 513, 946])
2025-02-22 01:44:07,480 - INFO - Function: [log_first_2_batches_outputs_inputs_targets_predicted_mask]
2025-02-22 01:44:07,483 - INFO - ####OUTPUTS, INPUTS, TARGETS,PREDICTEDMASK [2 BATCHES]####
Batch 1: Mask range: min=0.0000, max=75.9375
Batch 1: Inputs shape=torch.Size([4, 1, 513, 946]), Targets shape=torch.Size([4, 1, 513, 946]), Predicted Mask shape=torch.Size([4, 1, 513, 946]), Outputs shape=torch.Size([4, 64, 513, 946])
Mask min=0.0, max=1.0
[After Mask Application] Predicted vocals min: 0.0, max: 153.375

2025-02-22 01:44:07,483 - INFO - 
####LOSS VALUES####
[Combinedloss]:  Total treningsfeil, [BØR REDUSERES OVER TID]
[MaskLoss]: Sier hvor godt modellen lærer og predikere masken som isolerer vokaler[BØR REDUSERES OVER TID]
[l1_loss og stft_loss] gir ekstra indikasjoner på lydkvalitet.
[Hybridloss]: Kombinasjon av flere tapsfunksjoner[BØR REDUSERES OVER TID]

2025-02-22 01:44:07,504 - INFO - Appending Batch Losses: Mask: 0.38984790444374084, Hybrid: 0.615009605884552, Combined: 0.5143149495124817
2025-02-22 01:44:19,111 - INFO - [EPOCH 9]outputs from the model torch.Size([4, 64, 513, 946])
for batch 2
predicted mask shape torch.Size([4, 1, 513, 946])
2025-02-22 01:44:20,249 - INFO - Appending Batch Losses: Mask: 0.44090378284454346, Hybrid: 0.8082641363143921, Combined: 0.7992810010910034
2025-02-22 01:44:22,632 - INFO - Appending Batch Losses: Mask: 0.4180169105529785, Hybrid: 1.0809580087661743, Combined: 0.6215277910232544
2025-02-22 01:44:32,234 - INFO - Appending Batch Losses: Mask: 0.4490203857421875, Hybrid: 0.9741442203521729, Combined: 0.6549053192138672
2025-02-22 01:44:33,238 - INFO - Appending Batch Losses: Mask: 0.4273303151130676, Hybrid: 0.8824058771133423, Combined: 0.5951516628265381
2025-02-22 01:44:41,991 - INFO - Appending Batch Losses: Mask: 0.44866353273391724, Hybrid: 0.8938014507293701, Combined: 0.4350755512714386
2025-02-22 01:44:43,585 - INFO - Appending Batch Losses: Mask: 0.48347529768943787, Hybrid: 0.7340971231460571, Combined: 0.7274909019470215
2025-02-22 01:44:45,107 - INFO - Appending Batch Losses: Mask: 0.382257342338562, Hybrid: 0.6793093681335449, Combined: 0.31013423204421997
2025-02-22 01:44:46,373 - INFO - Appending Batch Losses: Mask: 0.3907322883605957, Hybrid: 0.7665654420852661, Combined: 0.5909532308578491
2025-02-22 01:45:03,888 - INFO - Appending Batch Losses: Mask: 0.39726001024246216, Hybrid: 0.6204919815063477, Combined: 0.60626220703125
2025-02-22 01:45:04,877 - INFO - Appending Batch Losses: Mask: 0.43665745854377747, Hybrid: 0.8392016887664795, Combined: 0.7465736269950867
2025-02-22 01:45:08,964 - INFO - Appending Batch Losses: Mask: 0.4744492471218109, Hybrid: 0.6756663918495178, Combined: 0.6301877498626709
2025-02-22 01:45:21,540 - INFO - Appending Batch Losses: Mask: 0.34378501772880554, Hybrid: 0.5778084993362427, Combined: 0.2764744162559509
2025-02-22 01:45:22,515 - INFO - Appending Batch Losses: Mask: 0.5150059461593628, Hybrid: 0.8057993054389954, Combined: 0.5871694087982178
2025-02-22 01:45:23,505 - INFO - Appending Batch Losses: Mask: 0.3994519114494324, Hybrid: 0.6682077646255493, Combined: 0.5071714520454407
2025-02-22 01:45:32,343 - INFO - Appending Batch Losses: Mask: 0.4564775228500366, Hybrid: 0.7602466940879822, Combined: 0.6577661037445068
2025-02-22 01:45:33,578 - INFO - Appending Batch Losses: Mask: 0.48858946561813354, Hybrid: 0.7455446720123291, Combined: 0.8129720091819763
2025-02-22 01:45:34,551 - INFO - Appending Batch Losses: Mask: 0.39699864387512207, Hybrid: 0.7657948732376099, Combined: 0.2500699460506439
2025-02-22 01:45:50,610 - INFO - Appending Batch Losses: Mask: 0.4215848743915558, Hybrid: 0.6996333599090576, Combined: 0.22715970873832703
2025-02-22 01:45:51,595 - INFO - Appending Batch Losses: Mask: 0.3722101151943207, Hybrid: 0.7571600675582886, Combined: 0.6985235214233398
2025-02-22 01:45:52,577 - INFO - Appending Batch Losses: Mask: 0.29095059633255005, Hybrid: 0.5842584371566772, Combined: 0.20211359858512878
2025-02-22 01:45:53,562 - INFO - Appending Batch Losses: Mask: 0.41972288489341736, Hybrid: 0.7230522632598877, Combined: 0.4156879484653473
2025-02-22 01:45:54,548 - INFO - Appending Batch Losses: Mask: 0.40635713934898376, Hybrid: 0.6553925275802612, Combined: 0.39614495635032654
2025-02-22 01:46:04,664 - INFO - Appending Batch Losses: Mask: 0.45848020911216736, Hybrid: 0.7184646129608154, Combined: 0.4737633764743805
2025-02-22 01:46:23,442 - INFO - Appending Batch Losses: Mask: 0.4646233022212982, Hybrid: 0.7123385667800903, Combined: 0.7649188041687012
2025-02-22 01:46:24,413 - INFO - Appending Batch Losses: Mask: 0.4953121244907379, Hybrid: 0.7137235999107361, Combined: 0.9118936657905579
2025-02-22 01:46:25,392 - INFO - Appending Batch Losses: Mask: 0.36557891964912415, Hybrid: 0.847954273223877, Combined: 0.4238170385360718
2025-02-22 01:46:26,389 - INFO - Appending Batch Losses: Mask: 0.3695721924304962, Hybrid: 0.6344397068023682, Combined: 0.4346747398376465
2025-02-22 01:46:27,235 - INFO - Appending Batch Losses: Mask: 0.36040905117988586, Hybrid: 0.6715993881225586, Combined: 0.5268267393112183
2025-02-22 01:46:43,784 - INFO - Appending Batch Losses: Mask: 0.4727536737918854, Hybrid: 0.6981701850891113, Combined: 0.5579820871353149
2025-02-22 01:46:46,386 - INFO - Appending Batch Losses: Mask: 0.7065760493278503, Hybrid: 1.1040421724319458, Combined: 1.134752869606018
2025-02-22 01:46:50,252 - INFO - Appending Batch Losses: Mask: 0.5102010369300842, Hybrid: 0.9903985857963562, Combined: 0.5136765241622925
2025-02-22 01:46:51,467 - INFO - Appending Batch Losses: Mask: 0.4082491993904114, Hybrid: 0.683811366558075, Combined: 0.5016002058982849
2025-02-22 01:46:52,308 - INFO - Appending Batch Losses: Mask: 0.4172550439834595, Hybrid: 0.6353258490562439, Combined: 0.17064812779426575
2025-02-22 01:46:53,147 - INFO - Appending Batch Losses: Mask: 0.3482629656791687, Hybrid: 0.6583926677703857, Combined: 0.38173583149909973
2025-02-22 01:47:06,602 - INFO - Appending Batch Losses: Mask: 0.35487696528434753, Hybrid: 0.5488841533660889, Combined: 0.5738891363143921
2025-02-22 01:47:07,569 - INFO - Appending Batch Losses: Mask: 0.4732433557510376, Hybrid: 0.7725508213043213, Combined: 0.41602855920791626
2025-02-22 01:47:09,769 - INFO - Current Learning Rate 0.0009002570017082938

2025-02-22 01:47:11,277 - INFO - Checkpoint saved: /mnt/c/Users/didri/Desktop/Programmering/ArtificalintelligenceModels/UNet-Model_Vocal_Isolation/Unet_model_Audio_Seperation/Model_Weights/CheckPoints/Training/checkpoint_epoch_8.pth
2025-02-22 01:47:11,278 - INFO - 
 [EPOCH 9]Model Checkpoint SAVED at epoch 9
 avg_epoch_loss: [0.541873]
 bestloss: [0.541873]
 Trigger times: 0/12

2025-02-22 01:48:40,690 - INFO - 
Trigger times: 5, patience: 15

2025-02-22 01:48:40,690 - INFO - 
Trigger times: 5, patience: 12

2025-02-22 01:48:40,691 - INFO - 
[Epoch Improvement] Epoch 9: Loss improved during training by 5.38% from previous epoch, 

2025-02-22 01:48:40,691 - INFO - ####LOGGING AVERAGE LOSS EPOCH###
[Epoch Summary] Epoch: 9/50, Avg Combined Loss: 0.541873, MaskLoss: 0.424160, Hybridloss: 0.735196Previous Epoch loss: 0.5726710477390805
2025-02-22 01:48:40,692 - INFO - Epoch: 9 COMPLETED





2025-02-22 01:48:40,692 - INFO - [Train] Epoch 10/50 started.

2025-02-22 01:49:12,178 - INFO - #####INPUTS & TARGETS VALUE [2 BATCHES]####
Batch 1: Mixture shape=torch.Size([3, 1, 513, 946]), Target shape=torch.Size([3, 1, 513, 946])
2025-02-22 01:49:12,920 - INFO - [EPOCH 10]outputs from the model torch.Size([3, 64, 513, 946])
for batch 1
predicted mask shape torch.Size([3, 1, 513, 946])
2025-02-22 01:49:14,070 - INFO - Function: [log_first_2_batches_outputs_inputs_targets_predicted_mask]
2025-02-22 01:49:14,073 - INFO - ####OUTPUTS, INPUTS, TARGETS,PREDICTEDMASK [2 BATCHES]####
Batch 1: Mask range: min=0.0000, max=61.5625
Batch 1: Inputs shape=torch.Size([3, 1, 513, 946]), Targets shape=torch.Size([3, 1, 513, 946]), Predicted Mask shape=torch.Size([3, 1, 513, 946]), Outputs shape=torch.Size([3, 64, 513, 946])
Mask min=0.0, max=1.0
[After Mask Application] Predicted vocals min: 0.0, max: 125.9375

2025-02-22 01:49:14,073 - INFO - 
####LOSS VALUES####
[Combinedloss]:  Total treningsfeil, [BØR REDUSERES OVER TID]
[MaskLoss]: Sier hvor godt modellen lærer og predikere masken som isolerer vokaler[BØR REDUSERES OVER TID]
[l1_loss og stft_loss] gir ekstra indikasjoner på lydkvalitet.
[Hybridloss]: Kombinasjon av flere tapsfunksjoner[BØR REDUSERES OVER TID]

2025-02-22 01:49:14,085 - INFO - Appending Batch Losses: Mask: 0.5288555026054382, Hybrid: 0.7747703194618225, Combined: 0.745806097984314
2025-02-22 01:49:14,933 - INFO - [EPOCH 10]outputs from the model torch.Size([4, 64, 513, 946])
for batch 2
predicted mask shape torch.Size([4, 1, 513, 946])
2025-02-22 01:49:16,199 - INFO - Appending Batch Losses: Mask: 0.48787423968315125, Hybrid: 0.8505534529685974, Combined: 0.7323600053787231
2025-02-22 01:49:26,529 - INFO - Appending Batch Losses: Mask: 0.5195454359054565, Hybrid: 0.8314752578735352, Combined: 0.9471005797386169
2025-02-22 01:49:27,780 - INFO - Appending Batch Losses: Mask: 0.4579800069332123, Hybrid: 0.7411755323410034, Combined: 0.5261970162391663
2025-02-22 01:49:28,777 - INFO - Appending Batch Losses: Mask: 0.4590276777744293, Hybrid: 0.7996006011962891, Combined: 0.6310189962387085
2025-02-22 01:49:33,660 - INFO - Appending Batch Losses: Mask: 0.3893304169178009, Hybrid: 0.6029784679412842, Combined: 0.5195791125297546
2025-02-22 01:49:34,647 - INFO - Appending Batch Losses: Mask: 0.45007139444351196, Hybrid: 0.7949618101119995, Combined: 0.5854681730270386
2025-02-22 01:49:56,346 - INFO - Appending Batch Losses: Mask: 0.55029296875, Hybrid: 0.7973768711090088, Combined: 0.7338945269584656
2025-02-22 01:50:04,118 - INFO - Appending Batch Losses: Mask: 0.36809229850769043, Hybrid: 0.6129562854766846, Combined: 0.6070980429649353
2025-02-22 01:50:04,966 - INFO - Appending Batch Losses: Mask: 0.4897049367427826, Hybrid: 0.8061217069625854, Combined: 0.7372698783874512
2025-02-22 01:50:05,834 - INFO - Appending Batch Losses: Mask: 0.5422723889350891, Hybrid: 1.2533934116363525, Combined: 1.0033015012741089
2025-02-22 01:50:07,104 - INFO - Appending Batch Losses: Mask: 0.2803233861923218, Hybrid: 0.6675183176994324, Combined: 0.053848326206207275
2025-02-22 01:50:08,085 - INFO - Appending Batch Losses: Mask: 0.47646063566207886, Hybrid: 0.7992805242538452, Combined: 0.557036280632019
2025-02-22 01:50:29,934 - INFO - Appending Batch Losses: Mask: 0.2726849615573883, Hybrid: 0.5048993825912476, Combined: 0.7052300572395325
2025-02-22 01:50:30,925 - INFO - Appending Batch Losses: Mask: 0.46955549716949463, Hybrid: 0.8134810924530029, Combined: 0.6386570930480957
2025-02-22 01:50:31,917 - INFO - Appending Batch Losses: Mask: 0.427375853061676, Hybrid: 0.7224503755569458, Combined: 0.354847252368927
2025-02-22 01:50:32,921 - INFO - Appending Batch Losses: Mask: 0.3949275314807892, Hybrid: 0.705470085144043, Combined: 0.4974623918533325
2025-02-22 01:50:42,353 - INFO - Appending Batch Losses: Mask: 0.3713739812374115, Hybrid: 0.6898391246795654, Combined: 0.2501945197582245
2025-02-22 01:50:43,340 - INFO - Appending Batch Losses: Mask: 0.387015700340271, Hybrid: 0.6810676455497742, Combined: 0.6272352933883667
2025-02-22 01:50:57,923 - INFO - Appending Batch Losses: Mask: 0.34887364506721497, Hybrid: 0.5747724771499634, Combined: 0.7477989196777344
2025-02-22 01:50:58,896 - INFO - Appending Batch Losses: Mask: 0.39865463972091675, Hybrid: 0.7241970300674438, Combined: 0.5097823143005371
2025-02-22 01:50:59,874 - INFO - Appending Batch Losses: Mask: 0.46573376655578613, Hybrid: 0.8190907835960388, Combined: 0.8481378555297852
2025-02-22 01:51:00,883 - INFO - Appending Batch Losses: Mask: 0.37541306018829346, Hybrid: 0.6336923837661743, Combined: 0.3929031789302826
2025-02-22 01:51:01,885 - INFO - Appending Batch Losses: Mask: 0.4032878875732422, Hybrid: 0.6560978889465332, Combined: 0.670116662979126
2025-02-22 01:51:02,881 - INFO - Appending Batch Losses: Mask: 0.41261494159698486, Hybrid: 0.6673299074172974, Combined: 0.5518231391906738
2025-02-22 01:51:22,985 - INFO - Appending Batch Losses: Mask: 0.3729138970375061, Hybrid: 0.7487924098968506, Combined: 0.5507996678352356
2025-02-22 01:51:23,960 - INFO - Appending Batch Losses: Mask: 0.4021495282649994, Hybrid: 0.6602391004562378, Combined: 0.3813295066356659
2025-02-22 01:51:25,236 - INFO - Appending Batch Losses: Mask: 0.4415815472602844, Hybrid: 0.6315510869026184, Combined: 0.4405626654624939
2025-02-22 01:51:26,205 - INFO - Appending Batch Losses: Mask: 0.5678392648696899, Hybrid: 0.8778491020202637, Combined: 0.9248572587966919
2025-02-22 01:51:28,218 - INFO - Appending Batch Losses: Mask: 0.40726426243782043, Hybrid: 0.7354153394699097, Combined: 0.6215014457702637
2025-02-22 01:51:37,324 - INFO - Appending Batch Losses: Mask: 0.5063498020172119, Hybrid: 0.782534658908844, Combined: 0.4350106120109558
2025-02-22 01:52:01,272 - INFO - Appending Batch Losses: Mask: 0.4918144941329956, Hybrid: 0.7189697027206421, Combined: 0.7840784788131714
2025-02-22 01:52:02,254 - INFO - Appending Batch Losses: Mask: 0.4468995928764343, Hybrid: 0.7890111804008484, Combined: 0.6173087358474731
2025-02-22 01:52:03,229 - INFO - Appending Batch Losses: Mask: 0.37430375814437866, Hybrid: 0.6359330415725708, Combined: 0.32854336500167847
2025-02-22 01:52:04,212 - INFO - Appending Batch Losses: Mask: 0.3729505240917206, Hybrid: 0.6409083008766174, Combined: 0.2733115553855896
2025-02-22 01:52:05,416 - INFO - Appending Batch Losses: Mask: 0.43459799885749817, Hybrid: 0.7639889121055603, Combined: 0.563791036605835
2025-02-22 01:52:06,390 - INFO - Appending Batch Losses: Mask: 0.44002264738082886, Hybrid: 0.6817910671234131, Combined: 0.5616123080253601
2025-02-22 01:52:08,446 - INFO - Current Learning Rate 0.0009109320322805665

2025-02-22 01:52:08,446 - INFO - 
[EPOCH 10]No improvement, NO NEW MODEL CHECKPOINT SAVED at epoch 10
 avg_epoch_loss: [0.585321]
 bestloss: [0.541873]
 Trigger: 6/12

2025-02-22 01:53:33,499 - INFO - 
Trigger times: 6, patience: 15

2025-02-22 01:53:33,500 - INFO - 
Trigger times: 6, patience: 12

2025-02-22 01:53:33,500 - INFO - 
[Epoch Improvement] Epoch 10: Loss improved during training by -8.02% from previous epoch, 

2025-02-22 01:53:33,502 - INFO - ####LOGGING AVERAGE LOSS EPOCH###
[Epoch Summary] Epoch: 10/50, Avg Combined Loss: 0.585321, MaskLoss: 0.424949, Hybridloss: 0.735167Previous Epoch loss: 0.5418734864608662
2025-02-22 01:53:33,502 - INFO - Epoch: 10 COMPLETED





2025-02-22 01:53:33,503 - INFO - [Train] Epoch 11/50 started.

2025-02-22 01:54:02,409 - INFO - #####INPUTS & TARGETS VALUE [2 BATCHES]####
Batch 1: Mixture shape=torch.Size([4, 1, 513, 946]), Target shape=torch.Size([4, 1, 513, 946])
2025-02-22 01:54:03,284 - INFO - [EPOCH 11]outputs from the model torch.Size([4, 64, 513, 946])
for batch 1
predicted mask shape torch.Size([4, 1, 513, 946])
2025-02-22 01:54:04,524 - INFO - Function: [log_first_2_batches_outputs_inputs_targets_predicted_mask]
2025-02-22 01:54:04,526 - INFO - ####OUTPUTS, INPUTS, TARGETS,PREDICTEDMASK [2 BATCHES]####
Batch 1: Mask range: min=0.0000, max=77.8750
Batch 1: Inputs shape=torch.Size([4, 1, 513, 946]), Targets shape=torch.Size([4, 1, 513, 946]), Predicted Mask shape=torch.Size([4, 1, 513, 946]), Outputs shape=torch.Size([4, 64, 513, 946])
Mask min=0.0, max=1.0
[After Mask Application] Predicted vocals min: 0.0, max: 157.375

2025-02-22 01:54:04,527 - INFO - 
####LOSS VALUES####
[Combinedloss]:  Total treningsfeil, [BØR REDUSERES OVER TID]
[MaskLoss]: Sier hvor godt modellen lærer og predikere masken som isolerer vokaler[BØR REDUSERES OVER TID]
[l1_loss og stft_loss] gir ekstra indikasjoner på lydkvalitet.
[Hybridloss]: Kombinasjon av flere tapsfunksjoner[BØR REDUSERES OVER TID]

2025-02-22 01:54:04,539 - INFO - Appending Batch Losses: Mask: 0.5088298320770264, Hybrid: 0.8228272795677185, Combined: 0.6454603672027588
2025-02-22 01:54:14,103 - INFO - [EPOCH 11]outputs from the model torch.Size([4, 64, 513, 946])
for batch 2
predicted mask shape torch.Size([4, 1, 513, 946])
2025-02-22 01:54:15,203 - INFO - Appending Batch Losses: Mask: 0.42829281091690063, Hybrid: 0.8220983147621155, Combined: 0.4487075209617615
2025-02-22 01:54:19,813 - INFO - Appending Batch Losses: Mask: 0.4832475781440735, Hybrid: 0.7941591739654541, Combined: 0.6054840087890625
2025-02-22 01:54:20,814 - INFO - Appending Batch Losses: Mask: 0.45956891775131226, Hybrid: 0.7515171766281128, Combined: 0.4187878370285034
2025-02-22 01:54:21,798 - INFO - Appending Batch Losses: Mask: 0.41243433952331543, Hybrid: 0.8608779907226562, Combined: 0.5389127731323242
2025-02-22 01:54:22,796 - INFO - Appending Batch Losses: Mask: 0.5508726239204407, Hybrid: 0.8609132766723633, Combined: 0.7638781666755676
2025-02-22 01:54:27,179 - INFO - Appending Batch Losses: Mask: 0.38012874126434326, Hybrid: 0.6005060076713562, Combined: 0.41690951585769653
2025-02-22 01:54:47,910 - INFO - Appending Batch Losses: Mask: 0.4117201566696167, Hybrid: 0.7396460771560669, Combined: 0.510858416557312
2025-02-22 01:54:48,900 - INFO - Appending Batch Losses: Mask: 0.3670211434364319, Hybrid: 0.5443869829177856, Combined: 0.4493105411529541
2025-02-22 01:54:49,921 - INFO - Appending Batch Losses: Mask: 0.32162681221961975, Hybrid: 0.7635290622711182, Combined: 0.3965414762496948
2025-02-22 01:54:52,149 - INFO - Appending Batch Losses: Mask: 0.3248754143714905, Hybrid: 0.51569664478302, Combined: 0.5474627017974854
2025-02-22 01:54:53,135 - INFO - Appending Batch Losses: Mask: 0.49207353591918945, Hybrid: 0.9085449576377869, Combined: 0.7643425464630127
2025-02-22 01:55:03,775 - INFO - Appending Batch Losses: Mask: 0.3376392722129822, Hybrid: 0.5933007001876831, Combined: 0.27427634596824646
2025-02-22 01:55:20,693 - INFO - Appending Batch Losses: Mask: 0.4548441767692566, Hybrid: 0.6656990051269531, Combined: 0.5764960050582886
2025-02-22 01:55:21,980 - INFO - Appending Batch Losses: Mask: 0.4520041346549988, Hybrid: 0.7339701652526855, Combined: 0.3671048581600189
2025-02-22 01:55:22,946 - INFO - Appending Batch Losses: Mask: 0.3944094777107239, Hybrid: 0.6504020094871521, Combined: 0.435430109500885
2025-02-22 01:55:23,931 - INFO - Appending Batch Losses: Mask: 0.44380348920822144, Hybrid: 0.7725276947021484, Combined: 0.5777418613433838
2025-02-22 01:55:24,912 - INFO - Appending Batch Losses: Mask: 0.3715120553970337, Hybrid: 0.5755816698074341, Combined: 0.538424551486969
2025-02-22 01:55:44,675 - INFO - Appending Batch Losses: Mask: 0.3767659068107605, Hybrid: 0.7009104490280151, Combined: 0.35888439416885376
2025-02-22 01:55:56,970 - INFO - Appending Batch Losses: Mask: 0.44566622376441956, Hybrid: 0.9217407703399658, Combined: 0.2200135588645935
2025-02-22 01:55:57,814 - INFO - Appending Batch Losses: Mask: 0.5133379101753235, Hybrid: 0.7552489042282104, Combined: 0.6531619429588318
2025-02-22 01:55:58,667 - INFO - Appending Batch Losses: Mask: 0.506669819355011, Hybrid: 0.8003311157226562, Combined: 0.8672791719436646
2025-02-22 01:55:59,751 - INFO - Appending Batch Losses: Mask: 0.38754400610923767, Hybrid: 0.6039794683456421, Combined: 0.44178929924964905
2025-02-22 01:56:00,466 - INFO - Appending Batch Losses: Mask: 0.5044625997543335, Hybrid: 0.7484686374664307, Combined: 0.7569709420204163
2025-02-22 01:56:03,956 - INFO - Appending Batch Losses: Mask: 0.4992161691188812, Hybrid: 0.808538556098938, Combined: 0.8327643275260925
2025-02-22 01:56:30,718 - INFO - Appending Batch Losses: Mask: 0.42416563630104065, Hybrid: 0.6425106525421143, Combined: 0.5776163935661316
2025-02-22 01:56:31,690 - INFO - Appending Batch Losses: Mask: 0.3506735563278198, Hybrid: 0.5622828006744385, Combined: 0.5350983142852783
2025-02-22 01:56:32,522 - INFO - Appending Batch Losses: Mask: 0.7423735857009888, Hybrid: 1.5811617374420166, Combined: 1.4090783596038818
2025-02-22 01:56:33,370 - INFO - Appending Batch Losses: Mask: 0.4746999740600586, Hybrid: 0.800826907157898, Combined: 0.5096721649169922
2025-02-22 01:56:34,340 - INFO - Appending Batch Losses: Mask: 0.42648768424987793, Hybrid: 0.7322564721107483, Combined: 0.6006424427032471
2025-02-22 01:56:35,569 - INFO - Appending Batch Losses: Mask: 0.47176703810691833, Hybrid: 0.8109822273254395, Combined: 0.8189336061477661
2025-02-22 01:56:52,357 - INFO - Appending Batch Losses: Mask: 0.4366418421268463, Hybrid: 0.7665671110153198, Combined: 0.550189733505249
2025-02-22 01:56:53,321 - INFO - Appending Batch Losses: Mask: 0.42349517345428467, Hybrid: 0.6414059400558472, Combined: 0.3777596652507782
2025-02-22 01:56:54,292 - INFO - Appending Batch Losses: Mask: 0.3101794719696045, Hybrid: 0.5983892679214478, Combined: 0.6259831190109253
2025-02-22 01:56:55,262 - INFO - Appending Batch Losses: Mask: 0.4214121401309967, Hybrid: 0.8777377009391785, Combined: 0.7578177452087402
2025-02-22 01:56:56,225 - INFO - Appending Batch Losses: Mask: 0.48035669326782227, Hybrid: 0.7445970773696899, Combined: 0.6635477542877197
2025-02-22 01:57:02,583 - INFO - Appending Batch Losses: Mask: 0.40553018450737, Hybrid: 0.7272723913192749, Combined: 0.2830218970775604
2025-02-22 01:57:04,904 - INFO - Current Learning Rate 0.0009190791018883574

2025-02-22 01:57:04,904 - INFO - 
[EPOCH 11]No improvement, NO NEW MODEL CHECKPOINT SAVED at epoch 11
 avg_epoch_loss: [0.570712]
 bestloss: [0.541873]
 Trigger: 7/12

2025-02-22 01:58:31,690 - INFO - 
Trigger times: 7, patience: 15

2025-02-22 01:58:31,691 - INFO - 
Trigger times: 7, patience: 12

2025-02-22 01:58:31,691 - INFO - 
[Epoch Improvement] Epoch 11: Loss improved during training by 2.50% from previous epoch, 

2025-02-22 01:58:31,691 - INFO - ####LOGGING AVERAGE LOSS EPOCH###
[Epoch Summary] Epoch: 11/50, Avg Combined Loss: 0.570712, MaskLoss: 0.426112, Hybridloss: 0.736642Previous Epoch loss: 0.5853209149193119
2025-02-22 01:58:31,692 - INFO - Epoch: 11 COMPLETED





2025-02-22 01:58:31,693 - INFO - [Train] Epoch 12/50 started.

2025-02-22 01:59:04,232 - INFO - #####INPUTS & TARGETS VALUE [2 BATCHES]####
Batch 1: Mixture shape=torch.Size([4, 1, 513, 946]), Target shape=torch.Size([4, 1, 513, 946])
2025-02-22 01:59:04,981 - INFO - [EPOCH 12]outputs from the model torch.Size([4, 64, 513, 946])
for batch 1
predicted mask shape torch.Size([4, 1, 513, 946])
2025-02-22 01:59:06,233 - INFO - Function: [log_first_2_batches_outputs_inputs_targets_predicted_mask]
2025-02-22 01:59:06,236 - INFO - ####OUTPUTS, INPUTS, TARGETS,PREDICTEDMASK [2 BATCHES]####
Batch 1: Mask range: min=0.0000, max=129.8750
Batch 1: Inputs shape=torch.Size([4, 1, 513, 946]), Targets shape=torch.Size([4, 1, 513, 946]), Predicted Mask shape=torch.Size([4, 1, 513, 946]), Outputs shape=torch.Size([4, 64, 513, 946])
Mask min=0.0, max=1.0
[After Mask Application] Predicted vocals min: 0.0, max: 157.125

2025-02-22 01:59:06,236 - INFO - 
####LOSS VALUES####
[Combinedloss]:  Total treningsfeil, [BØR REDUSERES OVER TID]
[MaskLoss]: Sier hvor godt modellen lærer og predikere masken som isolerer vokaler[BØR REDUSERES OVER TID]
[l1_loss og stft_loss] gir ekstra indikasjoner på lydkvalitet.
[Hybridloss]: Kombinasjon av flere tapsfunksjoner[BØR REDUSERES OVER TID]

2025-02-22 01:59:06,251 - INFO - Appending Batch Losses: Mask: 0.4288322925567627, Hybrid: 0.6639207601547241, Combined: 0.5555064082145691
2025-02-22 01:59:07,422 - INFO - [EPOCH 12]outputs from the model torch.Size([3, 64, 513, 946])
for batch 2
predicted mask shape torch.Size([3, 1, 513, 946])
2025-02-22 01:59:08,855 - INFO - Appending Batch Losses: Mask: 0.5319559574127197, Hybrid: 0.8511831164360046, Combined: 0.7134493589401245
2025-02-22 01:59:15,717 - INFO - Appending Batch Losses: Mask: 0.42636311054229736, Hybrid: 0.6664751768112183, Combined: 0.502487301826477
2025-02-22 01:59:16,717 - INFO - Appending Batch Losses: Mask: 0.46096301078796387, Hybrid: 0.73762446641922, Combined: 0.3327634036540985
2025-02-22 01:59:17,711 - INFO - Appending Batch Losses: Mask: 0.3754674792289734, Hybrid: 0.6629880666732788, Combined: 0.6050207018852234
2025-02-22 01:59:18,702 - INFO - Appending Batch Losses: Mask: 0.48661091923713684, Hybrid: 0.7498513460159302, Combined: 0.5828038454055786
2025-02-22 01:59:31,628 - INFO - Appending Batch Losses: Mask: 0.5654931664466858, Hybrid: 0.9265203475952148, Combined: 0.8119910955429077
2025-02-22 01:59:32,630 - INFO - Appending Batch Losses: Mask: 0.368580162525177, Hybrid: 0.661433219909668, Combined: 0.40206629037857056
2025-02-22 01:59:49,895 - INFO - Appending Batch Losses: Mask: 0.4304214119911194, Hybrid: 0.680846631526947, Combined: 0.5089465379714966
2025-02-22 01:59:51,008 - INFO - Appending Batch Losses: Mask: 0.4456258714199066, Hybrid: 0.6765023469924927, Combined: 0.7364885210990906
2025-02-22 01:59:51,991 - INFO - Appending Batch Losses: Mask: 0.40084153413772583, Hybrid: 0.6744887828826904, Combined: 0.46890658140182495
2025-02-22 01:59:52,987 - INFO - Appending Batch Losses: Mask: 0.3223142921924591, Hybrid: 0.6368522047996521, Combined: 0.09475237131118774
2025-02-22 02:00:14,913 - INFO - Appending Batch Losses: Mask: 0.37759271264076233, Hybrid: 0.651546835899353, Combined: 0.5028953552246094
2025-02-22 02:00:15,915 - INFO - Appending Batch Losses: Mask: 0.43175679445266724, Hybrid: 0.6456717848777771, Combined: 0.6662050485610962
2025-02-22 02:00:28,639 - INFO - Appending Batch Losses: Mask: 0.3843421936035156, Hybrid: 0.8846994042396545, Combined: 0.43336811661720276
2025-02-22 02:00:29,629 - INFO - Appending Batch Losses: Mask: 0.38101768493652344, Hybrid: 0.621917724609375, Combined: 0.37006884813308716
2025-02-22 02:00:30,620 - INFO - Appending Batch Losses: Mask: 0.47725045680999756, Hybrid: 0.7521122694015503, Combined: 0.6038388013839722
2025-02-22 02:00:31,847 - INFO - Appending Batch Losses: Mask: 0.4310761094093323, Hybrid: 0.7084882259368896, Combined: 0.644557535648346
2025-02-22 02:00:46,685 - INFO - Appending Batch Losses: Mask: 0.4371073544025421, Hybrid: 0.7442476749420166, Combined: 0.634638249874115
2025-02-22 02:00:47,911 - INFO - Appending Batch Losses: Mask: 0.40021055936813354, Hybrid: 0.6122168302536011, Combined: 0.5254655480384827
2025-02-22 02:01:18,989 - INFO - Appending Batch Losses: Mask: 0.3874363303184509, Hybrid: 0.7171562314033508, Combined: -0.07479888200759888
2025-02-22 02:01:19,967 - INFO - Appending Batch Losses: Mask: 0.5309523344039917, Hybrid: 0.9103296995162964, Combined: 0.7029129862785339
2025-02-22 02:01:20,939 - INFO - Appending Batch Losses: Mask: 0.629590630531311, Hybrid: 0.9465596675872803, Combined: 0.8382227420806885
2025-02-22 02:01:21,921 - INFO - Appending Batch Losses: Mask: 0.35822755098342896, Hybrid: 0.6059650778770447, Combined: 0.4121427536010742
2025-02-22 02:01:22,895 - INFO - Appending Batch Losses: Mask: 0.4066275656223297, Hybrid: 0.7844396829605103, Combined: 0.35947105288505554
2025-02-22 02:01:24,133 - INFO - Appending Batch Losses: Mask: 0.39591899514198303, Hybrid: 0.6456170082092285, Combined: 0.4093288779258728
2025-02-22 02:01:31,848 - INFO - Appending Batch Losses: Mask: 0.3751397728919983, Hybrid: 0.7197133302688599, Combined: 0.4994155764579773
2025-02-22 02:01:32,832 - INFO - Appending Batch Losses: Mask: 0.4132692515850067, Hybrid: 0.7211239337921143, Combined: 0.6882181167602539
2025-02-22 02:01:33,821 - INFO - Appending Batch Losses: Mask: 0.42517054080963135, Hybrid: 0.6924512386322021, Combined: 0.6852344870567322
2025-02-22 02:01:34,788 - INFO - Appending Batch Losses: Mask: 0.35851961374282837, Hybrid: 0.6377129554748535, Combined: 0.5469110608100891
2025-02-22 02:01:35,768 - INFO - Appending Batch Losses: Mask: 0.5221434235572815, Hybrid: 0.8352298736572266, Combined: 0.7544263005256653
2025-02-22 02:01:36,744 - INFO - Appending Batch Losses: Mask: 0.47666919231414795, Hybrid: 0.7706621885299683, Combined: 0.8028849959373474
2025-02-22 02:01:53,294 - INFO - Appending Batch Losses: Mask: 0.435402512550354, Hybrid: 0.7840140461921692, Combined: 0.781062126159668
2025-02-22 02:01:54,495 - INFO - Appending Batch Losses: Mask: 0.525084912776947, Hybrid: 0.7585573792457581, Combined: 0.7950296401977539
2025-02-22 02:01:55,456 - INFO - Appending Batch Losses: Mask: 0.4111856520175934, Hybrid: 0.6074658632278442, Combined: 0.29615992307662964
2025-02-22 02:01:56,422 - INFO - Appending Batch Losses: Mask: 0.3269127309322357, Hybrid: 0.5425493121147156, Combined: 0.5313791632652283
2025-02-22 02:01:57,791 - INFO - Appending Batch Losses: Mask: 0.33035922050476074, Hybrid: 0.6856561899185181, Combined: 0.5588281750679016
2025-02-22 02:01:59,899 - INFO - Current Learning Rate 0.0009288164228677785

2025-02-22 02:01:59,899 - INFO - 
[EPOCH 12]No improvement, NO NEW MODEL CHECKPOINT SAVED at epoch 12
 avg_epoch_loss: [0.548191]
 bestloss: [0.541873]
 Trigger: 8/12

2025-02-22 02:03:27,008 - INFO - 
Trigger times: 8, patience: 15

2025-02-22 02:03:27,008 - INFO - 
Trigger times: 8, patience: 12

2025-02-22 02:03:27,009 - INFO - 
[Epoch Improvement] Epoch 12: Loss improved during training by 3.95% from previous epoch, 

2025-02-22 02:03:27,009 - INFO - ####LOGGING AVERAGE LOSS EPOCH###
[Epoch Summary] Epoch: 12/50, Avg Combined Loss: 0.548191, MaskLoss: 0.426351, Hybridloss: 0.735108Previous Epoch loss: 0.5707122820454675
2025-02-22 02:03:27,010 - INFO - Epoch: 12 COMPLETED





2025-02-22 02:03:27,011 - INFO - [Train] Epoch 13/50 started.

2025-02-22 02:03:52,891 - INFO - #####INPUTS & TARGETS VALUE [2 BATCHES]####
Batch 1: Mixture shape=torch.Size([3, 1, 513, 946]), Target shape=torch.Size([3, 1, 513, 946])
2025-02-22 02:03:53,591 - INFO - [EPOCH 13]outputs from the model torch.Size([3, 64, 513, 946])
for batch 1
predicted mask shape torch.Size([3, 1, 513, 946])
2025-02-22 02:03:54,747 - INFO - Function: [log_first_2_batches_outputs_inputs_targets_predicted_mask]
2025-02-22 02:03:54,750 - INFO - ####OUTPUTS, INPUTS, TARGETS,PREDICTEDMASK [2 BATCHES]####
Batch 1: Mask range: min=0.0000, max=122.4375
Batch 1: Inputs shape=torch.Size([3, 1, 513, 946]), Targets shape=torch.Size([3, 1, 513, 946]), Predicted Mask shape=torch.Size([3, 1, 513, 946]), Outputs shape=torch.Size([3, 64, 513, 946])
Mask min=0.0, max=1.0
[After Mask Application] Predicted vocals min: 0.0, max: 186.125

2025-02-22 02:03:54,750 - INFO - 
####LOSS VALUES####
[Combinedloss]:  Total treningsfeil, [BØR REDUSERES OVER TID]
[MaskLoss]: Sier hvor godt modellen lærer og predikere masken som isolerer vokaler[BØR REDUSERES OVER TID]
[l1_loss og stft_loss] gir ekstra indikasjoner på lydkvalitet.
[Hybridloss]: Kombinasjon av flere tapsfunksjoner[BØR REDUSERES OVER TID]

2025-02-22 02:03:54,766 - INFO - Appending Batch Losses: Mask: 0.3862585723400116, Hybrid: 0.8094931840896606, Combined: 0.33745795488357544
2025-02-22 02:04:02,631 - INFO - [EPOCH 13]outputs from the model torch.Size([4, 64, 513, 946])
for batch 2
predicted mask shape torch.Size([4, 1, 513, 946])
2025-02-22 02:04:03,800 - INFO - Appending Batch Losses: Mask: 0.41453179717063904, Hybrid: 0.6541835069656372, Combined: 0.1859578788280487
2025-02-22 02:04:08,592 - INFO - Appending Batch Losses: Mask: 0.3602742552757263, Hybrid: 0.6314220428466797, Combined: 0.3938366770744324
2025-02-22 02:04:09,593 - INFO - Appending Batch Losses: Mask: 0.45705920457839966, Hybrid: 0.8428838849067688, Combined: 0.7922464609146118
2025-02-22 02:04:10,880 - INFO - Appending Batch Losses: Mask: 0.460849404335022, Hybrid: 0.7670139074325562, Combined: 0.7386454939842224
2025-02-22 02:04:11,867 - INFO - Appending Batch Losses: Mask: 0.4512619376182556, Hybrid: 0.8716530799865723, Combined: 0.4999796152114868
2025-02-22 02:04:17,173 - INFO - Appending Batch Losses: Mask: 0.4331177771091461, Hybrid: 0.7192485928535461, Combined: 0.5376277565956116
2025-02-22 02:04:21,644 - INFO - Appending Batch Losses: Mask: 0.5032479763031006, Hybrid: 1.073401689529419, Combined: 0.8455846905708313
2025-02-22 02:04:30,669 - INFO - Appending Batch Losses: Mask: 0.3882930278778076, Hybrid: 0.8252865672111511, Combined: 0.5311880111694336
2025-02-22 02:04:46,876 - INFO - Appending Batch Losses: Mask: 0.48665884137153625, Hybrid: 0.7924689650535583, Combined: 0.42895352840423584
2025-02-22 02:04:47,745 - INFO - Appending Batch Losses: Mask: 0.4612278938293457, Hybrid: 0.6784406900405884, Combined: 0.6180930137634277
2025-02-22 02:04:48,726 - INFO - Appending Batch Losses: Mask: 0.374834805727005, Hybrid: 0.6424893140792847, Combined: 0.32607778906822205
2025-02-22 02:04:50,041 - INFO - Appending Batch Losses: Mask: 0.44766348600387573, Hybrid: 0.6913922429084778, Combined: 0.48056864738464355
2025-02-22 02:04:51,018 - INFO - Appending Batch Losses: Mask: 0.42140910029411316, Hybrid: 0.6702181696891785, Combined: 0.6293526887893677
2025-02-22 02:04:54,337 - INFO - Appending Batch Losses: Mask: 0.45276570320129395, Hybrid: 0.7346498370170593, Combined: 0.39075449109077454
2025-02-22 02:05:19,791 - INFO - Appending Batch Losses: Mask: 0.399807333946228, Hybrid: 0.713771641254425, Combined: 0.38731998205184937
2025-02-22 02:05:20,770 - INFO - Appending Batch Losses: Mask: 0.46317335963249207, Hybrid: 0.8074945211410522, Combined: 0.6285672187805176
2025-02-22 02:05:21,757 - INFO - Appending Batch Losses: Mask: 0.4283226430416107, Hybrid: 0.7162399291992188, Combined: 0.5795623660087585
2025-02-22 02:05:22,735 - INFO - Appending Batch Losses: Mask: 0.46235108375549316, Hybrid: 0.7670404314994812, Combined: 0.7211599946022034
2025-02-22 02:05:23,721 - INFO - Appending Batch Losses: Mask: 0.3996180593967438, Hybrid: 0.6343262791633606, Combined: 0.4705909490585327
2025-02-22 02:05:25,004 - INFO - Appending Batch Losses: Mask: 0.39515796303749084, Hybrid: 0.612465500831604, Combined: 0.7367531657218933
2025-02-22 02:05:48,758 - INFO - Appending Batch Losses: Mask: 0.35665184259414673, Hybrid: 0.6469931602478027, Combined: 0.6102734208106995
2025-02-22 02:05:49,751 - INFO - Appending Batch Losses: Mask: 0.3583652973175049, Hybrid: 0.6591935157775879, Combined: 0.7097017168998718
2025-02-22 02:05:50,741 - INFO - Appending Batch Losses: Mask: 0.3815503716468811, Hybrid: 0.5878196358680725, Combined: 0.5114219188690186
2025-02-22 02:05:51,729 - INFO - Appending Batch Losses: Mask: 0.3700205087661743, Hybrid: 0.5591193437576294, Combined: 0.47067639231681824
2025-02-22 02:05:52,718 - INFO - Appending Batch Losses: Mask: 0.24602019786834717, Hybrid: 0.4652504324913025, Combined: 0.37414026260375977
2025-02-22 02:05:53,693 - INFO - Appending Batch Losses: Mask: 0.41879570484161377, Hybrid: 0.6956530809402466, Combined: 0.4033746123313904
2025-02-22 02:06:22,052 - INFO - Appending Batch Losses: Mask: 0.4669726490974426, Hybrid: 0.7527274489402771, Combined: 0.6716830730438232
2025-02-22 02:06:23,254 - INFO - Appending Batch Losses: Mask: 0.4501366913318634, Hybrid: 0.7425472140312195, Combined: 0.6696746945381165
2025-02-22 02:06:24,229 - INFO - Appending Batch Losses: Mask: 0.7043663859367371, Hybrid: 0.9732524752616882, Combined: 1.1287592649459839
2025-02-22 02:06:25,204 - INFO - Appending Batch Losses: Mask: 0.3762902617454529, Hybrid: 0.6966025829315186, Combined: 0.4798576831817627
2025-02-22 02:06:26,181 - INFO - Appending Batch Losses: Mask: 0.4047940671443939, Hybrid: 0.8393465280532837, Combined: 0.6483978629112244
2025-02-22 02:06:27,160 - INFO - Appending Batch Losses: Mask: 0.34416818618774414, Hybrid: 0.6020212173461914, Combined: 0.4695754647254944
2025-02-22 02:06:52,402 - INFO - Appending Batch Losses: Mask: 0.5379160642623901, Hybrid: 0.9719477891921997, Combined: 0.7192205786705017
2025-02-22 02:06:53,377 - INFO - Appending Batch Losses: Mask: 0.48313671350479126, Hybrid: 0.8146359324455261, Combined: 0.47784867882728577
2025-02-22 02:06:54,358 - INFO - Appending Batch Losses: Mask: 0.5188729763031006, Hybrid: 0.9442003965377808, Combined: 0.7598934173583984
2025-02-22 02:06:55,561 - INFO - Appending Batch Losses: Mask: 0.4526662230491638, Hybrid: 0.7056858539581299, Combined: 0.8194549679756165
2025-02-22 02:06:57,752 - INFO - Current Learning Rate 0.0009381006778383419

2025-02-22 02:06:57,752 - INFO - 
[EPOCH 13]No improvement, NO NEW MODEL CHECKPOINT SAVED at epoch 13
 avg_epoch_loss: [0.572547]
 bestloss: [0.541873]
 Trigger: 9/12

2025-02-22 02:08:24,725 - INFO - 
Trigger times: 9, patience: 15

2025-02-22 02:08:24,726 - INFO - 
Trigger times: 9, patience: 12

2025-02-22 02:08:24,726 - INFO - 
[Epoch Improvement] Epoch 13: Loss improved during training by -4.44% from previous epoch, 

2025-02-22 02:08:24,726 - INFO - ####LOGGING AVERAGE LOSS EPOCH###
[Epoch Summary] Epoch: 13/50, Avg Combined Loss: 0.572547, MaskLoss: 0.426650, Hybridloss: 0.735344Previous Epoch loss: 0.5481905139781333
2025-02-22 02:08:24,727 - INFO - Epoch: 13 COMPLETED





2025-02-22 02:08:24,728 - INFO - [Train] Epoch 14/50 started.

2025-02-22 02:08:51,004 - INFO - #####INPUTS & TARGETS VALUE [2 BATCHES]####
Batch 1: Mixture shape=torch.Size([4, 1, 513, 946]), Target shape=torch.Size([4, 1, 513, 946])
2025-02-22 02:08:51,777 - INFO - [EPOCH 14]outputs from the model torch.Size([4, 64, 513, 946])
for batch 1
predicted mask shape torch.Size([4, 1, 513, 946])
2025-02-22 02:08:53,004 - INFO - Function: [log_first_2_batches_outputs_inputs_targets_predicted_mask]
2025-02-22 02:08:53,007 - INFO - ####OUTPUTS, INPUTS, TARGETS,PREDICTEDMASK [2 BATCHES]####
Batch 1: Mask range: min=0.0000, max=62.8750
Batch 1: Inputs shape=torch.Size([4, 1, 513, 946]), Targets shape=torch.Size([4, 1, 513, 946]), Predicted Mask shape=torch.Size([4, 1, 513, 946]), Outputs shape=torch.Size([4, 64, 513, 946])
Mask min=0.0, max=1.0
[After Mask Application] Predicted vocals min: 0.0, max: 160.0

2025-02-22 02:08:53,007 - INFO - 
####LOSS VALUES####
[Combinedloss]:  Total treningsfeil, [BØR REDUSERES OVER TID]
[MaskLoss]: Sier hvor godt modellen lærer og predikere masken som isolerer vokaler[BØR REDUSERES OVER TID]
[l1_loss og stft_loss] gir ekstra indikasjoner på lydkvalitet.
[Hybridloss]: Kombinasjon av flere tapsfunksjoner[BØR REDUSERES OVER TID]

2025-02-22 02:08:53,022 - INFO - Appending Batch Losses: Mask: 0.5439651012420654, Hybrid: 0.7702906131744385, Combined: 0.7504447102546692
2025-02-22 02:09:11,131 - INFO - [EPOCH 14]outputs from the model torch.Size([4, 64, 513, 946])
for batch 2
predicted mask shape torch.Size([4, 1, 513, 946])
2025-02-22 02:09:12,340 - INFO - Appending Batch Losses: Mask: 0.36720094084739685, Hybrid: 0.6930519342422485, Combined: 0.25447744131088257
2025-02-22 02:09:13,210 - INFO - Appending Batch Losses: Mask: 0.359648734331131, Hybrid: 0.6060464382171631, Combined: 0.4577668309211731
2025-02-22 02:09:19,505 - INFO - Appending Batch Losses: Mask: 0.391189306974411, Hybrid: 0.7433124780654907, Combined: 0.5521843433380127
2025-02-22 02:09:20,500 - INFO - Appending Batch Losses: Mask: 0.4010094404220581, Hybrid: 0.6952109336853027, Combined: 0.3228808045387268
2025-02-22 02:09:21,497 - INFO - Appending Batch Losses: Mask: 0.3884173333644867, Hybrid: 0.6461900472640991, Combined: 0.3598765432834625
2025-02-22 02:09:23,845 - INFO - Appending Batch Losses: Mask: 0.4156672954559326, Hybrid: 0.7023026943206787, Combined: 0.639596164226532
2025-02-22 02:09:41,068 - INFO - Appending Batch Losses: Mask: 0.5048527121543884, Hybrid: 0.7685314416885376, Combined: 0.8419510722160339
2025-02-22 02:09:42,039 - INFO - Appending Batch Losses: Mask: 0.4333053529262543, Hybrid: 0.7797085046768188, Combined: 0.5090197324752808
2025-02-22 02:09:55,201 - INFO - Appending Batch Losses: Mask: 0.4557700753211975, Hybrid: 0.7477425336837769, Combined: 0.6943188905715942
2025-02-22 02:09:56,172 - INFO - Appending Batch Losses: Mask: 0.5227620005607605, Hybrid: 0.7477256059646606, Combined: 0.8240379095077515
2025-02-22 02:09:57,151 - INFO - Appending Batch Losses: Mask: 0.24764062464237213, Hybrid: 0.49980536103248596, Combined: 0.23275409638881683
2025-02-22 02:10:01,329 - INFO - Appending Batch Losses: Mask: 0.4894587993621826, Hybrid: 0.7484447956085205, Combined: 0.7133892178535461
2025-02-22 02:10:07,602 - INFO - Appending Batch Losses: Mask: 0.4303693473339081, Hybrid: 0.762527585029602, Combined: 0.6033362150192261
2025-02-22 02:10:08,597 - INFO - Appending Batch Losses: Mask: 0.361886203289032, Hybrid: 0.8052687048912048, Combined: 0.5153499841690063
2025-02-22 02:10:27,562 - INFO - Appending Batch Losses: Mask: 0.42717495560646057, Hybrid: 0.6800118088722229, Combined: 0.5157782435417175
2025-02-22 02:10:28,532 - INFO - Appending Batch Losses: Mask: 0.4184574484825134, Hybrid: 0.62885582447052, Combined: 0.7038572430610657
2025-02-22 02:10:29,510 - INFO - Appending Batch Losses: Mask: 0.5371144413948059, Hybrid: 0.8592081069946289, Combined: 0.7440208792686462
2025-02-22 02:10:30,505 - INFO - Appending Batch Losses: Mask: 0.4381619989871979, Hybrid: 0.754835307598114, Combined: 0.8303892612457275
2025-02-22 02:10:45,285 - INFO - Appending Batch Losses: Mask: 0.39783063530921936, Hybrid: 0.5831760168075562, Combined: 0.5094801187515259
2025-02-22 02:10:46,265 - INFO - Appending Batch Losses: Mask: 0.42785945534706116, Hybrid: 0.6921060085296631, Combined: 0.2237885594367981
2025-02-22 02:10:59,746 - INFO - Appending Batch Losses: Mask: 0.452515184879303, Hybrid: 0.7454006671905518, Combined: 0.5412553548812866
2025-02-22 02:11:00,733 - INFO - Appending Batch Losses: Mask: 0.41590553522109985, Hybrid: 0.8036680221557617, Combined: 0.13076752424240112
2025-02-22 02:11:01,995 - INFO - Appending Batch Losses: Mask: 0.32560858130455017, Hybrid: 0.5716082453727722, Combined: 0.4526998996734619
2025-02-22 02:11:02,962 - INFO - Appending Batch Losses: Mask: 0.32987770438194275, Hybrid: 0.5143459439277649, Combined: 0.5205414295196533
2025-02-22 02:11:12,257 - INFO - Appending Batch Losses: Mask: 0.331997811794281, Hybrid: 0.611258327960968, Combined: 0.37861770391464233
2025-02-22 02:11:13,111 - INFO - Appending Batch Losses: Mask: 0.40217649936676025, Hybrid: 0.8181838393211365, Combined: 0.4932750165462494
2025-02-22 02:11:19,363 - INFO - Appending Batch Losses: Mask: 0.5450830459594727, Hybrid: 0.9166053533554077, Combined: 0.7659069299697876
2025-02-22 02:11:20,349 - INFO - Appending Batch Losses: Mask: 0.5099107623100281, Hybrid: 0.7966114282608032, Combined: 0.9145054221153259
2025-02-22 02:11:21,337 - INFO - Appending Batch Losses: Mask: 0.3408556580543518, Hybrid: 0.5896776914596558, Combined: 0.25688472390174866
2025-02-22 02:11:27,615 - INFO - Appending Batch Losses: Mask: 0.46929794549942017, Hybrid: 0.6934800148010254, Combined: 0.618094801902771
2025-02-22 02:11:35,001 - INFO - Appending Batch Losses: Mask: 0.4277650713920593, Hybrid: 0.7065656185150146, Combined: 0.4014894962310791
2025-02-22 02:11:35,972 - INFO - Appending Batch Losses: Mask: 0.6051406860351562, Hybrid: 0.836264967918396, Combined: 0.8138375878334045
2025-02-22 02:11:58,408 - INFO - Appending Batch Losses: Mask: 0.3789697289466858, Hybrid: 0.7819690704345703, Combined: 0.5040736198425293
2025-02-22 02:11:59,391 - INFO - Appending Batch Losses: Mask: 0.40996742248535156, Hybrid: 0.6672896146774292, Combined: 0.39304012060165405
2025-02-22 02:12:00,374 - INFO - Appending Batch Losses: Mask: 0.39474618434906006, Hybrid: 0.6001652479171753, Combined: 0.5379899144172668
2025-02-22 02:12:01,361 - INFO - Appending Batch Losses: Mask: 0.5030470490455627, Hybrid: 1.0603233575820923, Combined: 0.7165699005126953
2025-02-22 02:12:03,612 - INFO - Current Learning Rate 0.0009452291317180653

2025-02-22 02:12:03,613 - INFO - 
[EPOCH 14]No improvement, NO NEW MODEL CHECKPOINT SAVED at epoch 14
 avg_epoch_loss: [0.546980]
 bestloss: [0.541873]
 Trigger: 10/12

2025-02-22 02:13:33,166 - INFO - 
Trigger times: 10, patience: 15

2025-02-22 02:13:33,167 - INFO - 
Trigger times: 10, patience: 12

2025-02-22 02:13:33,167 - INFO - 
[Epoch Improvement] Epoch 14: Loss improved during training by 4.47% from previous epoch, 

2025-02-22 02:13:33,168 - INFO - ####LOGGING AVERAGE LOSS EPOCH###
[Epoch Summary] Epoch: 14/50, Avg Combined Loss: 0.546980, MaskLoss: 0.426682, Hybridloss: 0.734225Previous Epoch loss: 0.5725468211882824
2025-02-22 02:13:33,168 - INFO - Epoch: 14 COMPLETED





2025-02-22 02:13:33,169 - INFO - [Train] Epoch 15/50 started.

2025-02-22 02:14:10,330 - INFO - #####INPUTS & TARGETS VALUE [2 BATCHES]####
Batch 1: Mixture shape=torch.Size([4, 1, 513, 946]), Target shape=torch.Size([4, 1, 513, 946])
2025-02-22 02:14:11,097 - INFO - [EPOCH 15]outputs from the model torch.Size([4, 64, 513, 946])
for batch 1
predicted mask shape torch.Size([4, 1, 513, 946])
2025-02-22 02:14:12,367 - INFO - Function: [log_first_2_batches_outputs_inputs_targets_predicted_mask]
2025-02-22 02:14:12,369 - INFO - ####OUTPUTS, INPUTS, TARGETS,PREDICTEDMASK [2 BATCHES]####
Batch 1: Mask range: min=0.0000, max=65.1250
Batch 1: Inputs shape=torch.Size([4, 1, 513, 946]), Targets shape=torch.Size([4, 1, 513, 946]), Predicted Mask shape=torch.Size([4, 1, 513, 946]), Outputs shape=torch.Size([4, 64, 513, 946])
Mask min=0.0, max=1.0
[After Mask Application] Predicted vocals min: 0.0, max: 131.5

2025-02-22 02:14:12,370 - INFO - 
####LOSS VALUES####
[Combinedloss]:  Total treningsfeil, [BØR REDUSERES OVER TID]
[MaskLoss]: Sier hvor godt modellen lærer og predikere masken som isolerer vokaler[BØR REDUSERES OVER TID]
[l1_loss og stft_loss] gir ekstra indikasjoner på lydkvalitet.
[Hybridloss]: Kombinasjon av flere tapsfunksjoner[BØR REDUSERES OVER TID]

2025-02-22 02:14:12,386 - INFO - Appending Batch Losses: Mask: 0.3957701325416565, Hybrid: 0.8379509449005127, Combined: 0.7044110894203186
2025-02-22 02:14:13,411 - INFO - [EPOCH 15]outputs from the model torch.Size([4, 64, 513, 946])
for batch 2
predicted mask shape torch.Size([4, 1, 513, 946])
2025-02-22 02:14:14,661 - INFO - Appending Batch Losses: Mask: 0.42769333720207214, Hybrid: 0.7752269506454468, Combined: 0.6823533773422241
2025-02-22 02:14:20,905 - INFO - Appending Batch Losses: Mask: 0.40959739685058594, Hybrid: 0.6892871856689453, Combined: 0.5826085805892944
2025-02-22 02:14:21,913 - INFO - Appending Batch Losses: Mask: 0.3673522472381592, Hybrid: 0.6655305027961731, Combined: 0.23411467671394348
2025-02-22 02:14:22,941 - INFO - Appending Batch Losses: Mask: 0.5542775392532349, Hybrid: 0.8528597354888916, Combined: 0.8253336548805237
2025-02-22 02:14:24,432 - INFO - Appending Batch Losses: Mask: 0.4135841727256775, Hybrid: 0.7281584739685059, Combined: 0.28681567311286926
2025-02-22 02:14:41,713 - INFO - Appending Batch Losses: Mask: 0.35017257928848267, Hybrid: 0.5046423673629761, Combined: 0.40970638394355774
2025-02-22 02:14:42,735 - INFO - Appending Batch Losses: Mask: 0.35122138261795044, Hybrid: 0.6862360239028931, Combined: 0.4162474274635315
2025-02-22 02:14:57,195 - INFO - Appending Batch Losses: Mask: 0.3960322439670563, Hybrid: 0.6423943042755127, Combined: 0.5110532641410828
2025-02-22 02:14:58,203 - INFO - Appending Batch Losses: Mask: 0.4645621180534363, Hybrid: 0.732937753200531, Combined: 0.5218520760536194
2025-02-22 02:14:59,445 - INFO - Appending Batch Losses: Mask: 0.3277134895324707, Hybrid: 0.6425238847732544, Combined: 0.34657299518585205
2025-02-22 02:15:00,448 - INFO - Appending Batch Losses: Mask: 0.41348710656166077, Hybrid: 0.6924564838409424, Combined: 0.3750098943710327
2025-02-22 02:15:12,354 - INFO - Appending Batch Losses: Mask: 0.4788326025009155, Hybrid: 0.7511072158813477, Combined: 0.4487308859825134
2025-02-22 02:15:13,220 - INFO - Appending Batch Losses: Mask: 0.3039631247520447, Hybrid: 0.6817676424980164, Combined: 0.6127941012382507
2025-02-22 02:15:14,081 - INFO - Appending Batch Losses: Mask: 0.45557472109794617, Hybrid: 0.6846917867660522, Combined: 0.8135836124420166
2025-02-22 02:15:15,070 - INFO - Appending Batch Losses: Mask: 0.48088279366493225, Hybrid: 0.7636584043502808, Combined: 0.7089613080024719
2025-02-22 02:15:16,084 - INFO - Appending Batch Losses: Mask: 0.3370249569416046, Hybrid: 0.6217907071113586, Combined: 0.4016750454902649
2025-02-22 02:15:17,633 - INFO - Appending Batch Losses: Mask: 0.3680790066719055, Hybrid: 0.6955264806747437, Combined: 0.19502565264701843
2025-02-22 02:15:39,016 - INFO - Appending Batch Losses: Mask: 0.41462498903274536, Hybrid: 0.7924081087112427, Combined: 0.2280064821243286
2025-02-22 02:15:39,894 - INFO - Appending Batch Losses: Mask: 0.47179508209228516, Hybrid: 0.7478358745574951, Combined: 0.5885969996452332
2025-02-22 02:16:05,241 - INFO - Appending Batch Losses: Mask: 0.444976270198822, Hybrid: 0.6934738159179688, Combined: 0.378071129322052
2025-02-22 02:16:06,228 - INFO - Appending Batch Losses: Mask: 0.3809182345867157, Hybrid: 0.7720968723297119, Combined: 0.5360881686210632
2025-02-22 02:16:07,212 - INFO - Appending Batch Losses: Mask: 0.35967206954956055, Hybrid: 0.4815639853477478, Combined: 0.6175565719604492
2025-02-22 02:16:08,198 - INFO - Appending Batch Losses: Mask: 0.38639381527900696, Hybrid: 0.7709009647369385, Combined: 0.24381431937217712
2025-02-22 02:16:09,198 - INFO - Appending Batch Losses: Mask: 0.570716381072998, Hybrid: 0.9390955567359924, Combined: 0.7575225830078125
2025-02-22 02:16:10,187 - INFO - Appending Batch Losses: Mask: 0.4063529968261719, Hybrid: 0.8759264945983887, Combined: 0.734306275844574
2025-02-22 02:16:33,383 - INFO - Appending Batch Losses: Mask: 0.4521622955799103, Hybrid: 0.8592591285705566, Combined: 0.28675276041030884
2025-02-22 02:16:34,227 - INFO - Appending Batch Losses: Mask: 0.44039368629455566, Hybrid: 0.7121056318283081, Combined: 0.4606683850288391
2025-02-22 02:16:35,217 - INFO - Appending Batch Losses: Mask: 0.36336901783943176, Hybrid: 0.6404088735580444, Combined: 0.46198225021362305
2025-02-22 02:16:36,205 - INFO - Appending Batch Losses: Mask: 0.4800802171230316, Hybrid: 0.9269092082977295, Combined: 0.7252492308616638
2025-02-22 02:16:37,190 - INFO - Appending Batch Losses: Mask: 0.4529739022254944, Hybrid: 0.7946505546569824, Combined: 0.49878251552581787
2025-02-22 02:16:38,184 - INFO - Appending Batch Losses: Mask: 0.4391443133354187, Hybrid: 0.793418288230896, Combined: 0.5430462956428528
2025-02-22 02:17:06,255 - INFO - Appending Batch Losses: Mask: 0.3902387320995331, Hybrid: 0.5445730090141296, Combined: 0.6410166025161743
2025-02-22 02:17:07,233 - INFO - Appending Batch Losses: Mask: 0.4958319664001465, Hybrid: 0.7822558879852295, Combined: 0.7098832726478577
2025-02-22 02:17:08,446 - INFO - Appending Batch Losses: Mask: 0.36922740936279297, Hybrid: 0.6779698133468628, Combined: 0.20542284846305847
2025-02-22 02:17:09,428 - INFO - Appending Batch Losses: Mask: 0.3843982517719269, Hybrid: 0.5989391803741455, Combined: 0.39535221457481384
2025-02-22 02:17:10,275 - INFO - Appending Batch Losses: Mask: 0.31585362553596497, Hybrid: 0.6294879913330078, Combined: 0.4247196316719055
2025-02-22 02:17:12,311 - INFO - Current Learning Rate 0.0009537959186018782

2025-02-22 02:17:13,778 - INFO - Checkpoint saved: /mnt/c/Users/didri/Desktop/Programmering/ArtificalintelligenceModels/UNet-Model_Vocal_Isolation/Unet_model_Audio_Seperation/Model_Weights/CheckPoints/Training/checkpoint_epoch_14.pth
2025-02-22 02:17:13,778 - INFO - 
 [EPOCH 15]Model Checkpoint SAVED at epoch 15
 avg_epoch_loss: [0.500370]
 bestloss: [0.500370]
 Trigger times: 0/12

2025-02-22 02:18:44,195 - INFO - 
Trigger times: 11, patience: 15

2025-02-22 02:18:44,195 - INFO - 
Trigger times: 11, patience: 12

2025-02-22 02:18:44,195 - INFO - 
[Epoch Improvement] Epoch 15: Loss improved during training by 8.52% from previous epoch, 

2025-02-22 02:18:44,197 - INFO - ####LOGGING AVERAGE LOSS EPOCH###
[Epoch Summary] Epoch: 15/50, Avg Combined Loss: 0.500370, MaskLoss: 0.425831, Hybridloss: 0.733352Previous Epoch loss: 0.546979667769896
2025-02-22 02:18:44,198 - INFO - Epoch: 15 COMPLETED





2025-02-22 02:18:44,199 - INFO - [Train] Epoch 16/50 started.

2025-02-22 02:19:28,469 - INFO - #####INPUTS & TARGETS VALUE [2 BATCHES]####
Batch 1: Mixture shape=torch.Size([4, 1, 513, 946]), Target shape=torch.Size([4, 1, 513, 946])
2025-02-22 02:19:29,282 - INFO - [EPOCH 16]outputs from the model torch.Size([4, 64, 513, 946])
for batch 1
predicted mask shape torch.Size([4, 1, 513, 946])
2025-02-22 02:19:30,535 - INFO - Function: [log_first_2_batches_outputs_inputs_targets_predicted_mask]
2025-02-22 02:19:30,537 - INFO - ####OUTPUTS, INPUTS, TARGETS,PREDICTEDMASK [2 BATCHES]####
Batch 1: Mask range: min=0.0000, max=111.0625
Batch 1: Inputs shape=torch.Size([4, 1, 513, 946]), Targets shape=torch.Size([4, 1, 513, 946]), Predicted Mask shape=torch.Size([4, 1, 513, 946]), Outputs shape=torch.Size([4, 64, 513, 946])
Mask min=0.0, max=1.0
[After Mask Application] Predicted vocals min: 0.0, max: 140.125

2025-02-22 02:19:30,538 - INFO - 
####LOSS VALUES####
[Combinedloss]:  Total treningsfeil, [BØR REDUSERES OVER TID]
[MaskLoss]: Sier hvor godt modellen lærer og predikere masken som isolerer vokaler[BØR REDUSERES OVER TID]
[l1_loss og stft_loss] gir ekstra indikasjoner på lydkvalitet.
[Hybridloss]: Kombinasjon av flere tapsfunksjoner[BØR REDUSERES OVER TID]

2025-02-22 02:19:30,551 - INFO - Appending Batch Losses: Mask: 0.4697439968585968, Hybrid: 0.8263759613037109, Combined: 0.7752690315246582
2025-02-22 02:19:31,524 - INFO - [EPOCH 16]outputs from the model torch.Size([4, 64, 513, 946])
for batch 2
predicted mask shape torch.Size([4, 1, 513, 946])
2025-02-22 02:19:32,713 - INFO - Appending Batch Losses: Mask: 0.40654775500297546, Hybrid: 0.7582794427871704, Combined: 0.33615806698799133
2025-02-22 02:19:33,708 - INFO - Appending Batch Losses: Mask: 0.4783395528793335, Hybrid: 0.6970455646514893, Combined: 0.668604850769043
2025-02-22 02:19:34,582 - INFO - Appending Batch Losses: Mask: 0.45905983448028564, Hybrid: 0.7015892267227173, Combined: 0.3052154779434204
2025-02-22 02:19:35,449 - INFO - Appending Batch Losses: Mask: 0.49700239300727844, Hybrid: 0.7618652582168579, Combined: 0.7682843804359436
2025-02-22 02:19:36,767 - INFO - Appending Batch Losses: Mask: 0.5522749423980713, Hybrid: 0.8331709504127502, Combined: 0.7954854369163513
2025-02-22 02:19:57,158 - INFO - Appending Batch Losses: Mask: 0.4098026752471924, Hybrid: 0.6660245060920715, Combined: 0.39369261264801025
2025-02-22 02:19:58,161 - INFO - Appending Batch Losses: Mask: 0.2671468257904053, Hybrid: 0.6442813873291016, Combined: 0.43367448449134827
2025-02-22 02:19:59,145 - INFO - Appending Batch Losses: Mask: 0.46892374753952026, Hybrid: 0.7209727764129639, Combined: 0.24217519164085388
2025-02-22 02:20:00,138 - INFO - Appending Batch Losses: Mask: 0.3831719160079956, Hybrid: 0.6052480936050415, Combined: 0.6013226509094238
2025-02-22 02:20:01,134 - INFO - Appending Batch Losses: Mask: 0.4751845896244049, Hybrid: 0.6873127222061157, Combined: 0.6022186875343323
2025-02-22 02:20:02,123 - INFO - Appending Batch Losses: Mask: 0.4537544846534729, Hybrid: 0.7452218532562256, Combined: 0.6562556028366089
2025-02-22 02:20:38,533 - INFO - Appending Batch Losses: Mask: 0.30873221158981323, Hybrid: 0.4980888366699219, Combined: 0.5141549706459045
2025-02-22 02:20:39,641 - INFO - Appending Batch Losses: Mask: 0.4914228618144989, Hybrid: 0.7252079248428345, Combined: 0.850030779838562
2025-02-22 02:20:40,500 - INFO - Appending Batch Losses: Mask: 0.4573749303817749, Hybrid: 0.7608239054679871, Combined: 0.9624773859977722
2025-02-22 02:20:41,488 - INFO - Appending Batch Losses: Mask: 0.4307037591934204, Hybrid: 0.720596432685852, Combined: 0.3183419406414032
2025-02-22 02:20:42,493 - INFO - Appending Batch Losses: Mask: 0.5182069540023804, Hybrid: 0.8555431365966797, Combined: 0.401887983083725
2025-02-22 02:20:43,485 - INFO - Appending Batch Losses: Mask: 0.5120348334312439, Hybrid: 0.8005667328834534, Combined: 0.6107310056686401
2025-02-22 02:21:09,181 - INFO - Appending Batch Losses: Mask: 0.3972000479698181, Hybrid: 0.7313231229782104, Combined: 0.24233588576316833
2025-02-22 02:21:10,174 - INFO - Appending Batch Losses: Mask: 0.36880865693092346, Hybrid: 0.5382208824157715, Combined: 0.6826426386833191
2025-02-22 02:21:11,141 - INFO - Appending Batch Losses: Mask: 0.3994535803794861, Hybrid: 0.869036078453064, Combined: 0.4457700848579407
2025-02-22 02:21:12,386 - INFO - Appending Batch Losses: Mask: 0.4516133964061737, Hybrid: 0.6424158215522766, Combined: 0.32086220383644104
2025-02-22 02:21:13,362 - INFO - Appending Batch Losses: Mask: 0.43709796667099, Hybrid: 0.7468773126602173, Combined: 0.5398002862930298
2025-02-22 02:21:14,351 - INFO - Appending Batch Losses: Mask: 0.387448251247406, Hybrid: 0.6470397114753723, Combined: 0.33231139183044434
2025-02-22 02:21:37,037 - INFO - Appending Batch Losses: Mask: 0.3377142548561096, Hybrid: 0.7554928064346313, Combined: 0.27717292308807373
2025-02-22 02:21:38,048 - INFO - Appending Batch Losses: Mask: 0.48148149251937866, Hybrid: 0.730832576751709, Combined: 0.69577956199646
2025-02-22 02:21:39,029 - INFO - Appending Batch Losses: Mask: 0.40482163429260254, Hybrid: 0.5767021775245667, Combined: 0.9051514863967896
2025-02-22 02:21:40,020 - INFO - Appending Batch Losses: Mask: 0.4487423896789551, Hybrid: 0.7413430213928223, Combined: 0.7104789018630981
2025-02-22 02:21:41,001 - INFO - Appending Batch Losses: Mask: 0.4481489062309265, Hybrid: 0.6806144714355469, Combined: 0.204012930393219
2025-02-22 02:21:42,243 - INFO - Appending Batch Losses: Mask: 0.37680578231811523, Hybrid: 0.6852501630783081, Combined: 0.5198755264282227
2025-02-22 02:21:54,939 - INFO - Appending Batch Losses: Mask: 0.4274321496486664, Hybrid: 0.8003678321838379, Combined: 0.36768555641174316
2025-02-22 02:21:56,817 - INFO - Appending Batch Losses: Mask: 0.42560404539108276, Hybrid: 0.7145334482192993, Combined: 0.622846245765686
2025-02-22 02:21:57,799 - INFO - Appending Batch Losses: Mask: 0.46470534801483154, Hybrid: 0.9324069023132324, Combined: 0.7368823289871216
2025-02-22 02:22:02,324 - INFO - Appending Batch Losses: Mask: 0.4176872968673706, Hybrid: 0.9164533019065857, Combined: 0.7732468843460083
2025-02-22 02:22:03,302 - INFO - Appending Batch Losses: Mask: 0.46954768896102905, Hybrid: 0.7154767513275146, Combined: 0.7044817805290222
2025-02-22 02:22:04,277 - INFO - Appending Batch Losses: Mask: 0.3353714048862457, Hybrid: 0.5366851687431335, Combined: 0.21191349625587463
2025-02-22 02:22:17,386 - INFO - Appending Batch Losses: Mask: 0.3556041419506073, Hybrid: 0.6835426092147827, Combined: 0.4323132634162903
2025-02-22 02:22:19,849 - INFO - Current Learning Rate 0.0009620100611362594

2025-02-22 02:22:19,849 - INFO - 
[EPOCH 16]No improvement, NO NEW MODEL CHECKPOINT SAVED at epoch 16
 avg_epoch_loss: [0.539501]
 bestloss: [0.500370]
 Trigger: 12/12

2025-02-22 02:23:49,668 - INFO - 
Trigger times: 0, patience: 15

2025-02-22 02:23:49,669 - INFO - 
Trigger times: 0, patience: 12

2025-02-22 02:23:49,669 - INFO - 
[Epoch Improvement] Epoch 16: Loss improved during training by -7.82% from previous epoch, 

2025-02-22 02:23:49,670 - INFO - ####LOGGING AVERAGE LOSS EPOCH###
[Epoch Summary] Epoch: 16/50, Avg Combined Loss: 0.539501, MaskLoss: 0.426032, Hybridloss: 0.732539Previous Epoch loss: 0.5003699523371619
2025-02-22 02:23:49,671 - INFO - Epoch: 16 COMPLETED





2025-02-22 02:23:49,675 - INFO - [Train] Epoch 17/50 started.

2025-02-22 02:24:32,215 - INFO - #####INPUTS & TARGETS VALUE [2 BATCHES]####
Batch 1: Mixture shape=torch.Size([3, 1, 513, 946]), Target shape=torch.Size([3, 1, 513, 946])
2025-02-22 02:24:33,080 - INFO - [EPOCH 17]outputs from the model torch.Size([3, 64, 513, 946])
for batch 1
predicted mask shape torch.Size([3, 1, 513, 946])
2025-02-22 02:24:34,324 - INFO - Function: [log_first_2_batches_outputs_inputs_targets_predicted_mask]
2025-02-22 02:24:34,326 - INFO - ####OUTPUTS, INPUTS, TARGETS,PREDICTEDMASK [2 BATCHES]####
Batch 1: Mask range: min=0.0000, max=72.8750
Batch 1: Inputs shape=torch.Size([3, 1, 513, 946]), Targets shape=torch.Size([3, 1, 513, 946]), Predicted Mask shape=torch.Size([3, 1, 513, 946]), Outputs shape=torch.Size([3, 64, 513, 946])
Mask min=0.0, max=1.0
[After Mask Application] Predicted vocals min: 0.0, max: 148.375

2025-02-22 02:24:34,327 - INFO - 
####LOSS VALUES####
[Combinedloss]:  Total treningsfeil, [BØR REDUSERES OVER TID]
[MaskLoss]: Sier hvor godt modellen lærer og predikere masken som isolerer vokaler[BØR REDUSERES OVER TID]
[l1_loss og stft_loss] gir ekstra indikasjoner på lydkvalitet.
[Hybridloss]: Kombinasjon av flere tapsfunksjoner[BØR REDUSERES OVER TID]

2025-02-22 02:24:34,338 - INFO - Appending Batch Losses: Mask: 0.42163246870040894, Hybrid: 0.7559913992881775, Combined: 0.4625124931335449
2025-02-22 02:24:35,193 - INFO - [EPOCH 17]outputs from the model torch.Size([4, 64, 513, 946])
for batch 2
predicted mask shape torch.Size([4, 1, 513, 946])
2025-02-22 02:24:36,341 - INFO - Appending Batch Losses: Mask: 0.3998984098434448, Hybrid: 0.7787454724311829, Combined: 0.14884817600250244
2025-02-22 02:24:37,329 - INFO - Appending Batch Losses: Mask: 0.42551562190055847, Hybrid: 0.6545963883399963, Combined: 0.4983920753002167
2025-02-22 02:24:38,326 - INFO - Appending Batch Losses: Mask: 0.4983827471733093, Hybrid: 0.772346019744873, Combined: 0.7602509260177612
2025-02-22 02:24:39,328 - INFO - Appending Batch Losses: Mask: 0.44809794425964355, Hybrid: 0.767275333404541, Combined: 0.33693206310272217
2025-02-22 02:24:40,358 - INFO - Appending Batch Losses: Mask: 0.3703870177268982, Hybrid: 0.7719626426696777, Combined: 0.42878225445747375
2025-02-22 02:25:05,990 - INFO - Appending Batch Losses: Mask: 0.5017880201339722, Hybrid: 0.7825670838356018, Combined: 0.8227428197860718
2025-02-22 02:25:06,973 - INFO - Appending Batch Losses: Mask: 0.35439440608024597, Hybrid: 0.6552215814590454, Combined: -0.007417023181915283
2025-02-22 02:25:08,201 - INFO - Appending Batch Losses: Mask: 0.45998868346214294, Hybrid: 0.7419452667236328, Combined: 0.5657644867897034
2025-02-22 02:25:09,173 - INFO - Appending Batch Losses: Mask: 0.4363168179988861, Hybrid: 0.7043802738189697, Combined: 0.5765536427497864
2025-02-22 02:25:10,164 - INFO - Appending Batch Losses: Mask: 0.40560394525527954, Hybrid: 0.7433992624282837, Combined: 0.5831674337387085
2025-02-22 02:25:11,160 - INFO - Appending Batch Losses: Mask: 0.5671287178993225, Hybrid: 0.8343265056610107, Combined: 0.8231696486473083
2025-02-22 02:25:41,310 - INFO - Appending Batch Losses: Mask: 0.37058573961257935, Hybrid: 0.6366978883743286, Combined: 0.5845985412597656
2025-02-22 02:25:42,298 - INFO - Appending Batch Losses: Mask: 0.5139992237091064, Hybrid: 0.8404966592788696, Combined: 0.7823030948638916
2025-02-22 02:25:43,148 - INFO - Appending Batch Losses: Mask: 0.43617135286331177, Hybrid: 0.7673131227493286, Combined: 0.7232192158699036
2025-02-22 02:25:44,005 - INFO - Appending Batch Losses: Mask: 0.41878190636634827, Hybrid: 0.7311016917228699, Combined: 0.5412523746490479
2025-02-22 02:25:45,252 - INFO - Appending Batch Losses: Mask: 0.5383497476577759, Hybrid: 0.8404223918914795, Combined: 0.6720106601715088
2025-02-22 02:25:46,246 - INFO - Appending Batch Losses: Mask: 0.3865174651145935, Hybrid: 0.8226292133331299, Combined: 0.41339242458343506
2025-02-22 02:26:16,010 - INFO - Appending Batch Losses: Mask: 0.3327469527721405, Hybrid: 0.6525790095329285, Combined: 0.5881213545799255
2025-02-22 02:26:17,003 - INFO - Appending Batch Losses: Mask: 0.49853605031967163, Hybrid: 0.7159211039543152, Combined: 0.6003094911575317
2025-02-22 02:26:18,000 - INFO - Appending Batch Losses: Mask: 0.4674077033996582, Hybrid: 0.7246177196502686, Combined: 0.7946434617042542
2025-02-22 02:26:19,001 - INFO - Appending Batch Losses: Mask: 0.4848397374153137, Hybrid: 0.7315235733985901, Combined: 0.5015480518341064
2025-02-22 02:26:19,986 - INFO - Appending Batch Losses: Mask: 0.38618016242980957, Hybrid: 0.5959096550941467, Combined: 0.7221354246139526
2025-02-22 02:26:20,980 - INFO - Appending Batch Losses: Mask: 0.5098505020141602, Hybrid: 0.8028405904769897, Combined: 0.5432168245315552
2025-02-22 02:26:48,043 - INFO - Appending Batch Losses: Mask: 0.29483646154403687, Hybrid: 0.5956863164901733, Combined: 0.16841772198677063
2025-02-22 02:26:49,021 - INFO - Appending Batch Losses: Mask: 0.47894707322120667, Hybrid: 0.7002983689308167, Combined: 0.6724178194999695
2025-02-22 02:26:50,005 - INFO - Appending Batch Losses: Mask: 0.39177489280700684, Hybrid: 0.6155540943145752, Combined: 0.39897751808166504
2025-02-22 02:26:50,990 - INFO - Appending Batch Losses: Mask: 0.5111383199691772, Hybrid: 0.8998167514801025, Combined: 0.6408451199531555
2025-02-22 02:26:51,975 - INFO - Appending Batch Losses: Mask: 0.4262855052947998, Hybrid: 0.7804362177848816, Combined: 0.5966594219207764
2025-02-22 02:26:52,950 - INFO - Appending Batch Losses: Mask: 0.36725887656211853, Hybrid: 0.6310759782791138, Combined: 0.44378745555877686
2025-02-22 02:27:10,770 - INFO - Appending Batch Losses: Mask: 0.31888726353645325, Hybrid: 0.49007177352905273, Combined: -0.07633620500564575
2025-02-22 02:27:11,744 - INFO - Appending Batch Losses: Mask: 0.4944634437561035, Hybrid: 0.8370226621627808, Combined: 0.6915871500968933
2025-02-22 02:27:12,861 - INFO - Appending Batch Losses: Mask: 0.4713360071182251, Hybrid: 0.7534114122390747, Combined: 0.6572175025939941
2025-02-22 02:27:13,699 - INFO - Appending Batch Losses: Mask: 0.4020240306854248, Hybrid: 0.6031578779220581, Combined: 0.5812414884567261
2025-02-22 02:27:14,672 - INFO - Appending Batch Losses: Mask: 0.5217115879058838, Hybrid: 0.86299729347229, Combined: 0.601640522480011
2025-02-22 02:27:15,652 - INFO - Appending Batch Losses: Mask: 0.28480955958366394, Hybrid: 0.4978322386741638, Combined: 0.3783344626426697
2025-02-22 02:27:34,881 - INFO - Appending Batch Losses: Mask: 0.42070892453193665, Hybrid: 0.7274404764175415, Combined: 0.35650959610939026
2025-02-22 02:27:37,000 - INFO - Current Learning Rate 0.0009683463231970777

2025-02-22 02:27:37,001 - INFO - 
[EPOCH 17]No improvement, NO NEW MODEL CHECKPOINT SAVED at epoch 17
 avg_epoch_loss: [0.529128]
 bestloss: [0.500370]
 Trigger: 1/12

2025-02-22 02:29:01,662 - INFO - 
Trigger times: 1, patience: 15

2025-02-22 02:29:01,663 - INFO - 
Trigger times: 1, patience: 12

2025-02-22 02:29:01,663 - INFO - 
[Epoch Improvement] Epoch 17: Loss improved during training by 1.92% from previous epoch, 

2025-02-22 02:29:01,663 - INFO - ####LOGGING AVERAGE LOSS EPOCH###
[Epoch Summary] Epoch: 17/50, Avg Combined Loss: 0.529128, MaskLoss: 0.426436, Hybridloss: 0.732087Previous Epoch loss: 0.5395011869636742
2025-02-22 02:29:01,664 - INFO - Epoch: 17 COMPLETED





2025-02-22 02:29:01,665 - INFO - [Train] Epoch 18/50 started.

2025-02-22 02:29:37,752 - INFO - #####INPUTS & TARGETS VALUE [2 BATCHES]####
Batch 1: Mixture shape=torch.Size([4, 1, 513, 946]), Target shape=torch.Size([4, 1, 513, 946])
2025-02-22 02:29:38,687 - INFO - [EPOCH 18]outputs from the model torch.Size([4, 64, 513, 946])
for batch 1
predicted mask shape torch.Size([4, 1, 513, 946])
2025-02-22 02:29:39,953 - INFO - Function: [log_first_2_batches_outputs_inputs_targets_predicted_mask]
2025-02-22 02:29:39,956 - INFO - ####OUTPUTS, INPUTS, TARGETS,PREDICTEDMASK [2 BATCHES]####
Batch 1: Mask range: min=0.0000, max=131.3750
Batch 1: Inputs shape=torch.Size([4, 1, 513, 946]), Targets shape=torch.Size([4, 1, 513, 946]), Predicted Mask shape=torch.Size([4, 1, 513, 946]), Outputs shape=torch.Size([4, 64, 513, 946])
Mask min=0.0, max=1.0
[After Mask Application] Predicted vocals min: 0.0, max: 144.25

2025-02-22 02:29:39,956 - INFO - 
####LOSS VALUES####
[Combinedloss]:  Total treningsfeil, [BØR REDUSERES OVER TID]
[MaskLoss]: Sier hvor godt modellen lærer og predikere masken som isolerer vokaler[BØR REDUSERES OVER TID]
[l1_loss og stft_loss] gir ekstra indikasjoner på lydkvalitet.
[Hybridloss]: Kombinasjon av flere tapsfunksjoner[BØR REDUSERES OVER TID]

2025-02-22 02:29:39,968 - INFO - Appending Batch Losses: Mask: 0.34549829363822937, Hybrid: 0.570366621017456, Combined: 0.6129608154296875
2025-02-22 02:29:40,952 - INFO - [EPOCH 18]outputs from the model torch.Size([4, 64, 513, 946])
for batch 2
predicted mask shape torch.Size([4, 1, 513, 946])
2025-02-22 02:29:42,185 - INFO - Appending Batch Losses: Mask: 0.44326096773147583, Hybrid: 0.7122182846069336, Combined: 0.6465039253234863
2025-02-22 02:29:43,415 - INFO - Appending Batch Losses: Mask: 0.40794193744659424, Hybrid: 0.6812872290611267, Combined: 0.6638720631599426
2025-02-22 02:29:49,972 - INFO - Appending Batch Losses: Mask: 0.41083210706710815, Hybrid: 0.5923473834991455, Combined: 0.5071685910224915
2025-02-22 02:29:50,826 - INFO - Appending Batch Losses: Mask: 0.42175859212875366, Hybrid: 0.6922037601470947, Combined: 0.608991265296936
2025-02-22 02:29:51,809 - INFO - Appending Batch Losses: Mask: 0.4479578733444214, Hybrid: 0.6877744197845459, Combined: 0.6602211594581604
2025-02-22 02:29:56,852 - INFO - Appending Batch Losses: Mask: 0.38493597507476807, Hybrid: 0.6949418187141418, Combined: 0.40017786622047424
2025-02-22 02:30:28,925 - INFO - Appending Batch Losses: Mask: 0.3849502205848694, Hybrid: 0.6660223603248596, Combined: 0.6226409673690796
2025-02-22 02:30:29,931 - INFO - Appending Batch Losses: Mask: 0.4677056670188904, Hybrid: 0.7675030827522278, Combined: 0.7278321385383606
2025-02-22 02:30:30,914 - INFO - Appending Batch Losses: Mask: 0.4168391227722168, Hybrid: 0.6356464624404907, Combined: 0.571140706539154
2025-02-22 02:30:31,899 - INFO - Appending Batch Losses: Mask: 0.4435015022754669, Hybrid: 0.7245310544967651, Combined: 0.5777193307876587
2025-02-22 02:30:33,123 - INFO - Appending Batch Losses: Mask: 0.4534223973751068, Hybrid: 0.7105848789215088, Combined: 0.6262393593788147
2025-02-22 02:30:34,100 - INFO - Appending Batch Losses: Mask: 0.4293951988220215, Hybrid: 0.7536778450012207, Combined: 0.586024284362793
2025-02-22 02:31:00,196 - INFO - Appending Batch Losses: Mask: 0.38255494832992554, Hybrid: 0.6457493305206299, Combined: 0.4421952962875366
2025-02-22 02:31:01,171 - INFO - Appending Batch Losses: Mask: 0.496819406747818, Hybrid: 0.7362226247787476, Combined: 0.6076567769050598
2025-02-22 02:31:02,146 - INFO - Appending Batch Losses: Mask: 0.3754160404205322, Hybrid: 0.5744595527648926, Combined: 0.5051421523094177
2025-02-22 02:31:03,124 - INFO - Appending Batch Losses: Mask: 0.3310956656932831, Hybrid: 0.6230646371841431, Combined: 0.047608256340026855
2025-02-22 02:31:04,115 - INFO - Appending Batch Losses: Mask: 0.4000629484653473, Hybrid: 0.6629953384399414, Combined: 0.5958551168441772
2025-02-22 02:31:05,100 - INFO - Appending Batch Losses: Mask: 0.4778350293636322, Hybrid: 0.7298955321311951, Combined: 0.7023597359657288
2025-02-22 02:31:31,419 - INFO - Appending Batch Losses: Mask: 0.526279866695404, Hybrid: 0.872390866279602, Combined: 0.6202807426452637
2025-02-22 02:31:40,352 - INFO - Appending Batch Losses: Mask: 0.42330044507980347, Hybrid: 0.8016132116317749, Combined: 0.7064430117607117
2025-02-22 02:31:41,200 - INFO - Appending Batch Losses: Mask: 0.6234791278839111, Hybrid: 1.324560523033142, Combined: 0.9474973678588867
2025-02-22 02:31:42,041 - INFO - Appending Batch Losses: Mask: 0.42675232887268066, Hybrid: 0.6609695553779602, Combined: 0.5707007050514221
2025-02-22 02:31:43,017 - INFO - Appending Batch Losses: Mask: 0.4051060080528259, Hybrid: 0.8082510828971863, Combined: 0.6708698272705078
2025-02-22 02:31:43,992 - INFO - Appending Batch Losses: Mask: 0.4206615090370178, Hybrid: 0.6750781536102295, Combined: 0.4980126619338989
2025-02-22 02:32:03,852 - INFO - Appending Batch Losses: Mask: 0.40760886669158936, Hybrid: 0.7749413251876831, Combined: 0.5293084383010864
2025-02-22 02:32:06,971 - INFO - Appending Batch Losses: Mask: 0.3821236193180084, Hybrid: 0.7039040327072144, Combined: 0.5132443308830261
2025-02-22 02:32:08,239 - INFO - Appending Batch Losses: Mask: 0.3981078267097473, Hybrid: 0.7850052714347839, Combined: 0.5422477722167969
2025-02-22 02:32:09,211 - INFO - Appending Batch Losses: Mask: 0.3876988887786865, Hybrid: 0.6667312383651733, Combined: 0.47920548915863037
2025-02-22 02:32:10,196 - INFO - Appending Batch Losses: Mask: 0.39237940311431885, Hybrid: 0.6180010437965393, Combined: 0.4116609990596771
2025-02-22 02:32:11,175 - INFO - Appending Batch Losses: Mask: 0.46815598011016846, Hybrid: 0.757840633392334, Combined: 0.4917328357696533
2025-02-22 02:32:34,885 - INFO - Appending Batch Losses: Mask: 0.6010483503341675, Hybrid: 0.8898962736129761, Combined: 0.8961463570594788
2025-02-22 02:32:35,860 - INFO - Appending Batch Losses: Mask: 0.4248847961425781, Hybrid: 0.6886790990829468, Combined: 0.5451446175575256
2025-02-22 02:32:36,832 - INFO - Appending Batch Losses: Mask: 0.5231279134750366, Hybrid: 0.8328031301498413, Combined: 0.729342520236969
2025-02-22 02:32:37,804 - INFO - Appending Batch Losses: Mask: 0.4804336428642273, Hybrid: 0.9087580442428589, Combined: 0.7021842002868652
2025-02-22 02:32:38,971 - INFO - Appending Batch Losses: Mask: 0.40350547432899475, Hybrid: 0.7427935004234314, Combined: 0.5733492374420166
2025-02-22 02:32:39,933 - INFO - Appending Batch Losses: Mask: 0.3462201654911041, Hybrid: 0.6149969100952148, Combined: 0.40071070194244385
2025-02-22 02:32:42,127 - INFO - Current Learning Rate 0.0009759938293620716

2025-02-22 02:32:42,128 - INFO - 
[EPOCH 18]No improvement, NO NEW MODEL CHECKPOINT SAVED at epoch 18
 avg_epoch_loss: [0.582173]
 bestloss: [0.500370]
 Trigger: 2/12

2025-02-22 02:34:08,304 - INFO - 
Trigger times: 2, patience: 15

2025-02-22 02:34:08,304 - INFO - 
Trigger times: 2, patience: 12

2025-02-22 02:34:08,305 - INFO - 
[Epoch Improvement] Epoch 18: Loss improved during training by -10.02% from previous epoch, 

2025-02-22 02:34:08,305 - INFO - ####LOGGING AVERAGE LOSS EPOCH###
[Epoch Summary] Epoch: 18/50, Avg Combined Loss: 0.582173, MaskLoss: 0.426713, Hybridloss: 0.731939Previous Epoch loss: 0.5291283646145383
2025-02-22 02:34:08,306 - INFO - Epoch: 18 COMPLETED





2025-02-22 02:34:08,307 - INFO - [Train] Epoch 19/50 started.

2025-02-22 02:34:37,134 - INFO - #####INPUTS & TARGETS VALUE [2 BATCHES]####
Batch 1: Mixture shape=torch.Size([4, 1, 513, 946]), Target shape=torch.Size([4, 1, 513, 946])
2025-02-22 02:34:38,174 - INFO - [EPOCH 19]outputs from the model torch.Size([4, 64, 513, 946])
for batch 1
predicted mask shape torch.Size([4, 1, 513, 946])
2025-02-22 02:34:39,384 - INFO - Function: [log_first_2_batches_outputs_inputs_targets_predicted_mask]
2025-02-22 02:34:39,387 - INFO - ####OUTPUTS, INPUTS, TARGETS,PREDICTEDMASK [2 BATCHES]####
Batch 1: Mask range: min=0.0000, max=57.5938
Batch 1: Inputs shape=torch.Size([4, 1, 513, 946]), Targets shape=torch.Size([4, 1, 513, 946]), Predicted Mask shape=torch.Size([4, 1, 513, 946]), Outputs shape=torch.Size([4, 64, 513, 946])
Mask min=0.0, max=1.0
[After Mask Application] Predicted vocals min: 0.0, max: 141.25

2025-02-22 02:34:39,387 - INFO - 
####LOSS VALUES####
[Combinedloss]:  Total treningsfeil, [BØR REDUSERES OVER TID]
[MaskLoss]: Sier hvor godt modellen lærer og predikere masken som isolerer vokaler[BØR REDUSERES OVER TID]
[l1_loss og stft_loss] gir ekstra indikasjoner på lydkvalitet.
[Hybridloss]: Kombinasjon av flere tapsfunksjoner[BØR REDUSERES OVER TID]

2025-02-22 02:34:39,399 - INFO - Appending Batch Losses: Mask: 0.5261095762252808, Hybrid: 0.8604789972305298, Combined: 0.7661837339401245
2025-02-22 02:34:57,790 - INFO - [EPOCH 19]outputs from the model torch.Size([4, 64, 513, 946])
for batch 2
predicted mask shape torch.Size([4, 1, 513, 946])
2025-02-22 02:34:58,949 - INFO - Appending Batch Losses: Mask: 0.43525177240371704, Hybrid: 0.7661813497543335, Combined: 0.4239026606082916
2025-02-22 02:34:59,936 - INFO - Appending Batch Losses: Mask: 0.3716839551925659, Hybrid: 0.6045429706573486, Combined: 0.3926509618759155
2025-02-22 02:35:00,923 - INFO - Appending Batch Losses: Mask: 0.5421171188354492, Hybrid: 0.8129912614822388, Combined: 0.6795713901519775
2025-02-22 02:35:01,909 - INFO - Appending Batch Losses: Mask: 0.3197901248931885, Hybrid: 0.5328812003135681, Combined: 0.3841322064399719
2025-02-22 02:35:02,886 - INFO - Appending Batch Losses: Mask: 0.2905432879924774, Hybrid: 0.5183277130126953, Combined: 0.37846046686172485
2025-02-22 02:35:11,112 - INFO - Appending Batch Losses: Mask: 0.49582719802856445, Hybrid: 0.7198091745376587, Combined: 0.6663591265678406
2025-02-22 02:35:36,543 - INFO - Appending Batch Losses: Mask: 0.40067243576049805, Hybrid: 0.6723076105117798, Combined: 0.2923058271408081
2025-02-22 02:35:37,529 - INFO - Appending Batch Losses: Mask: 0.3818865716457367, Hybrid: 0.6805700063705444, Combined: 0.48509788513183594
2025-02-22 02:35:38,519 - INFO - Appending Batch Losses: Mask: 0.45711928606033325, Hybrid: 0.7303206920623779, Combined: 0.6819946765899658
2025-02-22 02:35:39,512 - INFO - Appending Batch Losses: Mask: 0.3341482877731323, Hybrid: 0.5724067687988281, Combined: 0.27128997445106506
2025-02-22 02:35:40,511 - INFO - Appending Batch Losses: Mask: 0.5025352239608765, Hybrid: 0.9859294891357422, Combined: 0.7332605123519897
2025-02-22 02:35:41,507 - INFO - Appending Batch Losses: Mask: 0.5118474960327148, Hybrid: 0.9472781419754028, Combined: 0.7643853425979614
2025-02-22 02:36:08,940 - INFO - Appending Batch Losses: Mask: 0.33542466163635254, Hybrid: 0.5297560691833496, Combined: 0.279295414686203
2025-02-22 02:36:10,161 - INFO - Appending Batch Losses: Mask: 0.42169812321662903, Hybrid: 0.6567798852920532, Combined: 0.32040107250213623
2025-02-22 02:36:11,150 - INFO - Appending Batch Losses: Mask: 0.4243774712085724, Hybrid: 0.6842527985572815, Combined: 0.5438792705535889
2025-02-22 02:36:12,136 - INFO - Appending Batch Losses: Mask: 0.4390767812728882, Hybrid: 0.7208914756774902, Combined: 0.6595968008041382
2025-02-22 02:36:13,133 - INFO - Appending Batch Losses: Mask: 0.391978919506073, Hybrid: 0.5921931266784668, Combined: 0.2746187746524811
2025-02-22 02:36:14,129 - INFO - Appending Batch Losses: Mask: 0.3609418570995331, Hybrid: 0.7502762079238892, Combined: 0.5451381206512451
2025-02-22 02:36:32,346 - INFO - Appending Batch Losses: Mask: 0.3992469012737274, Hybrid: 0.6778587102890015, Combined: 0.593622088432312
2025-02-22 02:36:33,323 - INFO - Appending Batch Losses: Mask: 0.3937518894672394, Hybrid: 0.5972999334335327, Combined: 0.42162540555000305
2025-02-22 02:36:45,042 - INFO - Appending Batch Losses: Mask: 0.3478168845176697, Hybrid: 0.8714202642440796, Combined: -0.1794646978378296
2025-02-22 02:36:46,339 - INFO - Appending Batch Losses: Mask: 0.38154304027557373, Hybrid: 0.6845647096633911, Combined: 0.37361544370651245
2025-02-22 02:36:47,179 - INFO - Appending Batch Losses: Mask: 0.5237358212471008, Hybrid: 0.7535736560821533, Combined: 0.8865267038345337
2025-02-22 02:36:48,029 - INFO - Appending Batch Losses: Mask: 0.30479249358177185, Hybrid: 0.5558169484138489, Combined: 0.3438814878463745
2025-02-22 02:37:06,282 - INFO - Appending Batch Losses: Mask: 0.4097181558609009, Hybrid: 0.6475237607955933, Combined: 0.3655053675174713
2025-02-22 02:37:07,277 - INFO - Appending Batch Losses: Mask: 0.523389995098114, Hybrid: 0.9075656533241272, Combined: 0.5509970784187317
2025-02-22 02:37:24,005 - INFO - Appending Batch Losses: Mask: 0.5458076596260071, Hybrid: 0.8499079942703247, Combined: 0.7897559404373169
2025-02-22 02:37:24,982 - INFO - Appending Batch Losses: Mask: 0.5239526629447937, Hybrid: 0.8719091415405273, Combined: 0.8215928673744202
2025-02-22 02:37:25,965 - INFO - Appending Batch Losses: Mask: 0.3851306438446045, Hybrid: 0.6224141716957092, Combined: 0.60725337266922
2025-02-22 02:37:27,181 - INFO - Appending Batch Losses: Mask: 0.5099021792411804, Hybrid: 0.7642503976821899, Combined: 0.5666303634643555
2025-02-22 02:37:28,535 - INFO - Appending Batch Losses: Mask: 0.43116292357444763, Hybrid: 0.7784669399261475, Combined: 0.6269135475158691
2025-02-22 02:37:29,384 - INFO - Appending Batch Losses: Mask: 0.4401496946811676, Hybrid: 0.8093640804290771, Combined: 0.6850774884223938
2025-02-22 02:37:42,346 - INFO - Appending Batch Losses: Mask: 0.3497281074523926, Hybrid: 0.5413141250610352, Combined: 0.7683019042015076
2025-02-22 02:37:43,320 - INFO - Appending Batch Losses: Mask: 0.4341233968734741, Hybrid: 0.6771162748336792, Combined: 0.9041168689727783
2025-02-22 02:37:44,289 - INFO - Appending Batch Losses: Mask: 0.5572672486305237, Hybrid: 0.7563740015029907, Combined: 0.9011787176132202
2025-02-22 02:37:45,266 - INFO - Appending Batch Losses: Mask: 0.3874600827693939, Hybrid: 0.5381804704666138, Combined: 0.6423388123512268
2025-02-22 02:37:47,320 - INFO - Current Learning Rate 0.0009819076099242458

2025-02-22 02:37:47,321 - INFO - 
[EPOCH 19]No improvement, NO NEW MODEL CHECKPOINT SAVED at epoch 19
 avg_epoch_loss: [0.546270]
 bestloss: [0.500370]
 Trigger: 3/12

2025-02-22 02:39:14,222 - INFO - 
Trigger times: 0, patience: 15

2025-02-22 02:39:14,222 - INFO - 
Trigger times: 0, patience: 12

2025-02-22 02:39:14,222 - INFO - 
[Epoch Improvement] Epoch 19: Loss improved during training by 6.17% from previous epoch, 

2025-02-22 02:39:14,222 - INFO - ####LOGGING AVERAGE LOSS EPOCH###
[Epoch Summary] Epoch: 19/50, Avg Combined Loss: 0.546270, MaskLoss: 0.426718, Hybridloss: 0.730746Previous Epoch loss: 0.5821727465938877
2025-02-22 02:39:14,223 - INFO - Epoch: 19 COMPLETED





2025-02-22 02:39:14,224 - INFO - [Train] Epoch 20/50 started.

2025-02-22 02:39:48,091 - INFO - #####INPUTS & TARGETS VALUE [2 BATCHES]####
Batch 1: Mixture shape=torch.Size([4, 1, 513, 946]), Target shape=torch.Size([4, 1, 513, 946])
2025-02-22 02:39:49,250 - INFO - [EPOCH 20]outputs from the model torch.Size([4, 64, 513, 946])
for batch 1
predicted mask shape torch.Size([4, 1, 513, 946])
2025-02-22 02:39:50,518 - INFO - Function: [log_first_2_batches_outputs_inputs_targets_predicted_mask]
2025-02-22 02:39:50,521 - INFO - ####OUTPUTS, INPUTS, TARGETS,PREDICTEDMASK [2 BATCHES]####
Batch 1: Mask range: min=0.0000, max=74.0625
Batch 1: Inputs shape=torch.Size([4, 1, 513, 946]), Targets shape=torch.Size([4, 1, 513, 946]), Predicted Mask shape=torch.Size([4, 1, 513, 946]), Outputs shape=torch.Size([4, 64, 513, 946])
Mask min=0.0, max=1.0
[After Mask Application] Predicted vocals min: 0.0, max: 126.0625

2025-02-22 02:39:50,521 - INFO - 
####LOSS VALUES####
[Combinedloss]:  Total treningsfeil, [BØR REDUSERES OVER TID]
[MaskLoss]: Sier hvor godt modellen lærer og predikere masken som isolerer vokaler[BØR REDUSERES OVER TID]
[l1_loss og stft_loss] gir ekstra indikasjoner på lydkvalitet.
[Hybridloss]: Kombinasjon av flere tapsfunksjoner[BØR REDUSERES OVER TID]

2025-02-22 02:39:50,533 - INFO - Appending Batch Losses: Mask: 0.4986533522605896, Hybrid: 0.7695246934890747, Combined: 0.8304182887077332
2025-02-22 02:39:51,765 - INFO - [EPOCH 20]outputs from the model torch.Size([4, 64, 513, 946])
for batch 2
predicted mask shape torch.Size([4, 1, 513, 946])
2025-02-22 02:39:52,901 - INFO - Appending Batch Losses: Mask: 0.446250319480896, Hybrid: 0.7193520665168762, Combined: 0.5490401387214661
2025-02-22 02:39:53,891 - INFO - Appending Batch Losses: Mask: 0.49654465913772583, Hybrid: 0.771903395652771, Combined: 0.8146220445632935
2025-02-22 02:39:54,881 - INFO - Appending Batch Losses: Mask: 0.3433414101600647, Hybrid: 0.520369291305542, Combined: 0.553094208240509
2025-02-22 02:40:04,474 - INFO - Appending Batch Losses: Mask: 0.40748390555381775, Hybrid: 0.6294891238212585, Combined: 0.3066610097885132
2025-02-22 02:40:05,321 - INFO - Appending Batch Losses: Mask: 0.25243762135505676, Hybrid: 0.545693039894104, Combined: 0.30148571729660034
2025-02-22 02:40:25,378 - INFO - Appending Batch Losses: Mask: 0.4226362109184265, Hybrid: 0.7368607521057129, Combined: 0.22273558378219604
2025-02-22 02:40:26,385 - INFO - Appending Batch Losses: Mask: 0.4233000576496124, Hybrid: 0.5949362516403198, Combined: 0.5434257388114929
2025-02-22 02:40:27,383 - INFO - Appending Batch Losses: Mask: 0.44148707389831543, Hybrid: 0.6926722526550293, Combined: 0.47843441367149353
2025-02-22 02:40:28,670 - INFO - Appending Batch Losses: Mask: 0.34432855248451233, Hybrid: 0.6365686655044556, Combined: 0.41869398951530457
2025-02-22 02:40:45,785 - INFO - Appending Batch Losses: Mask: 0.3416150212287903, Hybrid: 0.5738769173622131, Combined: -0.11420810222625732
2025-02-22 02:40:46,772 - INFO - Appending Batch Losses: Mask: 0.427264928817749, Hybrid: 0.6597516536712646, Combined: 0.7369207143783569
2025-02-22 02:40:54,594 - INFO - Appending Batch Losses: Mask: 0.2510855793952942, Hybrid: 0.508162260055542, Combined: 0.2814420163631439
2025-02-22 02:40:55,580 - INFO - Appending Batch Losses: Mask: 0.34851789474487305, Hybrid: 0.5882682800292969, Combined: 0.3784511089324951
2025-02-22 02:40:56,562 - INFO - Appending Batch Losses: Mask: 0.4397638440132141, Hybrid: 0.7587953805923462, Combined: 0.5730793476104736
2025-02-22 02:40:57,542 - INFO - Appending Batch Losses: Mask: 0.41069257259368896, Hybrid: 0.6261579990386963, Combined: 0.5372500419616699
2025-02-22 02:41:25,973 - INFO - Appending Batch Losses: Mask: 0.44605690240859985, Hybrid: 0.7241109609603882, Combined: 0.6738200187683105
2025-02-22 02:41:27,252 - INFO - Appending Batch Losses: Mask: 0.5259606242179871, Hybrid: 0.8319255113601685, Combined: 0.7237789034843445
2025-02-22 02:41:30,492 - INFO - Appending Batch Losses: Mask: 0.39573827385902405, Hybrid: 0.6404653787612915, Combined: 0.5751680135726929
2025-02-22 02:41:31,488 - INFO - Appending Batch Losses: Mask: 0.37914878129959106, Hybrid: 0.7600394487380981, Combined: 0.5278708338737488
2025-02-22 02:41:32,474 - INFO - Appending Batch Losses: Mask: 0.46547767519950867, Hybrid: 0.741142749786377, Combined: 0.43582606315612793
2025-02-22 02:41:33,466 - INFO - Appending Batch Losses: Mask: 0.41176992654800415, Hybrid: 0.6432492733001709, Combined: 0.35228848457336426
2025-02-22 02:42:00,381 - INFO - Appending Batch Losses: Mask: 0.5181483626365662, Hybrid: 0.7855755090713501, Combined: 0.7601341009140015
2025-02-22 02:42:01,375 - INFO - Appending Batch Losses: Mask: 0.4813928008079529, Hybrid: 0.7629652619361877, Combined: 0.40748661756515503
2025-02-22 02:42:10,431 - INFO - Appending Batch Losses: Mask: 0.4943060874938965, Hybrid: 0.8227757215499878, Combined: 0.6469863653182983
2025-02-22 02:42:11,652 - INFO - Appending Batch Losses: Mask: 0.35028478503227234, Hybrid: 0.7515474557876587, Combined: 0.272209495306015
2025-02-22 02:42:12,628 - INFO - Appending Batch Losses: Mask: 0.4675430357456207, Hybrid: 1.0061113834381104, Combined: 0.7213732004165649
2025-02-22 02:42:13,627 - INFO - Appending Batch Losses: Mask: 0.4132535457611084, Hybrid: 0.8234964609146118, Combined: 0.41144245862960815
2025-02-22 02:42:31,051 - INFO - Appending Batch Losses: Mask: 0.28025150299072266, Hybrid: 0.42655080556869507, Combined: 0.31482070684432983
2025-02-22 02:42:32,077 - INFO - Appending Batch Losses: Mask: 0.5036838054656982, Hybrid: 0.8069738149642944, Combined: 0.7367685437202454
2025-02-22 02:42:37,740 - INFO - Appending Batch Losses: Mask: 0.3664962351322174, Hybrid: 0.6124189496040344, Combined: 0.6615058183670044
2025-02-22 02:42:38,721 - INFO - Appending Batch Losses: Mask: 0.35093700885772705, Hybrid: 0.5577857494354248, Combined: 0.25714075565338135
2025-02-22 02:42:39,696 - INFO - Appending Batch Losses: Mask: 0.47824394702911377, Hybrid: 0.7490097284317017, Combined: 0.7923561334609985
2025-02-22 02:42:40,889 - INFO - Appending Batch Losses: Mask: 0.4758129417896271, Hybrid: 0.8258664608001709, Combined: 0.6337531805038452
2025-02-22 02:42:42,741 - INFO - Appending Batch Losses: Mask: 0.48870232701301575, Hybrid: 0.813858151435852, Combined: 0.5248830318450928
2025-02-22 02:42:43,705 - INFO - Appending Batch Losses: Mask: 0.27436530590057373, Hybrid: 0.49436813592910767, Combined: 0.16029095649719238
2025-02-22 02:42:51,890 - INFO - Appending Batch Losses: Mask: 0.4587538540363312, Hybrid: 0.819625735282898, Combined: 0.5869623422622681
2025-02-22 02:42:54,084 - INFO - Current Learning Rate 0.0009890616192801795

2025-02-22 02:42:54,085 - INFO - 
[EPOCH 20]No improvement, NO NEW MODEL CHECKPOINT SAVED at epoch 20
 avg_epoch_loss: [0.502390]
 bestloss: [0.500370]
 Trigger: 1/12

2025-02-22 02:44:20,810 - INFO - 
Trigger times: 1, patience: 15

2025-02-22 02:44:20,811 - INFO - 
Trigger times: 1, patience: 12

2025-02-22 02:44:20,811 - INFO - 
[Epoch Improvement] Epoch 20: Loss improved during training by 8.03% from previous epoch, 

2025-02-22 02:44:20,813 - INFO - ####LOGGING AVERAGE LOSS EPOCH###
[Epoch Summary] Epoch: 20/50, Avg Combined Loss: 0.502390, MaskLoss: 0.426087, Hybridloss: 0.728982Previous Epoch loss: 0.5462700805148563
2025-02-22 02:44:20,813 - INFO - Epoch: 20 COMPLETED





2025-02-22 02:44:20,814 - INFO - [Train] Epoch 21/50 started.

2025-02-22 02:44:55,240 - INFO - #####INPUTS & TARGETS VALUE [2 BATCHES]####
Batch 1: Mixture shape=torch.Size([4, 1, 513, 946]), Target shape=torch.Size([4, 1, 513, 946])
2025-02-22 02:44:56,025 - INFO - [EPOCH 21]outputs from the model torch.Size([4, 64, 513, 946])
for batch 1
predicted mask shape torch.Size([4, 1, 513, 946])
2025-02-22 02:44:57,296 - INFO - Function: [log_first_2_batches_outputs_inputs_targets_predicted_mask]
2025-02-22 02:44:57,299 - INFO - ####OUTPUTS, INPUTS, TARGETS,PREDICTEDMASK [2 BATCHES]####
Batch 1: Mask range: min=0.0000, max=68.3750
Batch 1: Inputs shape=torch.Size([4, 1, 513, 946]), Targets shape=torch.Size([4, 1, 513, 946]), Predicted Mask shape=torch.Size([4, 1, 513, 946]), Outputs shape=torch.Size([4, 64, 513, 946])
Mask min=0.0, max=1.0
[After Mask Application] Predicted vocals min: 0.0, max: 161.75

2025-02-22 02:44:57,299 - INFO - 
####LOSS VALUES####
[Combinedloss]:  Total treningsfeil, [BØR REDUSERES OVER TID]
[MaskLoss]: Sier hvor godt modellen lærer og predikere masken som isolerer vokaler[BØR REDUSERES OVER TID]
[l1_loss og stft_loss] gir ekstra indikasjoner på lydkvalitet.
[Hybridloss]: Kombinasjon av flere tapsfunksjoner[BØR REDUSERES OVER TID]

2025-02-22 02:44:57,313 - INFO - Appending Batch Losses: Mask: 0.3772481679916382, Hybrid: 0.6853619813919067, Combined: 0.35097789764404297
2025-02-22 02:44:58,292 - INFO - [EPOCH 21]outputs from the model torch.Size([4, 64, 513, 946])
for batch 2
predicted mask shape torch.Size([4, 1, 513, 946])
2025-02-22 02:44:59,619 - INFO - Appending Batch Losses: Mask: 0.4904460310935974, Hybrid: 0.7553664445877075, Combined: 0.5490472912788391
2025-02-22 02:45:20,139 - INFO - Appending Batch Losses: Mask: 0.44086992740631104, Hybrid: 0.6577524542808533, Combined: 0.6632170677185059
2025-02-22 02:45:21,136 - INFO - Appending Batch Losses: Mask: 0.43159401416778564, Hybrid: 0.9206534624099731, Combined: 0.5782207250595093
2025-02-22 02:45:22,370 - INFO - Appending Batch Losses: Mask: 0.40458545088768005, Hybrid: 0.7208842039108276, Combined: 0.4521491229534149
2025-02-22 02:45:23,341 - INFO - Appending Batch Losses: Mask: 0.41786888241767883, Hybrid: 0.6122810244560242, Combined: 0.6532008051872253
2025-02-22 02:45:34,003 - INFO - Appending Batch Losses: Mask: 0.41446569561958313, Hybrid: 0.7793112397193909, Combined: 0.5522155165672302
2025-02-22 02:45:35,006 - INFO - Appending Batch Losses: Mask: 0.41015422344207764, Hybrid: 0.6400682926177979, Combined: 0.48103201389312744
2025-02-22 02:45:58,367 - INFO - Appending Batch Losses: Mask: 0.4125659465789795, Hybrid: 0.8620477914810181, Combined: 0.4427994191646576
2025-02-22 02:45:59,217 - INFO - Appending Batch Losses: Mask: 0.38975656032562256, Hybrid: 0.7145071029663086, Combined: 0.5820126533508301
2025-02-22 02:46:00,215 - INFO - Appending Batch Losses: Mask: 0.46127447485923767, Hybrid: 0.7912358045578003, Combined: 0.6038168668746948
2025-02-22 02:46:01,213 - INFO - Appending Batch Losses: Mask: 0.39883142709732056, Hybrid: 0.5859594345092773, Combined: 0.6317857503890991
2025-02-22 02:46:02,447 - INFO - Appending Batch Losses: Mask: 0.45609745383262634, Hybrid: 0.8131728172302246, Combined: 0.6680189371109009
2025-02-22 02:46:03,435 - INFO - Appending Batch Losses: Mask: 0.40899765491485596, Hybrid: 0.6814792156219482, Combined: 0.2013804018497467
2025-02-22 02:46:16,953 - INFO - Appending Batch Losses: Mask: 0.4980311095714569, Hybrid: 0.7576029300689697, Combined: 0.7547156810760498
2025-02-22 02:46:17,969 - INFO - Appending Batch Losses: Mask: 0.4106569290161133, Hybrid: 0.7166367769241333, Combined: 0.35663822293281555
2025-02-22 02:46:18,963 - INFO - Appending Batch Losses: Mask: 0.6523438692092896, Hybrid: 1.0831836462020874, Combined: 0.9015517234802246
2025-02-22 02:46:19,962 - INFO - Appending Batch Losses: Mask: 0.26895999908447266, Hybrid: 0.5809043645858765, Combined: 0.5326760411262512
2025-02-22 02:46:20,947 - INFO - Appending Batch Losses: Mask: 0.37482887506484985, Hybrid: 0.6535779237747192, Combined: 0.4497194290161133
2025-02-22 02:46:21,943 - INFO - Appending Batch Losses: Mask: 0.31561633944511414, Hybrid: 0.6613585948944092, Combined: 0.26526349782943726
2025-02-22 02:46:43,059 - INFO - Appending Batch Losses: Mask: 0.5296227931976318, Hybrid: 0.8493606448173523, Combined: 0.6216585636138916
2025-02-22 02:46:43,903 - INFO - Appending Batch Losses: Mask: 0.4488118886947632, Hybrid: 0.6961499452590942, Combined: 0.6797024011611938
2025-02-22 02:46:44,777 - INFO - Appending Batch Losses: Mask: 0.3749207556247711, Hybrid: 0.5792500376701355, Combined: 0.7584294676780701
2025-02-22 02:46:45,758 - INFO - Appending Batch Losses: Mask: 0.550225019454956, Hybrid: 0.7818924188613892, Combined: 0.4476390779018402
2025-02-22 02:46:46,627 - INFO - Appending Batch Losses: Mask: 0.597821831703186, Hybrid: 0.9121818542480469, Combined: 0.7243955135345459
2025-02-22 02:46:47,495 - INFO - Appending Batch Losses: Mask: 0.38865426182746887, Hybrid: 0.666790246963501, Combined: 0.4541615843772888
2025-02-22 02:47:02,889 - INFO - Appending Batch Losses: Mask: 0.32539820671081543, Hybrid: 0.5633588433265686, Combined: 0.18496766686439514
2025-02-22 02:47:10,678 - INFO - Appending Batch Losses: Mask: 0.43169277906417847, Hybrid: 0.7414928674697876, Combined: 0.3403392434120178
2025-02-22 02:47:11,926 - INFO - Appending Batch Losses: Mask: 0.5134048461914062, Hybrid: 0.9047857522964478, Combined: 0.7602821588516235
2025-02-22 02:47:22,559 - INFO - Appending Batch Losses: Mask: 0.403669536113739, Hybrid: 0.5728818774223328, Combined: 0.47329720854759216
2025-02-22 02:47:23,560 - INFO - Appending Batch Losses: Mask: 0.4755006432533264, Hybrid: 0.7118239402770996, Combined: 0.5931801795959473
2025-02-22 02:47:24,410 - INFO - Appending Batch Losses: Mask: 0.38575664162635803, Hybrid: 0.6305339336395264, Combined: 0.30096161365509033
2025-02-22 02:47:34,938 - INFO - Appending Batch Losses: Mask: 0.3615785837173462, Hybrid: 0.6202231049537659, Combined: 0.6440039873123169
2025-02-22 02:47:35,912 - INFO - Appending Batch Losses: Mask: 0.37872955203056335, Hybrid: 0.6389743089675903, Combined: 0.27940136194229126
2025-02-22 02:47:36,902 - INFO - Appending Batch Losses: Mask: 0.5684962868690491, Hybrid: 0.8556003570556641, Combined: 0.7693625092506409
2025-02-22 02:47:56,581 - INFO - Appending Batch Losses: Mask: 0.4412984549999237, Hybrid: 0.6544020771980286, Combined: 0.6443127989768982
2025-02-22 02:47:57,763 - INFO - Appending Batch Losses: Mask: 0.434624046087265, Hybrid: 0.6302898526191711, Combined: 0.6684403419494629
2025-02-22 02:48:00,001 - INFO - Current Learning Rate 0.0009959680347637109

2025-02-22 02:48:00,001 - INFO - 
[EPOCH 21]No improvement, NO NEW MODEL CHECKPOINT SAVED at epoch 21
 avg_epoch_loss: [0.540945]
 bestloss: [0.500370]
 Trigger: 2/12

2025-02-22 02:49:25,790 - INFO - 
Trigger times: 2, patience: 15

2025-02-22 02:49:25,791 - INFO - 
Trigger times: 2, patience: 12

2025-02-22 02:49:25,791 - INFO - 
[Epoch Improvement] Epoch 21: Loss improved during training by -7.67% from previous epoch, 

2025-02-22 02:49:25,791 - INFO - ####LOGGING AVERAGE LOSS EPOCH###
[Epoch Summary] Epoch: 21/50, Avg Combined Loss: 0.540945, MaskLoss: 0.426447, Hybridloss: 0.728610Previous Epoch loss: 0.5023895212121912
2025-02-22 02:49:25,792 - INFO - Epoch: 21 COMPLETED





2025-02-22 02:49:25,793 - INFO - [Train] Epoch 22/50 started.

2025-02-22 02:50:09,895 - INFO - #####INPUTS & TARGETS VALUE [2 BATCHES]####
Batch 1: Mixture shape=torch.Size([4, 1, 513, 946]), Target shape=torch.Size([4, 1, 513, 946])
2025-02-22 02:50:10,722 - INFO - [EPOCH 22]outputs from the model torch.Size([4, 64, 513, 946])
for batch 1
predicted mask shape torch.Size([4, 1, 513, 946])
2025-02-22 02:50:11,874 - INFO - Function: [log_first_2_batches_outputs_inputs_targets_predicted_mask]
2025-02-22 02:50:11,877 - INFO - ####OUTPUTS, INPUTS, TARGETS,PREDICTEDMASK [2 BATCHES]####
Batch 1: Mask range: min=0.0000, max=72.7500
Batch 1: Inputs shape=torch.Size([4, 1, 513, 946]), Targets shape=torch.Size([4, 1, 513, 946]), Predicted Mask shape=torch.Size([4, 1, 513, 946]), Outputs shape=torch.Size([4, 64, 513, 946])
Mask min=0.0, max=1.0
[After Mask Application] Predicted vocals min: 0.0, max: 155.125

2025-02-22 02:50:11,877 - INFO - 
####LOSS VALUES####
[Combinedloss]:  Total treningsfeil, [BØR REDUSERES OVER TID]
[MaskLoss]: Sier hvor godt modellen lærer og predikere masken som isolerer vokaler[BØR REDUSERES OVER TID]
[l1_loss og stft_loss] gir ekstra indikasjoner på lydkvalitet.
[Hybridloss]: Kombinasjon av flere tapsfunksjoner[BØR REDUSERES OVER TID]

2025-02-22 02:50:11,890 - INFO - Appending Batch Losses: Mask: 0.3153931200504303, Hybrid: 0.7800225019454956, Combined: 0.354238361120224
2025-02-22 02:50:12,879 - INFO - [EPOCH 22]outputs from the model torch.Size([4, 64, 513, 946])
for batch 2
predicted mask shape torch.Size([4, 1, 513, 946])
2025-02-22 02:50:14,060 - INFO - Appending Batch Losses: Mask: 0.578888475894928, Hybrid: 0.7412828207015991, Combined: 0.884051501750946
2025-02-22 02:50:14,917 - INFO - Appending Batch Losses: Mask: 0.5373249650001526, Hybrid: 0.9762527942657471, Combined: 0.5850298404693604
2025-02-22 02:50:15,782 - INFO - Appending Batch Losses: Mask: 0.49523407220840454, Hybrid: 0.7538814544677734, Combined: 0.9499248266220093
2025-02-22 02:50:16,782 - INFO - Appending Batch Losses: Mask: 0.27896848320961, Hybrid: 0.5482882857322693, Combined: 0.2806445360183716
2025-02-22 02:50:17,687 - INFO - Appending Batch Losses: Mask: 0.4529251456260681, Hybrid: 1.0241014957427979, Combined: 0.7194492816925049
2025-02-22 02:50:45,667 - INFO - Appending Batch Losses: Mask: 0.5321131348609924, Hybrid: 0.8197605013847351, Combined: 0.6422895789146423
2025-02-22 02:50:46,970 - INFO - Appending Batch Losses: Mask: 0.3812411427497864, Hybrid: 0.714153528213501, Combined: 0.5804887413978577
2025-02-22 02:50:47,969 - INFO - Appending Batch Losses: Mask: 0.45051416754722595, Hybrid: 0.6397786140441895, Combined: 0.8318675756454468
2025-02-22 02:50:48,955 - INFO - Appending Batch Losses: Mask: 0.6157476305961609, Hybrid: 1.2094976902008057, Combined: 1.0806918144226074
2025-02-22 02:50:49,958 - INFO - Appending Batch Losses: Mask: 0.44170671701431274, Hybrid: 0.8544832468032837, Combined: 0.5488319396972656
2025-02-22 02:50:50,952 - INFO - Appending Batch Losses: Mask: 0.41039717197418213, Hybrid: 0.7837202548980713, Combined: 0.1158100962638855
2025-02-22 02:51:22,770 - INFO - Appending Batch Losses: Mask: 0.35253167152404785, Hybrid: 0.7053608894348145, Combined: 0.21167555451393127
2025-02-22 02:51:23,763 - INFO - Appending Batch Losses: Mask: 0.4455753266811371, Hybrid: 0.6868781447410583, Combined: 0.5393366813659668
2025-02-22 02:51:24,764 - INFO - Appending Batch Losses: Mask: 0.38872337341308594, Hybrid: 0.6591390371322632, Combined: 0.45772784948349
2025-02-22 02:51:25,980 - INFO - Appending Batch Losses: Mask: 0.45030269026756287, Hybrid: 0.7033668756484985, Combined: 0.6021928787231445
2025-02-22 02:51:26,948 - INFO - Appending Batch Losses: Mask: 0.4361847937107086, Hybrid: 0.8118190765380859, Combined: 0.46513885259628296
2025-02-22 02:51:27,918 - INFO - Appending Batch Losses: Mask: 0.5203402042388916, Hybrid: 0.7640117406845093, Combined: 0.6086769104003906
2025-02-22 02:51:56,719 - INFO - Appending Batch Losses: Mask: 0.4751615524291992, Hybrid: 0.7124435901641846, Combined: 0.7301827073097229
2025-02-22 02:51:57,681 - INFO - Appending Batch Losses: Mask: 0.39294493198394775, Hybrid: 0.6343691349029541, Combined: 0.38358739018440247
2025-02-22 02:51:58,652 - INFO - Appending Batch Losses: Mask: 0.5135395526885986, Hybrid: 0.7476263046264648, Combined: 0.7194162011146545
2025-02-22 02:51:59,628 - INFO - Appending Batch Losses: Mask: 0.45155811309814453, Hybrid: 0.7375880479812622, Combined: 0.5658873915672302
2025-02-22 02:52:00,612 - INFO - Appending Batch Losses: Mask: 0.44711729884147644, Hybrid: 0.7180060148239136, Combined: 0.5242538452148438
2025-02-22 02:52:01,710 - INFO - Appending Batch Losses: Mask: 0.5092567801475525, Hybrid: 0.770461916923523, Combined: 0.45245641469955444
2025-02-22 02:52:21,554 - INFO - Appending Batch Losses: Mask: 0.4831748604774475, Hybrid: 0.7698187828063965, Combined: 0.3423817455768585
2025-02-22 02:52:27,955 - INFO - Appending Batch Losses: Mask: 0.3359908163547516, Hybrid: 0.758551299571991, Combined: 0.2254181206226349
2025-02-22 02:52:28,940 - INFO - Appending Batch Losses: Mask: 0.49659013748168945, Hybrid: 0.7210090160369873, Combined: 0.6100909113883972
2025-02-22 02:52:29,927 - INFO - Appending Batch Losses: Mask: 0.4178442060947418, Hybrid: 0.6834450960159302, Combined: 0.6274908185005188
2025-02-22 02:52:30,770 - INFO - Appending Batch Losses: Mask: 0.3336641192436218, Hybrid: 0.4866894781589508, Combined: 0.9430025219917297
2025-02-22 02:52:31,632 - INFO - Appending Batch Losses: Mask: 0.4427040219306946, Hybrid: 0.7658079862594604, Combined: 0.48204973340034485
2025-02-22 02:52:43,014 - INFO - Appending Batch Losses: Mask: 0.5099013447761536, Hybrid: 0.7862603068351746, Combined: 0.6433186531066895
2025-02-22 02:52:47,767 - INFO - Appending Batch Losses: Mask: 0.5368750691413879, Hybrid: 0.8426823616027832, Combined: 0.6827248930931091
2025-02-22 02:52:48,731 - INFO - Appending Batch Losses: Mask: 0.3186486065387726, Hybrid: 0.5093033313751221, Combined: 0.4659517705440521
2025-02-22 02:52:49,709 - INFO - Appending Batch Losses: Mask: 0.4362145662307739, Hybrid: 0.8466143012046814, Combined: 0.7210358381271362
2025-02-22 02:52:50,696 - INFO - Appending Batch Losses: Mask: 0.41791680455207825, Hybrid: 0.6935685276985168, Combined: 0.4695565402507782
2025-02-22 02:52:51,675 - INFO - Appending Batch Losses: Mask: 0.37304314970970154, Hybrid: 0.6050909161567688, Combined: -0.110462486743927
2025-02-22 02:53:00,716 - INFO - Appending Batch Losses: Mask: 0.47787052392959595, Hybrid: 0.9416365027427673, Combined: 0.5683239698410034
2025-02-22 02:53:02,744 - INFO - Current Learning Rate 0.001

2025-02-22 02:53:02,745 - INFO - 
[EPOCH 22]No improvement, NO NEW MODEL CHECKPOINT SAVED at epoch 22
 avg_epoch_loss: [0.554182]
 bestloss: [0.500370]
 Trigger: 3/12

2025-02-22 02:54:29,941 - INFO - 
Trigger times: 3, patience: 15

2025-02-22 02:54:29,942 - INFO - 
Trigger times: 3, patience: 12

2025-02-22 02:54:29,942 - INFO - 
[Epoch Improvement] Epoch 22: Loss improved during training by -2.45% from previous epoch, 

2025-02-22 02:54:29,942 - INFO - ####LOGGING AVERAGE LOSS EPOCH###
[Epoch Summary] Epoch: 22/50, Avg Combined Loss: 0.554182, MaskLoss: 0.427277, Hybridloss: 0.729775Previous Epoch loss: 0.540945263327779
2025-02-22 02:54:29,943 - INFO - Epoch: 22 COMPLETED





2025-02-22 02:54:29,943 - INFO - [Train] Epoch 23/50 started.

2025-02-22 02:55:09,012 - INFO - #####INPUTS & TARGETS VALUE [2 BATCHES]####
Batch 1: Mixture shape=torch.Size([3, 1, 513, 946]), Target shape=torch.Size([3, 1, 513, 946])
2025-02-22 02:55:09,797 - INFO - [EPOCH 23]outputs from the model torch.Size([3, 64, 513, 946])
for batch 1
predicted mask shape torch.Size([3, 1, 513, 946])
2025-02-22 02:55:11,042 - INFO - Function: [log_first_2_batches_outputs_inputs_targets_predicted_mask]
2025-02-22 02:55:11,045 - INFO - ####OUTPUTS, INPUTS, TARGETS,PREDICTEDMASK [2 BATCHES]####
Batch 1: Mask range: min=0.0000, max=52.5000
Batch 1: Inputs shape=torch.Size([3, 1, 513, 946]), Targets shape=torch.Size([3, 1, 513, 946]), Predicted Mask shape=torch.Size([3, 1, 513, 946]), Outputs shape=torch.Size([3, 64, 513, 946])
Mask min=0.0, max=1.0
[After Mask Application] Predicted vocals min: 0.0, max: 94.375

2025-02-22 02:55:11,046 - INFO - 
####LOSS VALUES####
[Combinedloss]:  Total treningsfeil, [BØR REDUSERES OVER TID]
[MaskLoss]: Sier hvor godt modellen lærer og predikere masken som isolerer vokaler[BØR REDUSERES OVER TID]
[l1_loss og stft_loss] gir ekstra indikasjoner på lydkvalitet.
[Hybridloss]: Kombinasjon av flere tapsfunksjoner[BØR REDUSERES OVER TID]

2025-02-22 02:55:11,062 - INFO - Appending Batch Losses: Mask: 0.38375744223594666, Hybrid: 0.5779141187667847, Combined: 0.537483274936676
2025-02-22 02:55:12,163 - INFO - [EPOCH 23]outputs from the model torch.Size([4, 64, 513, 946])
for batch 2
predicted mask shape torch.Size([4, 1, 513, 946])
2025-02-22 02:55:13,524 - INFO - Appending Batch Losses: Mask: 0.4870954155921936, Hybrid: 0.7112499475479126, Combined: 0.6281774640083313
2025-02-22 02:55:14,816 - INFO - Appending Batch Losses: Mask: 0.476728230714798, Hybrid: 0.7484484314918518, Combined: 0.7234084010124207
2025-02-22 02:55:15,791 - INFO - Appending Batch Losses: Mask: 0.28894901275634766, Hybrid: 0.5115976333618164, Combined: 0.30883678793907166
2025-02-22 02:55:16,797 - INFO - Appending Batch Losses: Mask: 0.5051532983779907, Hybrid: 0.8257781267166138, Combined: 0.6800498962402344
2025-02-22 02:55:17,782 - INFO - Appending Batch Losses: Mask: 0.42513221502304077, Hybrid: 0.7086228132247925, Combined: 0.2114575207233429
2025-02-22 02:55:32,549 - INFO - Appending Batch Losses: Mask: 0.4028593897819519, Hybrid: 0.635025143623352, Combined: 0.6552345752716064
2025-02-22 02:55:39,443 - INFO - Appending Batch Losses: Mask: 0.469505250453949, Hybrid: 1.0124560594558716, Combined: 0.5526589155197144
2025-02-22 02:55:40,424 - INFO - Appending Batch Losses: Mask: 0.5212947726249695, Hybrid: 0.8135266900062561, Combined: 0.5911860466003418
2025-02-22 02:55:46,984 - INFO - Appending Batch Losses: Mask: 0.2755162715911865, Hybrid: 0.5282436609268188, Combined: 0.6396545171737671
2025-02-22 02:55:48,208 - INFO - Appending Batch Losses: Mask: 0.4650854170322418, Hybrid: 0.7186603546142578, Combined: 0.5607599020004272
2025-02-22 02:55:49,182 - INFO - Appending Batch Losses: Mask: 0.3985716700553894, Hybrid: 0.7891287803649902, Combined: 0.4076644778251648
2025-02-22 02:55:59,472 - INFO - Appending Batch Losses: Mask: 0.3803764581680298, Hybrid: 0.6337306499481201, Combined: 0.31766581535339355
2025-02-22 02:56:08,051 - INFO - Appending Batch Losses: Mask: 0.3168056607246399, Hybrid: 0.6115243434906006, Combined: -0.05122441053390503
2025-02-22 02:56:15,356 - INFO - Appending Batch Losses: Mask: 0.49808529019355774, Hybrid: 0.790945291519165, Combined: 0.8031473755836487
2025-02-22 02:56:16,334 - INFO - Appending Batch Losses: Mask: 0.386001855134964, Hybrid: 0.6119648218154907, Combined: 0.4440152049064636
2025-02-22 02:56:24,350 - INFO - Appending Batch Losses: Mask: 0.4641087055206299, Hybrid: 0.7373683452606201, Combined: 0.4596249759197235
2025-02-22 02:56:25,332 - INFO - Appending Batch Losses: Mask: 0.4134851098060608, Hybrid: 0.6934316754341125, Combined: 0.4938768148422241
2025-02-22 02:56:40,955 - INFO - Appending Batch Losses: Mask: 0.47053608298301697, Hybrid: 0.7685766220092773, Combined: 0.4696788787841797
2025-02-22 02:56:41,932 - INFO - Appending Batch Losses: Mask: 0.3395853638648987, Hybrid: 0.8448845148086548, Combined: -0.05341804027557373
2025-02-22 02:56:51,414 - INFO - Appending Batch Losses: Mask: 0.3585572838783264, Hybrid: 0.720764696598053, Combined: 0.39665716886520386
2025-02-22 02:56:52,395 - INFO - Appending Batch Losses: Mask: 0.48681992292404175, Hybrid: 0.669662594795227, Combined: 0.5876798629760742
2025-02-22 02:56:55,714 - INFO - Appending Batch Losses: Mask: 0.5433228015899658, Hybrid: 0.7890241146087646, Combined: 0.7822387218475342
2025-02-22 02:56:56,696 - INFO - Appending Batch Losses: Mask: 0.41556018590927124, Hybrid: 0.679021418094635, Combined: 0.5442665219306946
2025-02-22 02:57:17,641 - INFO - Appending Batch Losses: Mask: 0.3202819526195526, Hybrid: 0.6121551394462585, Combined: 0.1437021791934967
2025-02-22 02:57:18,621 - INFO - Appending Batch Losses: Mask: 0.3639445900917053, Hybrid: 0.6348605155944824, Combined: 0.39101845026016235
2025-02-22 02:57:19,882 - INFO - Appending Batch Losses: Mask: 0.5354426503181458, Hybrid: 0.9054293632507324, Combined: 0.615288496017456
2025-02-22 02:57:20,851 - INFO - Appending Batch Losses: Mask: 0.34720274806022644, Hybrid: 0.7109766006469727, Combined: 0.3529188632965088
2025-02-22 02:57:31,990 - INFO - Appending Batch Losses: Mask: 0.3559052348136902, Hybrid: 0.6655827760696411, Combined: 0.04394644498825073
2025-02-22 02:57:32,975 - INFO - Appending Batch Losses: Mask: 0.48435306549072266, Hybrid: 0.8181184530258179, Combined: 0.8791840076446533
2025-02-22 02:57:49,544 - INFO - Appending Batch Losses: Mask: 0.4088520407676697, Hybrid: 0.7375756502151489, Combined: 0.6833810210227966
2025-02-22 02:57:50,370 - INFO - Appending Batch Losses: Mask: 0.4789472222328186, Hybrid: 0.7050988674163818, Combined: 0.4918861985206604
2025-02-22 02:57:51,203 - INFO - Appending Batch Losses: Mask: 0.46271389722824097, Hybrid: 0.7055685520172119, Combined: 0.43612170219421387
2025-02-22 02:57:52,190 - INFO - Appending Batch Losses: Mask: 0.37603822350502014, Hybrid: 0.6407138109207153, Combined: 0.18986722826957703
2025-02-22 02:57:53,409 - INFO - Appending Batch Losses: Mask: 0.5185744166374207, Hybrid: 0.8670382499694824, Combined: 0.5338406562805176
2025-02-22 02:57:54,365 - INFO - Appending Batch Losses: Mask: 0.45117488503456116, Hybrid: 0.7167224884033203, Combined: 0.6222363710403442
2025-02-22 02:58:09,235 - INFO - Appending Batch Losses: Mask: 0.43545863032341003, Hybrid: 0.8000291585922241, Combined: 0.5076128840446472
2025-02-22 02:58:11,437 - INFO - Current Learning Rate 0.0009989690721649484

2025-02-22 02:58:12,579 - INFO - Checkpoint saved: /mnt/c/Users/didri/Desktop/Programmering/ArtificalintelligenceModels/UNet-Model_Vocal_Isolation/Unet_model_Audio_Seperation/Model_Weights/CheckPoints/Training/checkpoint_epoch_22.pth
2025-02-22 02:58:12,579 - INFO - 
 [EPOCH 23]Model Checkpoint SAVED at epoch 23
 avg_epoch_loss: [0.475183]
 bestloss: [0.475183]
 Trigger times: 0/12

2025-02-22 02:59:42,465 - INFO - 
Trigger times: 4, patience: 15

2025-02-22 02:59:42,465 - INFO - 
Trigger times: 4, patience: 12

2025-02-22 02:59:42,466 - INFO - 
[Epoch Improvement] Epoch 23: Loss improved during training by 14.25% from previous epoch, 

2025-02-22 02:59:42,466 - INFO - ####LOGGING AVERAGE LOSS EPOCH###
[Epoch Summary] Epoch: 23/50, Avg Combined Loss: 0.475183, MaskLoss: 0.427163, Hybridloss: 0.729364Previous Epoch loss: 0.5541819946185963
2025-02-22 02:59:42,467 - INFO - Epoch: 23 COMPLETED





2025-02-22 02:59:42,467 - INFO - [Train] Epoch 24/50 started.

2025-02-22 03:00:11,330 - INFO - #####INPUTS & TARGETS VALUE [2 BATCHES]####
Batch 1: Mixture shape=torch.Size([4, 1, 513, 946]), Target shape=torch.Size([4, 1, 513, 946])
2025-02-22 03:00:12,152 - INFO - [EPOCH 24]outputs from the model torch.Size([4, 64, 513, 946])
for batch 1
predicted mask shape torch.Size([4, 1, 513, 946])
2025-02-22 03:00:13,287 - INFO - Function: [log_first_2_batches_outputs_inputs_targets_predicted_mask]
2025-02-22 03:00:13,289 - INFO - ####OUTPUTS, INPUTS, TARGETS,PREDICTEDMASK [2 BATCHES]####
Batch 1: Mask range: min=0.0000, max=88.5000
Batch 1: Inputs shape=torch.Size([4, 1, 513, 946]), Targets shape=torch.Size([4, 1, 513, 946]), Predicted Mask shape=torch.Size([4, 1, 513, 946]), Outputs shape=torch.Size([4, 64, 513, 946])
Mask min=0.0, max=1.0
[After Mask Application] Predicted vocals min: 0.0, max: 171.25

2025-02-22 03:00:13,289 - INFO - 
####LOSS VALUES####
[Combinedloss]:  Total treningsfeil, [BØR REDUSERES OVER TID]
[MaskLoss]: Sier hvor godt modellen lærer og predikere masken som isolerer vokaler[BØR REDUSERES OVER TID]
[l1_loss og stft_loss] gir ekstra indikasjoner på lydkvalitet.
[Hybridloss]: Kombinasjon av flere tapsfunksjoner[BØR REDUSERES OVER TID]

2025-02-22 03:00:13,301 - INFO - Appending Batch Losses: Mask: 0.47055765986442566, Hybrid: 0.7500820159912109, Combined: 0.5374304056167603
2025-02-22 03:00:17,826 - INFO - [EPOCH 24]outputs from the model torch.Size([4, 64, 513, 946])
for batch 2
predicted mask shape torch.Size([4, 1, 513, 946])
2025-02-22 03:00:18,901 - INFO - Appending Batch Losses: Mask: 0.4388751983642578, Hybrid: 0.5922726392745972, Combined: 0.56239914894104
2025-02-22 03:00:19,892 - INFO - Appending Batch Losses: Mask: 0.4638766348361969, Hybrid: 0.7632284164428711, Combined: 0.42878371477127075
2025-02-22 03:00:29,549 - INFO - Appending Batch Losses: Mask: 0.4216494858264923, Hybrid: 0.7718633413314819, Combined: 0.32188624143600464
2025-02-22 03:00:30,409 - INFO - Appending Batch Losses: Mask: 0.29653286933898926, Hybrid: 0.7002238035202026, Combined: 0.10017222166061401
2025-02-22 03:00:31,626 - INFO - Appending Batch Losses: Mask: 0.40652450919151306, Hybrid: 0.6830552220344543, Combined: 0.41626372933387756
2025-02-22 03:00:55,444 - INFO - Appending Batch Losses: Mask: 0.4167775511741638, Hybrid: 0.6399043798446655, Combined: 0.55702805519104
2025-02-22 03:00:56,437 - INFO - Appending Batch Losses: Mask: 0.30904069542884827, Hybrid: 0.6140763759613037, Combined: 0.3943687081336975
2025-02-22 03:00:57,442 - INFO - Appending Batch Losses: Mask: 0.33462414145469666, Hybrid: 0.7375880479812622, Combined: 0.0659339427947998
2025-02-22 03:00:58,436 - INFO - Appending Batch Losses: Mask: 0.40664395689964294, Hybrid: 0.6988476514816284, Combined: 0.5684632658958435
2025-02-22 03:00:59,437 - INFO - Appending Batch Losses: Mask: 0.4310540556907654, Hybrid: 0.6864307522773743, Combined: 0.3881591260433197
2025-02-22 03:01:00,450 - INFO - Appending Batch Losses: Mask: 0.4027407467365265, Hybrid: 0.8138366937637329, Combined: 0.6679279208183289
2025-02-22 03:01:27,093 - INFO - Appending Batch Losses: Mask: 0.5346631407737732, Hybrid: 0.8133697509765625, Combined: 0.48291608691215515
2025-02-22 03:01:36,424 - INFO - Appending Batch Losses: Mask: 0.31206566095352173, Hybrid: 0.48696884512901306, Combined: 0.3299097418785095
2025-02-22 03:01:37,410 - INFO - Appending Batch Losses: Mask: 0.4823393225669861, Hybrid: 0.6902897357940674, Combined: 0.483278751373291
2025-02-22 03:01:38,429 - INFO - Appending Batch Losses: Mask: 0.33137744665145874, Hybrid: 0.6177535653114319, Combined: 0.3513250946998596
2025-02-22 03:01:39,415 - INFO - Appending Batch Losses: Mask: 0.4873028099536896, Hybrid: 0.7895238399505615, Combined: 0.5568065643310547
2025-02-22 03:01:40,416 - INFO - Appending Batch Losses: Mask: 0.3935704827308655, Hybrid: 0.7095751762390137, Combined: 0.4504343569278717
2025-02-22 03:01:52,760 - INFO - Appending Batch Losses: Mask: 0.49460604786872864, Hybrid: 0.7266931533813477, Combined: 0.7657360434532166
2025-02-22 03:01:55,750 - INFO - Appending Batch Losses: Mask: 0.48043665289878845, Hybrid: 0.7552286386489868, Combined: 0.7246682643890381
2025-02-22 03:02:06,834 - INFO - Appending Batch Losses: Mask: 0.47451743483543396, Hybrid: 0.8266063928604126, Combined: 0.4427031874656677
2025-02-22 03:02:08,025 - INFO - Appending Batch Losses: Mask: 0.4714629650115967, Hybrid: 0.8610398173332214, Combined: 0.34455788135528564
2025-02-22 03:02:08,999 - INFO - Appending Batch Losses: Mask: 0.38803988695144653, Hybrid: 0.6282621622085571, Combined: 0.5096561908721924
2025-02-22 03:02:09,980 - INFO - Appending Batch Losses: Mask: 0.34748947620391846, Hybrid: 0.6154317855834961, Combined: 0.13274672627449036
2025-02-22 03:02:27,348 - INFO - Appending Batch Losses: Mask: 0.48908835649490356, Hybrid: 0.8084216117858887, Combined: 0.8681336641311646
2025-02-22 03:02:28,335 - INFO - Appending Batch Losses: Mask: 0.39961668848991394, Hybrid: 0.6450967788696289, Combined: 0.3073500990867615
2025-02-22 03:02:33,572 - INFO - Appending Batch Losses: Mask: 0.5223245620727539, Hybrid: 0.8146274089813232, Combined: 0.7602184414863586
2025-02-22 03:02:34,552 - INFO - Appending Batch Losses: Mask: 0.4470651149749756, Hybrid: 0.9081786870956421, Combined: 0.8287841081619263
2025-02-22 03:02:35,541 - INFO - Appending Batch Losses: Mask: 0.5026369094848633, Hybrid: 0.855488657951355, Combined: 0.6866886615753174
2025-02-22 03:02:36,798 - INFO - Appending Batch Losses: Mask: 0.31062689423561096, Hybrid: 0.5205195546150208, Combined: 0.5732964277267456
2025-02-22 03:02:50,770 - INFO - Appending Batch Losses: Mask: 0.49284446239471436, Hybrid: 0.795583963394165, Combined: 0.6950438618659973
2025-02-22 03:02:58,407 - INFO - Appending Batch Losses: Mask: 0.5366225838661194, Hybrid: 0.8046575784683228, Combined: 0.5720801949501038
2025-02-22 03:03:02,129 - INFO - Appending Batch Losses: Mask: 0.329872727394104, Hybrid: 0.6850345134735107, Combined: 0.30427029728889465
2025-02-22 03:03:03,113 - INFO - Appending Batch Losses: Mask: 0.49017590284347534, Hybrid: 0.8033795356750488, Combined: 0.46568918228149414
2025-02-22 03:03:04,093 - INFO - Appending Batch Losses: Mask: 0.49910300970077515, Hybrid: 0.8161479830741882, Combined: 0.4928789436817169
2025-02-22 03:03:05,068 - INFO - Appending Batch Losses: Mask: 0.45081737637519836, Hybrid: 0.7468664646148682, Combined: 0.24787861108779907
2025-02-22 03:03:10,931 - INFO - Appending Batch Losses: Mask: 0.3602115213871002, Hybrid: 0.5475779175758362, Combined: 0.4762192368507385
2025-02-22 03:03:13,405 - INFO - Current Learning Rate 0.0009979381443298969

2025-02-22 03:03:13,405 - INFO - 
[EPOCH 24]No improvement, NO NEW MODEL CHECKPOINT SAVED at epoch 24
 avg_epoch_loss: [0.482759]
 bestloss: [0.475183]
 Trigger: 5/12

2025-02-22 03:04:37,538 - INFO - 
Trigger times: 5, patience: 15

2025-02-22 03:04:37,539 - INFO - 
Trigger times: 5, patience: 12

2025-02-22 03:04:37,539 - INFO - 
[Epoch Improvement] Epoch 24: Loss improved during training by -1.59% from previous epoch, 

2025-02-22 03:04:37,539 - INFO - ####LOGGING AVERAGE LOSS EPOCH###
[Epoch Summary] Epoch: 24/50, Avg Combined Loss: 0.482759, MaskLoss: 0.427188, Hybridloss: 0.729068Previous Epoch loss: 0.4751833830330823
2025-02-22 03:04:37,540 - INFO - Epoch: 24 COMPLETED





2025-02-22 03:04:37,541 - INFO - [Train] Epoch 25/50 started.

2025-02-22 03:05:17,890 - INFO - #####INPUTS & TARGETS VALUE [2 BATCHES]####
Batch 1: Mixture shape=torch.Size([4, 1, 513, 946]), Target shape=torch.Size([4, 1, 513, 946])
2025-02-22 03:05:18,732 - INFO - [EPOCH 25]outputs from the model torch.Size([4, 64, 513, 946])
for batch 1
predicted mask shape torch.Size([4, 1, 513, 946])
2025-02-22 03:05:19,886 - INFO - Function: [log_first_2_batches_outputs_inputs_targets_predicted_mask]
2025-02-22 03:05:19,889 - INFO - ####OUTPUTS, INPUTS, TARGETS,PREDICTEDMASK [2 BATCHES]####
Batch 1: Mask range: min=0.0000, max=75.0000
Batch 1: Inputs shape=torch.Size([4, 1, 513, 946]), Targets shape=torch.Size([4, 1, 513, 946]), Predicted Mask shape=torch.Size([4, 1, 513, 946]), Outputs shape=torch.Size([4, 64, 513, 946])
Mask min=0.0, max=1.0
[After Mask Application] Predicted vocals min: 0.0, max: 145.25

2025-02-22 03:05:19,889 - INFO - 
####LOSS VALUES####
[Combinedloss]:  Total treningsfeil, [BØR REDUSERES OVER TID]
[MaskLoss]: Sier hvor godt modellen lærer og predikere masken som isolerer vokaler[BØR REDUSERES OVER TID]
[l1_loss og stft_loss] gir ekstra indikasjoner på lydkvalitet.
[Hybridloss]: Kombinasjon av flere tapsfunksjoner[BØR REDUSERES OVER TID]

2025-02-22 03:05:19,905 - INFO - Appending Batch Losses: Mask: 0.3078673481941223, Hybrid: 0.498573362827301, Combined: 0.7652993202209473
2025-02-22 03:05:20,886 - INFO - [EPOCH 25]outputs from the model torch.Size([4, 64, 513, 946])
for batch 2
predicted mask shape torch.Size([4, 1, 513, 946])
2025-02-22 03:05:22,283 - INFO - Appending Batch Losses: Mask: 0.3606693148612976, Hybrid: 0.5617326498031616, Combined: 0.5130240321159363
2025-02-22 03:05:23,279 - INFO - Appending Batch Losses: Mask: 0.4021908938884735, Hybrid: 0.6559216976165771, Combined: 0.4801023006439209
2025-02-22 03:05:24,275 - INFO - Appending Batch Losses: Mask: 0.48035430908203125, Hybrid: 0.9364694356918335, Combined: 0.49837610125541687
2025-02-22 03:05:25,286 - INFO - Appending Batch Losses: Mask: 0.5507183074951172, Hybrid: 0.8641301393508911, Combined: 0.5542892217636108
2025-02-22 03:05:26,278 - INFO - Appending Batch Losses: Mask: 0.4032931327819824, Hybrid: 0.6737381815910339, Combined: 0.012866079807281494
2025-02-22 03:05:36,188 - INFO - Appending Batch Losses: Mask: 0.42954137921333313, Hybrid: 0.6560964584350586, Combined: 0.7139638662338257
2025-02-22 03:05:37,180 - INFO - Appending Batch Losses: Mask: 0.4155455231666565, Hybrid: 0.7299761176109314, Combined: 0.5995783805847168
2025-02-22 03:05:43,303 - INFO - Appending Batch Losses: Mask: 0.4000723659992218, Hybrid: 0.6521655321121216, Combined: 0.5541589856147766
2025-02-22 03:05:53,860 - INFO - Appending Batch Losses: Mask: 0.4663999080657959, Hybrid: 0.7538594007492065, Combined: 0.2525143027305603
2025-02-22 03:05:54,866 - INFO - Appending Batch Losses: Mask: 0.46038877964019775, Hybrid: 1.0610125064849854, Combined: 0.6465962529182434
2025-02-22 03:05:55,870 - INFO - Appending Batch Losses: Mask: 0.2945261001586914, Hybrid: 0.7848361134529114, Combined: -0.5038288235664368
2025-02-22 03:05:56,875 - INFO - Appending Batch Losses: Mask: 0.4124286472797394, Hybrid: 0.6679641008377075, Combined: 0.45606929063796997
2025-02-22 03:05:57,877 - INFO - Appending Batch Losses: Mask: 0.4484582543373108, Hybrid: 0.7400832176208496, Combined: 0.5527310967445374
2025-02-22 03:06:12,535 - INFO - Appending Batch Losses: Mask: 0.5683175325393677, Hybrid: 0.8685803413391113, Combined: 0.9298651218414307
2025-02-22 03:06:20,748 - INFO - Appending Batch Losses: Mask: 0.39813363552093506, Hybrid: 0.6362866163253784, Combined: 0.7153790593147278
2025-02-22 03:06:22,008 - INFO - Appending Batch Losses: Mask: 0.44197383522987366, Hybrid: 0.715955376625061, Combined: 0.5906872749328613
2025-02-22 03:06:22,988 - INFO - Appending Batch Losses: Mask: 0.36879414319992065, Hybrid: 0.5800853967666626, Combined: 0.4430830478668213
2025-02-22 03:06:23,965 - INFO - Appending Batch Losses: Mask: 0.40564391016960144, Hybrid: 0.661131739616394, Combined: 0.3983752131462097
2025-02-22 03:06:28,723 - INFO - Appending Batch Losses: Mask: 0.5581095218658447, Hybrid: 0.8027060031890869, Combined: 0.7340027093887329
2025-02-22 03:06:45,164 - INFO - Appending Batch Losses: Mask: 0.47977203130722046, Hybrid: 0.7361873984336853, Combined: 0.5824471116065979
2025-02-22 03:07:13,147 - INFO - Appending Batch Losses: Mask: 0.3245502710342407, Hybrid: 0.6171082258224487, Combined: 0.5932852625846863
2025-02-22 03:07:14,131 - INFO - Appending Batch Losses: Mask: 0.4286179542541504, Hybrid: 0.7457046508789062, Combined: 0.24762779474258423
2025-02-22 03:07:15,112 - INFO - Appending Batch Losses: Mask: 0.43604573607444763, Hybrid: 0.6458133459091187, Combined: 0.5008105039596558
2025-02-22 03:07:16,388 - INFO - Appending Batch Losses: Mask: 0.39177900552749634, Hybrid: 0.6892724633216858, Combined: 0.6503960490226746
2025-02-22 03:07:17,363 - INFO - Appending Batch Losses: Mask: 0.5468538999557495, Hybrid: 0.7642019391059875, Combined: 0.9510849714279175
2025-02-22 03:07:18,354 - INFO - Appending Batch Losses: Mask: 0.44132718443870544, Hybrid: 0.7291916608810425, Combined: 0.26381057500839233
2025-02-22 03:07:34,648 - INFO - Appending Batch Losses: Mask: 0.5744805932044983, Hybrid: 0.8172549605369568, Combined: 0.7229363918304443
2025-02-22 03:07:35,631 - INFO - Appending Batch Losses: Mask: 0.41358694434165955, Hybrid: 0.6326874494552612, Combined: 0.5957028269767761
2025-02-22 03:07:36,507 - INFO - Appending Batch Losses: Mask: 0.4661225378513336, Hybrid: 0.714250922203064, Combined: 0.4403863847255707
2025-02-22 03:07:37,350 - INFO - Appending Batch Losses: Mask: 0.3761691749095917, Hybrid: 0.6881269216537476, Combined: 0.5133860111236572
2025-02-22 03:07:38,328 - INFO - Appending Batch Losses: Mask: 0.37677785754203796, Hybrid: 0.7048616409301758, Combined: 0.2497555911540985
2025-02-22 03:07:39,550 - INFO - Appending Batch Losses: Mask: 0.37027648091316223, Hybrid: 0.6466888785362244, Combined: 0.4901450276374817
2025-02-22 03:08:05,002 - INFO - Appending Batch Losses: Mask: 0.35524889826774597, Hybrid: 0.8969388008117676, Combined: 0.4075723886489868
2025-02-22 03:08:05,978 - INFO - Appending Batch Losses: Mask: 0.44031351804733276, Hybrid: 0.6449743509292603, Combined: 0.6230130195617676
2025-02-22 03:08:06,947 - INFO - Appending Batch Losses: Mask: 0.4788680076599121, Hybrid: 0.714722752571106, Combined: 0.549599289894104
2025-02-22 03:08:07,912 - INFO - Appending Batch Losses: Mask: 0.35205331444740295, Hybrid: 0.7119637727737427, Combined: 0.12562042474746704
2025-02-22 03:08:10,113 - INFO - Current Learning Rate 0.0009971134020618558

2025-02-22 03:08:10,114 - INFO - 
[EPOCH 25]No improvement, NO NEW MODEL CHECKPOINT SAVED at epoch 25
 avg_epoch_loss: [0.497695]
 bestloss: [0.475183]
 Trigger: 6/12

2025-02-22 03:09:38,757 - INFO - 
Trigger times: 6, patience: 15

2025-02-22 03:09:38,758 - INFO - 
Trigger times: 6, patience: 12

2025-02-22 03:09:38,758 - INFO - 
[Epoch Improvement] Epoch 25: Loss improved during training by -3.09% from previous epoch, 

2025-02-22 03:09:38,760 - INFO - ####LOGGING AVERAGE LOSS EPOCH###
[Epoch Summary] Epoch: 25/50, Avg Combined Loss: 0.497695, MaskLoss: 0.427210, Hybridloss: 0.728663Previous Epoch loss: 0.4827591108309256
2025-02-22 03:09:38,761 - INFO - Epoch: 25 COMPLETED





2025-02-22 03:09:38,762 - INFO - [Train] Epoch 26/50 started.

2025-02-22 03:10:35,682 - INFO - #####INPUTS & TARGETS VALUE [2 BATCHES]####
Batch 1: Mixture shape=torch.Size([4, 1, 513, 946]), Target shape=torch.Size([4, 1, 513, 946])
2025-02-22 03:10:36,366 - INFO - [EPOCH 26]outputs from the model torch.Size([4, 64, 513, 946])
for batch 1
predicted mask shape torch.Size([4, 1, 513, 946])
2025-02-22 03:10:37,427 - INFO - Function: [log_first_2_batches_outputs_inputs_targets_predicted_mask]
2025-02-22 03:10:37,430 - INFO - ####OUTPUTS, INPUTS, TARGETS,PREDICTEDMASK [2 BATCHES]####
Batch 1: Mask range: min=0.0000, max=102.5625
Batch 1: Inputs shape=torch.Size([4, 1, 513, 946]), Targets shape=torch.Size([4, 1, 513, 946]), Predicted Mask shape=torch.Size([4, 1, 513, 946]), Outputs shape=torch.Size([4, 64, 513, 946])
Mask min=0.0, max=1.0
[After Mask Application] Predicted vocals min: 0.0, max: 152.375

2025-02-22 03:10:37,430 - INFO - 
####LOSS VALUES####
[Combinedloss]:  Total treningsfeil, [BØR REDUSERES OVER TID]
[MaskLoss]: Sier hvor godt modellen lærer og predikere masken som isolerer vokaler[BØR REDUSERES OVER TID]
[l1_loss og stft_loss] gir ekstra indikasjoner på lydkvalitet.
[Hybridloss]: Kombinasjon av flere tapsfunksjoner[BØR REDUSERES OVER TID]

2025-02-22 03:10:37,440 - INFO - Appending Batch Losses: Mask: 0.4264869689941406, Hybrid: 0.7533084154129028, Combined: 0.4778236448764801
2025-02-22 03:10:38,408 - INFO - [EPOCH 26]outputs from the model torch.Size([4, 64, 513, 946])
for batch 2
predicted mask shape torch.Size([4, 1, 513, 946])
2025-02-22 03:10:39,548 - INFO - Appending Batch Losses: Mask: 0.28404903411865234, Hybrid: 0.4114493727684021, Combined: 0.3965713083744049
2025-02-22 03:10:40,543 - INFO - Appending Batch Losses: Mask: 0.40930768847465515, Hybrid: 0.6670500040054321, Combined: 0.3219492435455322
2025-02-22 03:10:41,837 - INFO - Appending Batch Losses: Mask: 0.37148317694664, Hybrid: 0.9449992179870605, Combined: 0.5645194053649902
2025-02-22 03:10:42,858 - INFO - Appending Batch Losses: Mask: 0.44983065128326416, Hybrid: 0.8295841217041016, Combined: 0.7051857113838196
2025-02-22 03:10:43,705 - INFO - Appending Batch Losses: Mask: 0.34466353058815, Hybrid: 0.6672518253326416, Combined: 0.5175314545631409
2025-02-22 03:10:59,578 - INFO - Appending Batch Losses: Mask: 0.4024168848991394, Hybrid: 0.6372284889221191, Combined: 0.42205357551574707
2025-02-22 03:11:00,586 - INFO - Appending Batch Losses: Mask: 0.5605665445327759, Hybrid: 0.8942334055900574, Combined: 0.7438839673995972
2025-02-22 03:11:01,594 - INFO - Appending Batch Losses: Mask: 0.5150048136711121, Hybrid: 0.7771515846252441, Combined: 0.6250194907188416
2025-02-22 03:11:02,603 - INFO - Appending Batch Losses: Mask: 0.43846553564071655, Hybrid: 0.6602417826652527, Combined: 0.6309058666229248
2025-02-22 03:11:03,604 - INFO - Appending Batch Losses: Mask: 0.42296046018600464, Hybrid: 0.7050434350967407, Combined: 0.4143652319908142
2025-02-22 03:11:04,885 - INFO - Appending Batch Losses: Mask: 0.46684530377388, Hybrid: 0.8226735591888428, Combined: 0.4549640417098999
2025-02-22 03:11:20,162 - INFO - Appending Batch Losses: Mask: 0.4242282509803772, Hybrid: 0.6449763774871826, Combined: 0.5512958765029907
2025-02-22 03:11:21,144 - INFO - Appending Batch Losses: Mask: 0.45172759890556335, Hybrid: 0.7305915355682373, Combined: 0.46080872416496277
2025-02-22 03:11:22,147 - INFO - Appending Batch Losses: Mask: 0.5876502394676208, Hybrid: 0.8092513084411621, Combined: 0.8141214847564697
2025-02-22 03:11:23,161 - INFO - Appending Batch Losses: Mask: 0.39153194427490234, Hybrid: 0.6609169244766235, Combined: 0.30629101395606995
2025-02-22 03:11:24,165 - INFO - Appending Batch Losses: Mask: 0.41334155201911926, Hybrid: 0.676474392414093, Combined: 0.47453027963638306
2025-02-22 03:11:25,175 - INFO - Appending Batch Losses: Mask: 0.4413735866546631, Hybrid: 0.6895532608032227, Combined: 0.7958471775054932
2025-02-22 03:11:38,440 - INFO - Appending Batch Losses: Mask: 0.46754658222198486, Hybrid: 0.8670241832733154, Combined: 0.717958390712738
2025-02-22 03:11:39,661 - INFO - Appending Batch Losses: Mask: 0.47462210059165955, Hybrid: 0.7389441728591919, Combined: 0.4916561543941498
2025-02-22 03:11:40,643 - INFO - Appending Batch Losses: Mask: 0.3281523287296295, Hybrid: 0.533420205116272, Combined: 0.2002529799938202
2025-02-22 03:11:41,480 - INFO - Appending Batch Losses: Mask: 0.4340851902961731, Hybrid: 0.6782152652740479, Combined: 0.633696436882019
2025-02-22 03:11:42,333 - INFO - Appending Batch Losses: Mask: 0.38232120871543884, Hybrid: 0.602348268032074, Combined: 0.30214232206344604
2025-02-22 03:11:43,316 - INFO - Appending Batch Losses: Mask: 0.49593454599380493, Hybrid: 0.7219734787940979, Combined: 0.34539198875427246
2025-02-22 03:12:12,551 - INFO - Appending Batch Losses: Mask: 0.42962923645973206, Hybrid: 0.651825487613678, Combined: 0.4586767554283142
2025-02-22 03:12:13,547 - INFO - Appending Batch Losses: Mask: 0.3693792223930359, Hybrid: 0.7740620374679565, Combined: 0.08604967594146729
2025-02-22 03:12:14,539 - INFO - Appending Batch Losses: Mask: 0.3585672080516815, Hybrid: 0.6096434593200684, Combined: 0.4084516763687134
2025-02-22 03:12:15,789 - INFO - Appending Batch Losses: Mask: 0.584283709526062, Hybrid: 0.8929452896118164, Combined: 0.669032633304596
2025-02-22 03:12:16,665 - INFO - Appending Batch Losses: Mask: 0.5131025314331055, Hybrid: 0.8106224536895752, Combined: 0.9130144715309143
2025-02-22 03:12:19,383 - INFO - Appending Batch Losses: Mask: 0.26801812648773193, Hybrid: 0.47405970096588135, Combined: -0.12137964367866516
2025-02-22 03:12:36,216 - INFO - Appending Batch Losses: Mask: 0.40171968936920166, Hybrid: 0.587649405002594, Combined: 0.41072213649749756
2025-02-22 03:12:37,193 - INFO - Appending Batch Losses: Mask: 0.35848963260650635, Hybrid: 0.6179090142250061, Combined: 0.4504346549510956
2025-02-22 03:12:43,237 - INFO - Appending Batch Losses: Mask: 0.36861133575439453, Hybrid: 0.6847163438796997, Combined: 0.2892943322658539
2025-02-22 03:12:44,219 - INFO - Appending Batch Losses: Mask: 0.4004020094871521, Hybrid: 0.591059148311615, Combined: 0.4345436990261078
2025-02-22 03:12:45,194 - INFO - Appending Batch Losses: Mask: 0.3819863200187683, Hybrid: 0.7122111320495605, Combined: 0.05399274826049805
2025-02-22 03:12:46,255 - INFO - Appending Batch Losses: Mask: 0.44229087233543396, Hybrid: 0.9050570726394653, Combined: 0.30235934257507324
2025-02-22 03:12:58,750 - INFO - Appending Batch Losses: Mask: 0.38995617628097534, Hybrid: 0.6523027420043945, Combined: 0.29591575264930725
2025-02-22 03:13:00,878 - INFO - Current Learning Rate 0.000996082474226804

2025-02-22 03:13:02,233 - INFO - Checkpoint saved: /mnt/c/Users/didri/Desktop/Programmering/ArtificalintelligenceModels/UNet-Model_Vocal_Isolation/Unet_model_Audio_Seperation/Model_Weights/CheckPoints/Training/checkpoint_epoch_25.pth
2025-02-22 03:13:02,233 - INFO - 
 [EPOCH 26]Model Checkpoint SAVED at epoch 26
 avg_epoch_loss: [0.459997]
 bestloss: [0.459997]
 Trigger times: 0/12

2025-02-22 03:14:31,509 - INFO - 
Trigger times: 7, patience: 15

2025-02-22 03:14:31,509 - INFO - 
Trigger times: 7, patience: 12

2025-02-22 03:14:31,509 - INFO - 
[Epoch Improvement] Epoch 26: Loss improved during training by 7.57% from previous epoch, 

2025-02-22 03:14:31,510 - INFO - ####LOGGING AVERAGE LOSS EPOCH###
[Epoch Summary] Epoch: 26/50, Avg Combined Loss: 0.459997, MaskLoss: 0.427049, Hybridloss: 0.727756Previous Epoch loss: 0.497694931320242
2025-02-22 03:14:31,511 - INFO - Epoch: 26 COMPLETED





2025-02-22 03:14:31,511 - INFO - [Train] Epoch 27/50 started.

2025-02-22 03:15:01,487 - INFO - #####INPUTS & TARGETS VALUE [2 BATCHES]####
Batch 1: Mixture shape=torch.Size([4, 1, 513, 946]), Target shape=torch.Size([4, 1, 513, 946])
2025-02-22 03:15:02,220 - INFO - [EPOCH 27]outputs from the model torch.Size([4, 64, 513, 946])
for batch 1
predicted mask shape torch.Size([4, 1, 513, 946])
2025-02-22 03:15:03,304 - INFO - Function: [log_first_2_batches_outputs_inputs_targets_predicted_mask]
2025-02-22 03:15:03,307 - INFO - ####OUTPUTS, INPUTS, TARGETS,PREDICTEDMASK [2 BATCHES]####
Batch 1: Mask range: min=0.0000, max=79.3750
Batch 1: Inputs shape=torch.Size([4, 1, 513, 946]), Targets shape=torch.Size([4, 1, 513, 946]), Predicted Mask shape=torch.Size([4, 1, 513, 946]), Outputs shape=torch.Size([4, 64, 513, 946])
Mask min=0.0, max=1.0
[After Mask Application] Predicted vocals min: 0.0, max: 179.625

2025-02-22 03:15:03,307 - INFO - 
####LOSS VALUES####
[Combinedloss]:  Total treningsfeil, [BØR REDUSERES OVER TID]
[MaskLoss]: Sier hvor godt modellen lærer og predikere masken som isolerer vokaler[BØR REDUSERES OVER TID]
[l1_loss og stft_loss] gir ekstra indikasjoner på lydkvalitet.
[Hybridloss]: Kombinasjon av flere tapsfunksjoner[BØR REDUSERES OVER TID]

2025-02-22 03:15:03,321 - INFO - Appending Batch Losses: Mask: 0.49528685212135315, Hybrid: 0.7560811042785645, Combined: 0.5481467247009277
2025-02-22 03:15:04,310 - INFO - [EPOCH 27]outputs from the model torch.Size([4, 64, 513, 946])
for batch 2
predicted mask shape torch.Size([4, 1, 513, 946])
2025-02-22 03:15:05,612 - INFO - Appending Batch Losses: Mask: 0.47961026430130005, Hybrid: 0.7589735388755798, Combined: 0.6672608852386475
2025-02-22 03:15:06,613 - INFO - Appending Batch Losses: Mask: 0.43868470191955566, Hybrid: 0.8206853270530701, Combined: 0.5491814017295837
2025-02-22 03:15:25,040 - INFO - Appending Batch Losses: Mask: 0.5656872987747192, Hybrid: 0.9348363876342773, Combined: 0.5927452445030212
2025-02-22 03:15:25,914 - INFO - Appending Batch Losses: Mask: 0.4259973168373108, Hybrid: 0.7501809000968933, Combined: 0.4994064271450043
2025-02-22 03:15:26,919 - INFO - Appending Batch Losses: Mask: 0.45073965191841125, Hybrid: 0.7543346881866455, Combined: 0.7049669027328491
2025-02-22 03:15:35,599 - INFO - Appending Batch Losses: Mask: 0.482900470495224, Hybrid: 0.7706775665283203, Combined: 0.4795530140399933
2025-02-22 03:15:36,588 - INFO - Appending Batch Losses: Mask: 0.45120036602020264, Hybrid: 0.7549100518226624, Combined: 0.5432891845703125
2025-02-22 03:15:43,534 - INFO - Appending Batch Losses: Mask: 0.3827025592327118, Hybrid: 0.6294221878051758, Combined: 0.31824180483818054
2025-02-22 03:15:58,593 - INFO - Appending Batch Losses: Mask: 0.4714203178882599, Hybrid: 0.7612069249153137, Combined: 0.6025220155715942
2025-02-22 03:15:59,592 - INFO - Appending Batch Losses: Mask: 0.37003642320632935, Hybrid: 0.8300518989562988, Combined: 0.46587154269218445
2025-02-22 03:16:00,589 - INFO - Appending Batch Losses: Mask: 0.4422871172428131, Hybrid: 0.7783322334289551, Combined: 0.47622328996658325
2025-02-22 03:16:04,895 - INFO - Appending Batch Losses: Mask: 0.4676322042942047, Hybrid: 0.6869397759437561, Combined: 0.7712498307228088
2025-02-22 03:16:05,898 - INFO - Appending Batch Losses: Mask: 0.4561265707015991, Hybrid: 0.7101439237594604, Combined: 0.6863344311714172
2025-02-22 03:16:11,161 - INFO - Appending Batch Losses: Mask: 0.4021213948726654, Hybrid: 0.680313229560852, Combined: 0.38317063450813293
2025-02-22 03:16:40,185 - INFO - Appending Batch Losses: Mask: 0.45746874809265137, Hybrid: 0.6575637459754944, Combined: 0.624757707118988
2025-02-22 03:16:41,171 - INFO - Appending Batch Losses: Mask: 0.5174910426139832, Hybrid: 0.7842616438865662, Combined: 0.5399683713912964
2025-02-22 03:16:42,019 - INFO - Appending Batch Losses: Mask: 0.44994330406188965, Hybrid: 0.6640337705612183, Combined: 0.2984769642353058
2025-02-22 03:16:42,874 - INFO - Appending Batch Losses: Mask: 0.31107038259506226, Hybrid: 0.6709573864936829, Combined: 0.47870904207229614
2025-02-22 03:16:43,869 - INFO - Appending Batch Losses: Mask: 0.43310150504112244, Hybrid: 0.675383985042572, Combined: 0.5738505125045776
2025-02-22 03:16:45,961 - INFO - Appending Batch Losses: Mask: 0.3312092423439026, Hybrid: 0.6852717399597168, Combined: -0.15620261430740356
2025-02-22 03:17:17,200 - INFO - Appending Batch Losses: Mask: 0.3618076741695404, Hybrid: 0.49992114305496216, Combined: 0.7229059934616089
2025-02-22 03:17:18,422 - INFO - Appending Batch Losses: Mask: 0.45284512639045715, Hybrid: 0.7123152017593384, Combined: 0.36817467212677
2025-02-22 03:17:19,391 - INFO - Appending Batch Losses: Mask: 0.3888610899448395, Hybrid: 0.7053781151771545, Combined: 0.650653600692749
2025-02-22 03:17:20,374 - INFO - Appending Batch Losses: Mask: 0.34896695613861084, Hybrid: 0.7489522695541382, Combined: 0.5916203856468201
2025-02-22 03:17:21,360 - INFO - Appending Batch Losses: Mask: 0.44899654388427734, Hybrid: 0.6863572597503662, Combined: -0.02863001823425293
2025-02-22 03:17:22,335 - INFO - Appending Batch Losses: Mask: 0.42226123809814453, Hybrid: 0.70360267162323, Combined: 0.6185245513916016
2025-02-22 03:17:40,213 - INFO - Appending Batch Losses: Mask: 0.48769956827163696, Hybrid: 0.8211956024169922, Combined: 0.7303868532180786
2025-02-22 03:17:41,195 - INFO - Appending Batch Losses: Mask: 0.4063505530357361, Hybrid: 0.610470175743103, Combined: 0.3361341655254364
2025-02-22 03:17:42,167 - INFO - Appending Batch Losses: Mask: 0.35854849219322205, Hybrid: 0.5463700294494629, Combined: 0.45831310749053955
2025-02-22 03:17:43,474 - INFO - Appending Batch Losses: Mask: 0.3782639503479004, Hybrid: 0.5898957252502441, Combined: 0.6784585118293762
2025-02-22 03:17:44,447 - INFO - Appending Batch Losses: Mask: 0.36545053124427795, Hybrid: 0.6208153367042542, Combined: 0.2926027774810791
2025-02-22 03:17:45,450 - INFO - Appending Batch Losses: Mask: 0.4545498192310333, Hybrid: 0.6913231015205383, Combined: 0.3217582106590271
2025-02-22 03:18:04,547 - INFO - Appending Batch Losses: Mask: 0.4439832866191864, Hybrid: 0.828703761100769, Combined: 0.15183067321777344
2025-02-22 03:18:05,401 - INFO - Appending Batch Losses: Mask: 0.5538350343704224, Hybrid: 0.8820200562477112, Combined: 0.6902191042900085
2025-02-22 03:18:06,239 - INFO - Appending Batch Losses: Mask: 0.43629756569862366, Hybrid: 0.71775221824646, Combined: 0.7267659306526184
2025-02-22 03:18:07,209 - INFO - Appending Batch Losses: Mask: 0.4339744448661804, Hybrid: 0.8323782682418823, Combined: 0.7481511235237122
2025-02-22 03:18:09,491 - INFO - Current Learning Rate 0.000995257731958763

2025-02-22 03:18:09,491 - INFO - 
[EPOCH 27]No improvement, NO NEW MODEL CHECKPOINT SAVED at epoch 27
 avg_epoch_loss: [0.505557]
 bestloss: [0.459997]
 Trigger: 8/12

2025-02-22 03:19:34,466 - INFO - 
Trigger times: 8, patience: 15

2025-02-22 03:19:34,467 - INFO - 
Trigger times: 8, patience: 12

2025-02-22 03:19:34,467 - INFO - 
[Epoch Improvement] Epoch 27: Loss improved during training by -9.90% from previous epoch, 

2025-02-22 03:19:34,468 - INFO - ####LOGGING AVERAGE LOSS EPOCH###
[Epoch Summary] Epoch: 27/50, Avg Combined Loss: 0.505557, MaskLoss: 0.427273, Hybridloss: 0.727541Previous Epoch loss: 0.4599965947705346
2025-02-22 03:19:34,469 - INFO - Epoch: 27 COMPLETED





2025-02-22 03:19:34,470 - INFO - [Train] Epoch 28/50 started.

2025-02-22 03:20:18,742 - INFO - #####INPUTS & TARGETS VALUE [2 BATCHES]####
Batch 1: Mixture shape=torch.Size([4, 1, 513, 946]), Target shape=torch.Size([4, 1, 513, 946])
2025-02-22 03:20:19,766 - INFO - [EPOCH 28]outputs from the model torch.Size([4, 64, 513, 946])
for batch 1
predicted mask shape torch.Size([4, 1, 513, 946])
2025-02-22 03:20:21,145 - INFO - Function: [log_first_2_batches_outputs_inputs_targets_predicted_mask]
2025-02-22 03:20:21,148 - INFO - ####OUTPUTS, INPUTS, TARGETS,PREDICTEDMASK [2 BATCHES]####
Batch 1: Mask range: min=0.0000, max=52.1562
Batch 1: Inputs shape=torch.Size([4, 1, 513, 946]), Targets shape=torch.Size([4, 1, 513, 946]), Predicted Mask shape=torch.Size([4, 1, 513, 946]), Outputs shape=torch.Size([4, 64, 513, 946])
Mask min=0.0, max=1.0
[After Mask Application] Predicted vocals min: 0.0, max: 134.125

2025-02-22 03:20:21,149 - INFO - 
####LOSS VALUES####
[Combinedloss]:  Total treningsfeil, [BØR REDUSERES OVER TID]
[MaskLoss]: Sier hvor godt modellen lærer og predikere masken som isolerer vokaler[BØR REDUSERES OVER TID]
[l1_loss og stft_loss] gir ekstra indikasjoner på lydkvalitet.
[Hybridloss]: Kombinasjon av flere tapsfunksjoner[BØR REDUSERES OVER TID]

2025-02-22 03:20:21,164 - INFO - Appending Batch Losses: Mask: 0.4055832028388977, Hybrid: 0.6774160861968994, Combined: 0.4508271813392639
2025-02-22 03:20:22,462 - INFO - [EPOCH 28]outputs from the model torch.Size([4, 64, 513, 946])
for batch 2
predicted mask shape torch.Size([4, 1, 513, 946])
2025-02-22 03:20:23,712 - INFO - Appending Batch Losses: Mask: 0.39359980821609497, Hybrid: 0.5725452899932861, Combined: 0.6403189897537231
2025-02-22 03:20:24,766 - INFO - Appending Batch Losses: Mask: 0.4017915725708008, Hybrid: 0.6446815729141235, Combined: 0.5181849002838135
2025-02-22 03:20:25,782 - INFO - Appending Batch Losses: Mask: 0.37940773367881775, Hybrid: 0.5955466628074646, Combined: 0.4458213746547699
2025-02-22 03:20:31,634 - INFO - Appending Batch Losses: Mask: 0.5335767865180969, Hybrid: 0.7881171703338623, Combined: 0.3896806836128235
2025-02-22 03:20:32,625 - INFO - Appending Batch Losses: Mask: 0.39807993173599243, Hybrid: 0.6530629396438599, Combined: 0.5970835089683533
2025-02-22 03:20:40,931 - INFO - Appending Batch Losses: Mask: 0.41557276248931885, Hybrid: 0.6567373275756836, Combined: 0.49779438972473145
2025-02-22 03:20:41,918 - INFO - Appending Batch Losses: Mask: 0.38404807448387146, Hybrid: 0.5672457218170166, Combined: 0.45309120416641235
2025-02-22 03:20:42,906 - INFO - Appending Batch Losses: Mask: 0.43486449122428894, Hybrid: 0.8523545265197754, Combined: 0.41305723786354065
2025-02-22 03:21:06,988 - INFO - Appending Batch Losses: Mask: 0.31926560401916504, Hybrid: 0.5915316939353943, Combined: 0.39665502309799194
2025-02-22 03:21:07,994 - INFO - Appending Batch Losses: Mask: 0.43014857172966003, Hybrid: 0.8016130924224854, Combined: 0.3324565589427948
2025-02-22 03:21:09,002 - INFO - Appending Batch Losses: Mask: 0.38392847776412964, Hybrid: 0.6424010992050171, Combined: 0.49623602628707886
2025-02-22 03:21:15,425 - INFO - Appending Batch Losses: Mask: 0.5917359590530396, Hybrid: 0.8723015785217285, Combined: 0.6694308519363403
2025-02-22 03:21:16,400 - INFO - Appending Batch Losses: Mask: 0.44690537452697754, Hybrid: 0.6824812293052673, Combined: 0.5477986931800842
2025-02-22 03:21:17,376 - INFO - Appending Batch Losses: Mask: 0.5474974513053894, Hybrid: 0.963367223739624, Combined: 0.7983092069625854
2025-02-22 03:21:29,211 - INFO - Appending Batch Losses: Mask: 0.40075910091400146, Hybrid: 0.7244945764541626, Combined: 0.48168277740478516
2025-02-22 03:21:30,211 - INFO - Appending Batch Losses: Mask: 0.5044164657592773, Hybrid: 0.8690840005874634, Combined: 0.7296677231788635
2025-02-22 03:21:31,531 - INFO - Appending Batch Losses: Mask: 0.3965923488140106, Hybrid: 0.6789652109146118, Combined: 0.22937622666358948
2025-02-22 03:21:45,357 - INFO - Appending Batch Losses: Mask: 0.35373079776763916, Hybrid: 0.5811080932617188, Combined: 0.7279553413391113
2025-02-22 03:21:46,342 - INFO - Appending Batch Losses: Mask: 0.46093854308128357, Hybrid: 0.763208270072937, Combined: 0.7062655091285706
2025-02-22 03:21:47,338 - INFO - Appending Batch Losses: Mask: 0.5159363150596619, Hybrid: 0.7794090509414673, Combined: 0.7337067723274231
2025-02-22 03:21:54,962 - INFO - Appending Batch Losses: Mask: 0.5160766243934631, Hybrid: 0.8286881446838379, Combined: 0.48516586422920227
2025-02-22 03:21:55,945 - INFO - Appending Batch Losses: Mask: 0.4389580190181732, Hybrid: 0.6877715587615967, Combined: 0.30569207668304443
2025-02-22 03:21:56,955 - INFO - Appending Batch Losses: Mask: 0.3286691904067993, Hybrid: 0.6589310169219971, Combined: 0.2739861011505127
2025-02-22 03:22:13,929 - INFO - Appending Batch Losses: Mask: 0.40857037901878357, Hybrid: 0.7893165349960327, Combined: 0.6636244654655457
2025-02-22 03:22:15,181 - INFO - Appending Batch Losses: Mask: 0.38087570667266846, Hybrid: 0.6198362112045288, Combined: 0.3709786534309387
2025-02-22 03:22:16,156 - INFO - Appending Batch Losses: Mask: 0.5039400458335876, Hybrid: 0.9004993438720703, Combined: 0.5988302826881409
2025-02-22 03:22:32,305 - INFO - Appending Batch Losses: Mask: 0.3703519105911255, Hybrid: 0.8397257328033447, Combined: 0.439742773771286
2025-02-22 03:22:33,312 - INFO - Appending Batch Losses: Mask: 0.455068439245224, Hybrid: 0.71193528175354, Combined: 0.3860354423522949
2025-02-22 03:22:34,292 - INFO - Appending Batch Losses: Mask: 0.3906119167804718, Hybrid: 0.6970115900039673, Combined: 0.16253578662872314
2025-02-22 03:22:35,286 - INFO - Appending Batch Losses: Mask: 0.35651105642318726, Hybrid: 0.6714296340942383, Combined: 0.43752992153167725
2025-02-22 03:22:36,301 - INFO - Appending Batch Losses: Mask: 0.41354066133499146, Hybrid: 0.6225160360336304, Combined: 0.4830876588821411
2025-02-22 03:22:37,276 - INFO - Appending Batch Losses: Mask: 0.4791824221611023, Hybrid: 0.6634709239006042, Combined: 0.3219870924949646
2025-02-22 03:22:57,302 - INFO - Appending Batch Losses: Mask: 0.4928927421569824, Hybrid: 0.7631011605262756, Combined: 0.7344106435775757
2025-02-22 03:22:58,269 - INFO - Appending Batch Losses: Mask: 0.4447575509548187, Hybrid: 0.6610914468765259, Combined: 0.31556379795074463
2025-02-22 03:22:59,244 - INFO - Appending Batch Losses: Mask: 0.2776288390159607, Hybrid: 0.4889163374900818, Combined: 0.16052553057670593
2025-02-22 03:23:00,225 - INFO - Appending Batch Losses: Mask: 0.4569079279899597, Hybrid: 0.7761633396148682, Combined: 0.7600228190422058
2025-02-22 03:23:02,355 - INFO - Current Learning Rate 0.0009942268041237114

2025-02-22 03:23:02,356 - INFO - 
[EPOCH 28]No improvement, NO NEW MODEL CHECKPOINT SAVED at epoch 28
 avg_epoch_loss: [0.490679]
 bestloss: [0.459997]
 Trigger: 9/12

2025-02-22 03:24:26,410 - INFO - 
Trigger times: 9, patience: 15

2025-02-22 03:24:26,410 - INFO - 
Trigger times: 9, patience: 12

2025-02-22 03:24:26,411 - INFO - 
[Epoch Improvement] Epoch 28: Loss improved during training by 2.94% from previous epoch, 

2025-02-22 03:24:26,411 - INFO - ####LOGGING AVERAGE LOSS EPOCH###
[Epoch Summary] Epoch: 28/50, Avg Combined Loss: 0.490679, MaskLoss: 0.427277, Hybridloss: 0.726980Previous Epoch loss: 0.5055565664897094
2025-02-22 03:24:26,412 - INFO - Epoch: 28 COMPLETED





2025-02-22 03:24:26,413 - INFO - [Train] Epoch 29/50 started.

2025-02-22 03:24:51,802 - INFO - #####INPUTS & TARGETS VALUE [2 BATCHES]####
Batch 1: Mixture shape=torch.Size([4, 1, 513, 946]), Target shape=torch.Size([4, 1, 513, 946])
2025-02-22 03:24:52,749 - INFO - [EPOCH 29]outputs from the model torch.Size([4, 64, 513, 946])
for batch 1
predicted mask shape torch.Size([4, 1, 513, 946])
2025-02-22 03:24:53,987 - INFO - Function: [log_first_2_batches_outputs_inputs_targets_predicted_mask]
2025-02-22 03:24:53,990 - INFO - ####OUTPUTS, INPUTS, TARGETS,PREDICTEDMASK [2 BATCHES]####
Batch 1: Mask range: min=0.0000, max=50.6562
Batch 1: Inputs shape=torch.Size([4, 1, 513, 946]), Targets shape=torch.Size([4, 1, 513, 946]), Predicted Mask shape=torch.Size([4, 1, 513, 946]), Outputs shape=torch.Size([4, 64, 513, 946])
Mask min=0.0, max=1.0
[After Mask Application] Predicted vocals min: 0.0, max: 133.0

2025-02-22 03:24:53,990 - INFO - 
####LOSS VALUES####
[Combinedloss]:  Total treningsfeil, [BØR REDUSERES OVER TID]
[MaskLoss]: Sier hvor godt modellen lærer og predikere masken som isolerer vokaler[BØR REDUSERES OVER TID]
[l1_loss og stft_loss] gir ekstra indikasjoner på lydkvalitet.
[Hybridloss]: Kombinasjon av flere tapsfunksjoner[BØR REDUSERES OVER TID]

2025-02-22 03:24:54,004 - INFO - Appending Batch Losses: Mask: 0.49265363812446594, Hybrid: 0.8618824481964111, Combined: 0.4695386588573456
2025-02-22 03:25:05,303 - INFO - [EPOCH 29]outputs from the model torch.Size([4, 64, 513, 946])
for batch 2
predicted mask shape torch.Size([4, 1, 513, 946])
2025-02-22 03:25:06,603 - INFO - Appending Batch Losses: Mask: 0.42030346393585205, Hybrid: 0.6898961663246155, Combined: 0.20506104826927185
2025-02-22 03:25:07,600 - INFO - Appending Batch Losses: Mask: 0.41967564821243286, Hybrid: 0.6582119464874268, Combined: 0.6043049693107605
2025-02-22 03:25:08,465 - INFO - Appending Batch Losses: Mask: 0.4662064015865326, Hybrid: 0.7558757662773132, Combined: 0.5497112274169922
2025-02-22 03:25:17,050 - INFO - Appending Batch Losses: Mask: 0.4298290014266968, Hybrid: 0.7264971137046814, Combined: 0.6444435119628906
2025-02-22 03:25:18,062 - INFO - Appending Batch Losses: Mask: 0.42869943380355835, Hybrid: 0.7710655331611633, Combined: 0.6912822723388672
2025-02-22 03:25:32,121 - INFO - Appending Batch Losses: Mask: 0.4518090784549713, Hybrid: 0.7439417839050293, Combined: 0.7170435190200806
2025-02-22 03:25:53,899 - INFO - Appending Batch Losses: Mask: 0.48033231496810913, Hybrid: 0.8451293706893921, Combined: 0.6708906292915344
2025-02-22 03:25:54,751 - INFO - Appending Batch Losses: Mask: 0.37234562635421753, Hybrid: 0.5830192565917969, Combined: 0.36919546127319336
2025-02-22 03:25:55,743 - INFO - Appending Batch Losses: Mask: 0.3787536323070526, Hybrid: 0.5726507902145386, Combined: 0.09479531645774841
2025-02-22 03:25:56,712 - INFO - Appending Batch Losses: Mask: 0.3627222180366516, Hybrid: 0.6603686213493347, Combined: -0.12722712755203247
2025-02-22 03:25:57,578 - INFO - Appending Batch Losses: Mask: 0.5707296133041382, Hybrid: 0.8869013786315918, Combined: 0.6538434028625488
2025-02-22 03:26:09,497 - INFO - Appending Batch Losses: Mask: 0.3474820554256439, Hybrid: 0.7150865197181702, Combined: 0.36474061012268066
2025-02-22 03:26:10,479 - INFO - Appending Batch Losses: Mask: 0.49132129549980164, Hybrid: 0.7349554300308228, Combined: 0.7009281516075134
2025-02-22 03:26:14,111 - INFO - Appending Batch Losses: Mask: 0.43372485041618347, Hybrid: 0.8973726034164429, Combined: 0.8012388348579407
2025-02-22 03:26:15,080 - INFO - Appending Batch Losses: Mask: 0.3473401963710785, Hybrid: 0.5342456102371216, Combined: 0.4023645520210266
2025-02-22 03:26:16,056 - INFO - Appending Batch Losses: Mask: 0.5172284841537476, Hybrid: 0.9188708066940308, Combined: 0.5513291358947754
2025-02-22 03:26:17,033 - INFO - Appending Batch Losses: Mask: 0.373771071434021, Hybrid: 0.562510073184967, Combined: 0.6277455687522888
2025-02-22 03:26:32,517 - INFO - Appending Batch Losses: Mask: 0.35110434889793396, Hybrid: 0.7393896579742432, Combined: 0.3419877588748932
2025-02-22 03:26:33,510 - INFO - Appending Batch Losses: Mask: 0.49138519167900085, Hybrid: 0.8283291459083557, Combined: 0.553473174571991
2025-02-22 03:26:34,744 - INFO - Appending Batch Losses: Mask: 0.3671181797981262, Hybrid: 0.7883382439613342, Combined: 0.2763001024723053
2025-02-22 03:26:35,730 - INFO - Appending Batch Losses: Mask: 0.45595768094062805, Hybrid: 0.7157573699951172, Combined: 0.5007553100585938
2025-02-22 03:26:36,719 - INFO - Appending Batch Losses: Mask: 0.4027100205421448, Hybrid: 0.7080433368682861, Combined: 0.3654123842716217
2025-02-22 03:26:43,162 - INFO - Appending Batch Losses: Mask: 0.3532596230506897, Hybrid: 0.8360713720321655, Combined: 0.14761823415756226
2025-02-22 03:27:04,852 - INFO - Appending Batch Losses: Mask: 0.35319915413856506, Hybrid: 0.6544890999794006, Combined: 0.5152553915977478
2025-02-22 03:27:05,841 - INFO - Appending Batch Losses: Mask: 0.4860690236091614, Hybrid: 0.7176975011825562, Combined: 0.6256870031356812
2025-02-22 03:27:06,842 - INFO - Appending Batch Losses: Mask: 0.40790385007858276, Hybrid: 0.6758677959442139, Combined: 0.4421001076698303
2025-02-22 03:27:07,829 - INFO - Appending Batch Losses: Mask: 0.2851824164390564, Hybrid: 0.4497676491737366, Combined: 0.36597520112991333
2025-02-22 03:27:09,038 - INFO - Appending Batch Losses: Mask: 0.4578610360622406, Hybrid: 0.7151007652282715, Combined: 0.5416969060897827
2025-02-22 03:27:16,577 - INFO - Appending Batch Losses: Mask: 0.38800573348999023, Hybrid: 0.5947846174240112, Combined: 0.3367472290992737
2025-02-22 03:27:24,538 - INFO - Appending Batch Losses: Mask: 0.5217199325561523, Hybrid: 0.8211924433708191, Combined: 0.8054298758506775
2025-02-22 03:27:29,639 - INFO - Appending Batch Losses: Mask: 0.41874730587005615, Hybrid: 0.7245156168937683, Combined: 0.435568630695343
2025-02-22 03:27:30,478 - INFO - Appending Batch Losses: Mask: 0.39026445150375366, Hybrid: 0.7498898506164551, Combined: 0.2843906581401825
2025-02-22 03:27:31,318 - INFO - Appending Batch Losses: Mask: 0.38408976793289185, Hybrid: 0.6143306493759155, Combined: 0.5381834506988525
2025-02-22 03:27:32,169 - INFO - Appending Batch Losses: Mask: 0.38718342781066895, Hybrid: 0.5289514064788818, Combined: 0.6664984226226807
2025-02-22 03:27:39,646 - INFO - Appending Batch Losses: Mask: 0.45315638184547424, Hybrid: 0.7411152124404907, Combined: 0.5372880697250366
2025-02-22 03:27:50,020 - INFO - Appending Batch Losses: Mask: 0.3381711542606354, Hybrid: 0.5017589926719666, Combined: 0.5366058349609375
2025-02-22 03:27:52,176 - INFO - Current Learning Rate 0.0009931958762886598

2025-02-22 03:27:52,177 - INFO - 
[EPOCH 29]No improvement, NO NEW MODEL CHECKPOINT SAVED at epoch 29
 avg_epoch_loss: [0.481303]
 bestloss: [0.459997]
 Trigger: 10/12

2025-02-22 03:29:15,390 - INFO - 
Trigger times: 10, patience: 15

2025-02-22 03:29:15,390 - INFO - 
Trigger times: 10, patience: 12

2025-02-22 03:29:15,390 - INFO - 
[Epoch Improvement] Epoch 29: Loss improved during training by 1.91% from previous epoch, 

2025-02-22 03:29:15,390 - INFO - ####LOGGING AVERAGE LOSS EPOCH###
[Epoch Summary] Epoch: 29/50, Avg Combined Loss: 0.481303, MaskLoss: 0.426968, Hybridloss: 0.726352Previous Epoch loss: 0.49067889435871226
2025-02-22 03:29:15,391 - INFO - Epoch: 29 COMPLETED





2025-02-22 03:29:15,392 - INFO - [Train] Epoch 30/50 started.

2025-02-22 03:29:49,568 - INFO - #####INPUTS & TARGETS VALUE [2 BATCHES]####
Batch 1: Mixture shape=torch.Size([4, 1, 513, 946]), Target shape=torch.Size([4, 1, 513, 946])
2025-02-22 03:29:50,438 - INFO - [EPOCH 30]outputs from the model torch.Size([4, 64, 513, 946])
for batch 1
predicted mask shape torch.Size([4, 1, 513, 946])
2025-02-22 03:29:51,723 - INFO - Function: [log_first_2_batches_outputs_inputs_targets_predicted_mask]
2025-02-22 03:29:51,726 - INFO - ####OUTPUTS, INPUTS, TARGETS,PREDICTEDMASK [2 BATCHES]####
Batch 1: Mask range: min=0.0000, max=81.8125
Batch 1: Inputs shape=torch.Size([4, 1, 513, 946]), Targets shape=torch.Size([4, 1, 513, 946]), Predicted Mask shape=torch.Size([4, 1, 513, 946]), Outputs shape=torch.Size([4, 64, 513, 946])
Mask min=0.0, max=1.0
[After Mask Application] Predicted vocals min: 0.0, max: 168.75

2025-02-22 03:29:51,726 - INFO - 
####LOSS VALUES####
[Combinedloss]:  Total treningsfeil, [BØR REDUSERES OVER TID]
[MaskLoss]: Sier hvor godt modellen lærer og predikere masken som isolerer vokaler[BØR REDUSERES OVER TID]
[l1_loss og stft_loss] gir ekstra indikasjoner på lydkvalitet.
[Hybridloss]: Kombinasjon av flere tapsfunksjoner[BØR REDUSERES OVER TID]

2025-02-22 03:29:51,740 - INFO - Appending Batch Losses: Mask: 0.42747625708580017, Hybrid: 0.7995352745056152, Combined: 0.4616820216178894
2025-02-22 03:30:00,695 - INFO - [EPOCH 30]outputs from the model torch.Size([4, 64, 513, 946])
for batch 2
predicted mask shape torch.Size([4, 1, 513, 946])
2025-02-22 03:30:01,967 - INFO - Appending Batch Losses: Mask: 0.4253840744495392, Hybrid: 0.6720179915428162, Combined: 0.09516865015029907
2025-02-22 03:30:02,972 - INFO - Appending Batch Losses: Mask: 0.5469843745231628, Hybrid: 0.8939738869667053, Combined: 0.5529853105545044
2025-02-22 03:30:03,980 - INFO - Appending Batch Losses: Mask: 0.436722993850708, Hybrid: 0.901942253112793, Combined: 0.6631267070770264
2025-02-22 03:30:04,978 - INFO - Appending Batch Losses: Mask: 0.3624235987663269, Hybrid: 0.6520801782608032, Combined: 0.48233622312545776
2025-02-22 03:30:05,997 - INFO - Appending Batch Losses: Mask: 0.37284910678863525, Hybrid: 0.6565959453582764, Combined: 0.27917224168777466
2025-02-22 03:30:32,051 - INFO - Appending Batch Losses: Mask: 0.3118286430835724, Hybrid: 0.6520572900772095, Combined: 0.23867353796958923
2025-02-22 03:30:33,153 - INFO - Appending Batch Losses: Mask: 0.47083041071891785, Hybrid: 0.7236523628234863, Combined: 0.8032321929931641
2025-02-22 03:30:34,139 - INFO - Appending Batch Losses: Mask: 0.44957423210144043, Hybrid: 0.7470652461051941, Combined: 0.37586510181427
2025-02-22 03:30:35,124 - INFO - Appending Batch Losses: Mask: 0.3397042751312256, Hybrid: 0.5563757419586182, Combined: 0.5499340891838074
2025-02-22 03:30:36,114 - INFO - Appending Batch Losses: Mask: 0.4729984700679779, Hybrid: 0.825232982635498, Combined: 0.3205569386482239
2025-02-22 03:30:37,120 - INFO - Appending Batch Losses: Mask: 0.5392990112304688, Hybrid: 0.8447263240814209, Combined: 0.8335894346237183
2025-02-22 03:31:10,813 - INFO - Appending Batch Losses: Mask: 0.48970258235931396, Hybrid: 0.7428773641586304, Combined: 0.4701879322528839
2025-02-22 03:31:11,791 - INFO - Appending Batch Losses: Mask: 0.48961496353149414, Hybrid: 0.7495369911193848, Combined: 0.734167754650116
2025-02-22 03:31:12,772 - INFO - Appending Batch Losses: Mask: 0.5850259065628052, Hybrid: 0.8097492456436157, Combined: 0.8272411823272705
2025-02-22 03:31:13,967 - INFO - Appending Batch Losses: Mask: 0.3653835952281952, Hybrid: 0.6379651427268982, Combined: 0.47665339708328247
2025-02-22 03:31:14,939 - INFO - Appending Batch Losses: Mask: 0.40106379985809326, Hybrid: 0.691263735294342, Combined: 0.40319162607192993
2025-02-22 03:31:15,924 - INFO - Appending Batch Losses: Mask: 0.48338761925697327, Hybrid: 0.7537734508514404, Combined: 0.7958898544311523
2025-02-22 03:31:41,683 - INFO - Appending Batch Losses: Mask: 0.3709511160850525, Hybrid: 0.5363174676895142, Combined: 0.4258313775062561
2025-02-22 03:31:42,662 - INFO - Appending Batch Losses: Mask: 0.5208290815353394, Hybrid: 0.741135835647583, Combined: 0.6838107109069824
2025-02-22 03:31:43,640 - INFO - Appending Batch Losses: Mask: 0.36623767018318176, Hybrid: 0.5663007497787476, Combined: 0.6714610457420349
2025-02-22 03:31:44,631 - INFO - Appending Batch Losses: Mask: 0.4604719281196594, Hybrid: 0.7549406290054321, Combined: 0.7635650038719177
2025-02-22 03:31:45,629 - INFO - Appending Batch Losses: Mask: 0.4719637334346771, Hybrid: 0.7578995227813721, Combined: 0.4810851216316223
2025-02-22 03:31:46,883 - INFO - Appending Batch Losses: Mask: 0.4594234824180603, Hybrid: 0.6774510145187378, Combined: 0.49968165159225464
2025-02-22 03:32:12,355 - INFO - Appending Batch Losses: Mask: 0.6285920143127441, Hybrid: 0.9187040328979492, Combined: 0.7312113046646118
2025-02-22 03:32:13,330 - INFO - Appending Batch Losses: Mask: 0.4827365279197693, Hybrid: 0.7837117910385132, Combined: 0.6068360805511475
2025-02-22 03:32:14,310 - INFO - Appending Batch Losses: Mask: 0.3922290802001953, Hybrid: 0.7500854730606079, Combined: 0.4786483645439148
2025-02-22 03:32:15,299 - INFO - Appending Batch Losses: Mask: 0.559518039226532, Hybrid: 0.9211459755897522, Combined: 0.6932574510574341
2025-02-22 03:32:16,146 - INFO - Appending Batch Losses: Mask: 0.5475530028343201, Hybrid: 0.8231161832809448, Combined: 0.7679412961006165
2025-02-22 03:32:16,992 - INFO - Appending Batch Losses: Mask: 0.3535482585430145, Hybrid: 0.6686631441116333, Combined: 0.3202430307865143
2025-02-22 03:32:30,782 - INFO - Appending Batch Losses: Mask: 0.5626795887947083, Hybrid: 0.849341869354248, Combined: 0.7103314399719238
2025-02-22 03:32:31,905 - INFO - Appending Batch Losses: Mask: 0.48739907145500183, Hybrid: 0.7308329343795776, Combined: 0.5874698162078857
2025-02-22 03:32:37,157 - ERROR - [Train] Error during training: CUDA out of memory. Tried to allocate 948.00 MiB. GPU 0 has a total capacity of 12.00 GiB of which 0 bytes is free. Including non-PyTorch memory, this process has 17179869184.00 GiB memory in use. Process 6066 has 17179869184.00 GiB memory in use. Process 6068 has 17179869184.00 GiB memory in use. Process 6065 has 17179869184.00 GiB memory in use. Of the allocated memory 7.36 GiB is allocated by PyTorch, and 2.98 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
