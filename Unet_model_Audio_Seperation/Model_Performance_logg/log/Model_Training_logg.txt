2025-01-21 18:29:06,256 - INFO - Found 100 files in 'C:\Users\didri\Desktop\UNet-Models\Unet_model_Audio_Seperation\Datasets\Dataset_Audio_Folders\musdb18\train' (subset='train')
2025-01-21 18:29:06,256 - INFO - Dataset initialized with 100 valid files.
2025-01-21 18:29:06,256 - INFO - Found 50 files in 'C:\Users\didri\Desktop\UNet-Models\Unet_model_Audio_Seperation\Datasets\Dataset_Audio_Folders\musdb18\test' (subset='test')
2025-01-21 18:29:06,257 - INFO - Dataset initialized with 50 valid files.
2025-01-21 18:29:06,262 - INFO - Training dataset size: 150
2025-01-21 18:29:06,262 - INFO - Validation dataset size: 100
2025-01-21 18:29:06,276 - INFO - [Train] Using device: cuda
2025-01-21 18:29:07,830 - INFO - Total number of parameters: 28905365
2025-01-21 18:29:07,831 - INFO - Trainable parameters: 28905365
2025-01-21 18:29:07,832 - INFO - Model architecture:
UNet(
  (encoder): ModuleList(
    (0): Sequential(
      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      (2): ReLU(inplace=True)
      (3): SEBlock(
        (avg_pool): AdaptiveAvgPool2d(output_size=1)
        (fc): Sequential(
          (0): Linear(in_features=64, out_features=4, bias=False)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=4, out_features=64, bias=False)
          (3): Sigmoid()
        )
      )
      (4): SpectralAttentionBlock(
        (avg_pool): AdaptiveAvgPool2d(output_size=(1, None))
        (fc): Sequential(
          (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
          (1): ReLU(inplace=True)
          (2): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))
          (3): Sigmoid()
        )
      )
      (5): Dropout(p=0.4, inplace=False)
      (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      (8): ReLU(inplace=True)
    )
    (1): Sequential(
      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      (2): ReLU(inplace=True)
      (3): SEBlock(
        (avg_pool): AdaptiveAvgPool2d(output_size=1)
        (fc): Sequential(
          (0): Linear(in_features=128, out_features=8, bias=False)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=8, out_features=128, bias=False)
          (3): Sigmoid()
        )
      )
      (4): SpectralAttentionBlock(
        (avg_pool): AdaptiveAvgPool2d(output_size=(1, None))
        (fc): Sequential(
          (0): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1))
          (1): ReLU(inplace=True)
          (2): Conv2d(16, 128, kernel_size=(1, 1), stride=(1, 1))
          (3): Sigmoid()
        )
      )
      (5): Dropout(p=0.4, inplace=False)
      (6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      (8): ReLU(inplace=True)
    )
    (2): Sequential(
      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      (2): ReLU(inplace=True)
      (3): SEBlock(
        (avg_pool): AdaptiveAvgPool2d(output_size=1)
        (fc): Sequential(
          (0): Linear(in_features=256, out_features=16, bias=False)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=16, out_features=256, bias=False)
          (3): Sigmoid()
        )
      )
      (4): SpectralAttentionBlock(
        (avg_pool): AdaptiveAvgPool2d(output_size=(1, None))
        (fc): Sequential(
          (0): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
          (1): ReLU(inplace=True)
          (2): Conv2d(32, 256, kernel_size=(1, 1), stride=(1, 1))
          (3): Sigmoid()
        )
      )
      (5): Dropout(p=0.4, inplace=False)
      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      (8): ReLU(inplace=True)
    )
    (3): Sequential(
      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      (2): ReLU(inplace=True)
      (3): SEBlock(
        (avg_pool): AdaptiveAvgPool2d(output_size=1)
        (fc): Sequential(
          (0): Linear(in_features=512, out_features=32, bias=False)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=32, out_features=512, bias=False)
          (3): Sigmoid()
        )
      )
      (4): SpectralAttentionBlock(
        (avg_pool): AdaptiveAvgPool2d(output_size=(1, None))
        (fc): Sequential(
          (0): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))
          (1): ReLU(inplace=True)
          (2): Conv2d(64, 512, kernel_size=(1, 1), stride=(1, 1))
          (3): Sigmoid()
        )
      )
      (5): Dropout(p=0.4, inplace=False)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      (8): ReLU(inplace=True)
    )
  )
  (bottleneck): Sequential(
    (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (2): ReLU(inplace=True)
    (3): SEBlock(
      (avg_pool): AdaptiveAvgPool2d(output_size=1)
      (fc): Sequential(
        (0): Linear(in_features=1024, out_features=64, bias=False)
        (1): ReLU(inplace=True)
        (2): Linear(in_features=64, out_features=1024, bias=False)
        (3): Sigmoid()
      )
    )
    (4): SpectralAttentionBlock(
      (avg_pool): AdaptiveAvgPool2d(output_size=(1, None))
      (fc): Sequential(
        (0): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1))
        (1): ReLU(inplace=True)
        (2): Conv2d(128, 1024, kernel_size=(1, 1), stride=(1, 1))
        (3): Sigmoid()
      )
    )
    (5): Dropout(p=0.4, inplace=False)
    (6): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (8): ReLU(inplace=True)
  )
  (decoder): ModuleList(
    (0): MultiScaleDecoderBlock(
      (up): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))
      (conv): Sequential(
        (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): SEBlock(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (fc): Sequential(
            (0): Linear(in_features=512, out_features=32, bias=False)
            (1): ReLU(inplace=True)
            (2): Linear(in_features=32, out_features=512, bias=False)
            (3): Sigmoid()
          )
        )
        (4): SpectralAttentionBlock(
          (avg_pool): AdaptiveAvgPool2d(output_size=(1, None))
          (fc): Sequential(
            (0): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))
            (1): ReLU(inplace=True)
            (2): Conv2d(64, 512, kernel_size=(1, 1), stride=(1, 1))
            (3): Sigmoid()
          )
        )
      )
    )
    (1): AttentionBlock(
      (W_g): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
      (W_x): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
      (psi): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))
      (relu): ReLU(inplace=True)
      (sigmoid): Sigmoid()
    )
    (2): MultiScaleDecoderBlock(
      (up): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))
      (conv): Sequential(
        (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): SEBlock(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (fc): Sequential(
            (0): Linear(in_features=256, out_features=16, bias=False)
            (1): ReLU(inplace=True)
            (2): Linear(in_features=16, out_features=256, bias=False)
            (3): Sigmoid()
          )
        )
        (4): SpectralAttentionBlock(
          (avg_pool): AdaptiveAvgPool2d(output_size=(1, None))
          (fc): Sequential(
            (0): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
            (1): ReLU(inplace=True)
            (2): Conv2d(32, 256, kernel_size=(1, 1), stride=(1, 1))
            (3): Sigmoid()
          )
        )
      )
    )
    (3): AttentionBlock(
      (W_g): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))
      (W_x): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))
      (psi): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))
      (relu): ReLU(inplace=True)
      (sigmoid): Sigmoid()
    )
    (4): MultiScaleDecoderBlock(
      (up): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))
      (conv): Sequential(
        (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): SEBlock(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (fc): Sequential(
            (0): Linear(in_features=128, out_features=8, bias=False)
            (1): ReLU(inplace=True)
            (2): Linear(in_features=8, out_features=128, bias=False)
            (3): Sigmoid()
          )
        )
        (4): SpectralAttentionBlock(
          (avg_pool): AdaptiveAvgPool2d(output_size=(1, None))
          (fc): Sequential(
            (0): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1))
            (1): ReLU(inplace=True)
            (2): Conv2d(16, 128, kernel_size=(1, 1), stride=(1, 1))
            (3): Sigmoid()
          )
        )
      )
    )
    (5): AttentionBlock(
      (W_g): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
      (W_x): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
      (psi): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (relu): ReLU(inplace=True)
      (sigmoid): Sigmoid()
    )
    (6): MultiScaleDecoderBlock(
      (up): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))
      (conv): Sequential(
        (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): SEBlock(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (fc): Sequential(
            (0): Linear(in_features=64, out_features=4, bias=False)
            (1): ReLU(inplace=True)
            (2): Linear(in_features=4, out_features=64, bias=False)
            (3): Sigmoid()
          )
        )
        (4): SpectralAttentionBlock(
          (avg_pool): AdaptiveAvgPool2d(output_size=(1, None))
          (fc): Sequential(
            (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
            (1): ReLU(inplace=True)
            (2): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))
            (3): Sigmoid()
          )
        )
      )
    )
    (7): AttentionBlock(
      (W_g): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))
      (W_x): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))
      (psi): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))
      (relu): ReLU(inplace=True)
      (sigmoid): Sigmoid()
    )
  )
  (final_conv): Sequential(
    (0): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (1): Sigmoid()
  )
)
2025-01-21 18:29:07,991 - INFO - Loaded model from C:\Users\didri\Desktop\UNet-Models\Unet_model_Audio_Seperation\Model_Weights\Fine_tuned\model.pth
2025-01-21 18:29:07,991 - INFO - [Memory Clearing memory before training] Timestamp: 2025-01-21 18:29:07
2025-01-21 18:29:07,991 - INFO - [Memory Clearing memory before training] GPU 0: NVIDIA GeForce RTX 3060, Total=12.88 GB, Allocated=0.12 GB, Cached=0.25 GB
2025-01-21 18:29:07,991 - INFO - [Memory Clearing memory before training] CPU Memory Usage: ~0.61 GB
2025-01-21 18:29:08,065 - INFO - [Memory Memory after clearing it...] Timestamp: 2025-01-21 18:29:08
2025-01-21 18:29:08,065 - INFO - [Memory Memory after clearing it...] GPU 0: NVIDIA GeForce RTX 3060, Total=12.88 GB, Allocated=0.12 GB, Cached=0.12 GB
2025-01-21 18:29:08,065 - INFO - [Memory Memory after clearing it...] CPU Memory Usage: ~0.61 GB
2025-01-21 18:29:08,065 - INFO - Training dataset: 37 batches
2025-01-21 18:29:08,065 - INFO - Validation dataset: 25 batches
2025-01-21 18:30:42,103 - INFO - Training started with configuration: Batch size=4, Effective batch size: 64 Learning rate=1e-06, Epochs=13
2025-01-21 18:30:42,103 - INFO - [Train] Epoch 1/13 started.
2025-01-21 18:31:06,959 - INFO - Batch 1: Mixture shape=torch.Size([4, 1, 1025, 861]), Target shape=torch.Size([4, 1, 1025, 861])
2025-01-21 18:31:06,975 - INFO - Mixture min=0.0000, max=375.5096
2025-01-21 18:31:06,975 - INFO - Target min=0.0000, max=222.0078
2025-01-21 18:31:27,835 - ERROR - [Train] Error during training: 'tuple' object has no attribute 'to'
